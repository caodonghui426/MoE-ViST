{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from vilt.modules import heads, objectives\n",
    "import vilt.modules.vision_transformer as vit\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from typing import OrderedDict\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vilt.transforms import pixelbert_transform\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import pretrainedmodels\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class config:\n",
    "    debug = False\n",
    "    exp_name = \"vilt\"\n",
    "    seed = 101\n",
    "    batch_size = 4096  # this is a desired batch size; pl trainer will accumulate gradients when per step batch is smaller.\n",
    "    train_batch_size = 32\n",
    "    valid_batch_size = 4\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_fold = 5\n",
    "\n",
    "    model_name = \"sensorViLOnlyTransformerSS\"\n",
    "    # wandb \n",
    "    wandb_name = \"vilt|玉米|290仅图像|修改学习率\"\n",
    "    \n",
    "\n",
    "    # Image setting\n",
    "    train_transform_keys = [\"pixelbert\"]\n",
    "    val_transform_keys = [\"pixelbert\"]\n",
    "    img_size = 384\n",
    "    max_image_len = -1\n",
    "    patch_size = 32\n",
    "    draw_false_image = 1\n",
    "    image_only = False\n",
    "\n",
    "    # Sensor\n",
    "    # senser_input_num = 11 # 翔冠的传感器参数\n",
    "    senser_input_num = 17 # 天航的传感器参数\n",
    "    \n",
    "    # Text Setting\n",
    "    vqav2_label_size = 3129\n",
    "    max_text_len = 40\n",
    "    tokenizer = \"bert-base-uncased\"\n",
    "    vocab_size = 30522 # vocabulary词汇数量\n",
    "    whole_word_masking = False\n",
    "    mlm_prob = 0.15\n",
    "    draw_false_text = 0\n",
    "\n",
    "    # Transformer Setting\n",
    "    vit = \"vit_base_patch32_384\"\n",
    "    hidden_size = 768  # 嵌入向量大小\n",
    "    num_heads = 12\n",
    "    num_layers = 12\n",
    "    mlp_ratio = 4\n",
    "    drop_rate = 0.1\n",
    "\n",
    "    # Optimizer Setting\n",
    "    optim_type = \"adamw\"\n",
    "    learning_rate = 2e-3 #0.0015#2e-3 #\n",
    "    weight_decay = 1e-4 # 0.01 ->1e-4\n",
    "    decay_power = 1\n",
    "    max_epoch = 50\n",
    "    max_steps = 25000\n",
    "    warmup_steps = 2500\n",
    "    end_lr = 0\n",
    "    lr_mult = 1  # multiply lr for downstream heads\n",
    "    # T_max = 8000/train_batch_size*max_epoch \n",
    "    T_max = 1000/train_batch_size*max_epoch \n",
    "\n",
    "    # Downstream Setting\n",
    "    get_recall_metric = False\n",
    "\n",
    "\n",
    "    # below params varies with the environment\n",
    "    data_root = \"\"\n",
    "    log_dir = \"result\"\n",
    "    per_gpu_batchsize = 0  # you should define this manually with per_gpu_batch_size=#\n",
    "    num_gpus = 1\n",
    "    num_nodes = 1\n",
    "    load_path = \"weights/vilt_200k_mlm_itm.ckpt\"\n",
    "    # load_path = \"save_model_dict.pt\"\n",
    "    num_workers = 1\n",
    "    precision = 16\n",
    "\n",
    "# config = vars(config)\n",
    "# config = dict(config)\n",
    "config\n",
    "\n",
    "if config.debug:\n",
    "    config.max_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "\n",
    "    torch.manual_seed(seed)  # 为CPU设置随机种子\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.manual_seed(seed)  # 为当前GPU设置随机种子\n",
    "    torch.cuda.manual_seed_all(seed)  # 为所有GPU设置随机种子\n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "setup_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_MODE\"] = 'dryrun' # 离线模式\n",
    "try:\n",
    "    # wandb.log(key=\"*******\") # if debug\n",
    "    wandb.login() # storage in ~/.netrc file\n",
    "    anonymous = None\n",
    "except:\n",
    "    anonymous = \"must\"\n",
    "    print('\\nGet your W&B access token from here: https://wandb.ai/authorize\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(892, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pic_key</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date</th>\n",
       "      <th>co2</th>\n",
       "      <th>stemp</th>\n",
       "      <th>stemp2</th>\n",
       "      <th>stemp3</th>\n",
       "      <th>stemp4</th>\n",
       "      <th>stemp5</th>\n",
       "      <th>...</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm25</th>\n",
       "      <th>press</th>\n",
       "      <th>solar</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind_d</th>\n",
       "      <th>wind_sp</th>\n",
       "      <th>LAI</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>/797/1655496809_1655496663_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>393</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>991.1</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.26</td>\n",
       "      <td>274.3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.4475</td>\n",
       "      <td>/home/junsheng/data/tianhang_corn/1655496809_1...</td>\n",
       "      <td>1.4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>606</td>\n",
       "      <td>/797/1655496809_1655496663_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>393</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>991.2</td>\n",
       "      <td>5.93</td>\n",
       "      <td>17.18</td>\n",
       "      <td>268.7</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.4475</td>\n",
       "      <td>/home/junsheng/data/tianhang_corn/1655496809_1...</td>\n",
       "      <td>1.4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607</td>\n",
       "      <td>/797/1655496809_1655496663_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>393</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>991.1</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.26</td>\n",
       "      <td>274.3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.4475</td>\n",
       "      <td>/home/junsheng/data/tianhang_corn/1655496809_1...</td>\n",
       "      <td>1.4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>608</td>\n",
       "      <td>/797/1655496809_1655496663_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>393</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>991.2</td>\n",
       "      <td>5.93</td>\n",
       "      <td>17.18</td>\n",
       "      <td>268.7</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.4475</td>\n",
       "      <td>/home/junsheng/data/tianhang_corn/1655496809_1...</td>\n",
       "      <td>1.4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>609</td>\n",
       "      <td>/797/1655504080_1655503863_4.jpg</td>\n",
       "      <td>2022-06-18 06</td>\n",
       "      <td>2022-06-18</td>\n",
       "      <td>391</td>\n",
       "      <td>18.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>991.9</td>\n",
       "      <td>8.84</td>\n",
       "      <td>17.75</td>\n",
       "      <td>248.6</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.4475</td>\n",
       "      <td>/home/junsheng/data/tianhang_corn/1655504080_1...</td>\n",
       "      <td>1.4475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                           pic_key      date_hour        date  co2  \\\n",
       "0    605  /797/1655496809_1655496663_4.jpg  2022-06-18 04  2022-06-18  393   \n",
       "1    606  /797/1655496809_1655496663_4.jpg  2022-06-18 04  2022-06-18  393   \n",
       "2    607  /797/1655496809_1655496663_4.jpg  2022-06-18 04  2022-06-18  393   \n",
       "3    608  /797/1655496809_1655496663_4.jpg  2022-06-18 04  2022-06-18  393   \n",
       "4    609  /797/1655504080_1655503863_4.jpg  2022-06-18 06  2022-06-18  391   \n",
       "\n",
       "   stemp  stemp2  stemp3  stemp4  stemp5  ...  pm10  pm25  press  solar  \\\n",
       "0   19.0    19.0    18.9   -30.0    17.5  ...   6.0   6.0  991.1   2.52   \n",
       "1   19.0    19.0    18.9   -30.0    17.5  ...   7.0   7.0  991.2   5.93   \n",
       "2   18.9    19.0    18.8   -30.0    17.5  ...   6.0   6.0  991.1   2.52   \n",
       "3   18.9    19.0    18.8   -30.0    17.5  ...   7.0   7.0  991.2   5.93   \n",
       "4   18.6    18.8    18.7   -30.0    17.5  ...   5.0   5.0  991.9   8.84   \n",
       "\n",
       "    temp wind_d wind_sp     LAI  \\\n",
       "0  17.26  274.3    3.75  1.4475   \n",
       "1  17.18  268.7    2.67  1.4475   \n",
       "2  17.26  274.3    3.75  1.4475   \n",
       "3  17.18  268.7    2.67  1.4475   \n",
       "4  17.75  248.6    2.07  1.4475   \n",
       "\n",
       "                                          image_path   label  \n",
       "0  /home/junsheng/data/tianhang_corn/1655496809_1...  1.4475  \n",
       "1  /home/junsheng/data/tianhang_corn/1655496809_1...  1.4475  \n",
       "2  /home/junsheng/data/tianhang_corn/1655496809_1...  1.4475  \n",
       "3  /home/junsheng/data/tianhang_corn/1655496809_1...  1.4475  \n",
       "4  /home/junsheng/data/tianhang_corn/1655504080_1...  1.4475  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tianhang = pd.read_csv(\"/home/junsheng/ViLT/data/290-tianhang-corn.csv\")\n",
    "df_tianhang['image_path'] = df_tianhang['pic_key'].map(lambda x:os.path.join('/home/junsheng/data/tianhang_corn',x.split('/')[-1]))\n",
    "df_tianhang['label'] = df_tianhang['LAI']\n",
    "df_tianhang = df_tianhang.dropna()\n",
    "df_tianhang = df_tianhang.reset_index()\n",
    "print(df_tianhang.shape)\n",
    "df_tianhang.to_csv(\"test.csv\",index=False)\n",
    "df_tianhang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "785\n",
      "562\n"
     ]
    }
   ],
   "source": [
    "# 检查图片下载的全不全\n",
    "pic = df_tianhang.image_path.map(lambda x:x.split('/')[-1]).unique()\n",
    "print(len(pic))\n",
    "file_ls = os.listdir(\"/home/junsheng/data/tianhang_corn\")\n",
    "print(len(file_ls))\n",
    "ret = list(set(pic) ^ set(file_ls))\n",
    "print(len(ret)) #差集\n",
    "# assert len(pic)==len(file_ls),\"请检查下载的图片，缺了{}个\".format(len(pic)-len(file_ls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化非object列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'pic_key',\n",
       " 'date_hour',\n",
       " 'date',\n",
       " 'co2',\n",
       " 'stemp',\n",
       " 'stemp2',\n",
       " 'stemp3',\n",
       " 'stemp4',\n",
       " 'stemp5',\n",
       " 'shumi',\n",
       " 'shumi2',\n",
       " 'shumi3',\n",
       " 'shumi4',\n",
       " 'shumi5',\n",
       " 'ts',\n",
       " 'insert_time',\n",
       " 'humi',\n",
       " 'pm10',\n",
       " 'pm25',\n",
       " 'press',\n",
       " 'solar',\n",
       " 'temp',\n",
       " 'wind_d',\n",
       " 'wind_sp',\n",
       " 'LAI',\n",
       " 'image_path',\n",
       " 'label']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_tianhang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'co2', 'stemp', 'stemp2', 'stemp3', 'stemp4', 'stemp5', 'shumi', 'shumi2', 'shumi3', 'shumi4', 'shumi5', 'humi', 'pm10', 'pm25', 'press', 'solar', 'temp', 'wind_d', 'wind_sp', 'LAI', 'label']\n",
      "{'index': (605, 1752), 'co2': (364, 636), 'stemp': (18.1, 25.1), 'stemp2': (18.3, 23.0), 'stemp3': (18.3, 22.1), 'stemp4': (-30.0, -30.0), 'stemp5': (17.1, 21.2), 'shumi': (46.8, 80.6), 'shumi2': (53.0, 75.6), 'shumi3': (55.2, 79.5), 'shumi4': (0.0, 0.0), 'shumi5': (67.3, 81.5), 'humi': (31.0, 98.53), 'pm10': (0.0, 128.0), 'pm25': (0.0, 55.0), 'press': (981.1, 1005.1), 'solar': (0.0, 200.0), 'temp': (16.37, 30.99), 'wind_d': (0.0, 359.8), 'wind_sp': (0.0, 6.68), 'LAI': (1.3075, 1.91), 'label': (1.3075, 1.91)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_388755/1995579911.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  df_tianhang[title] = df_tianhang[title].map(lambda x:(x-x_min)/(x_max - x_min))\n"
     ]
    }
   ],
   "source": [
    "number_title = []\n",
    "recorder = {}\n",
    "for title in df_tianhang:\n",
    "    # print(df_xiangguan[title].head())\n",
    "    if title == 'raw_label':\n",
    "        continue\n",
    "    if df_tianhang[title].dtype != \"object\":\n",
    "        \n",
    "        number_title.append(title)\n",
    "        x_min = df_tianhang[title].min()\n",
    "        x_max = df_tianhang[title].max()\n",
    "        # print(x_min,x_max)\n",
    "        recorder[title] = (x_min,x_max)\n",
    "        df_tianhang[title] = df_tianhang[title].map(lambda x:(x-x_min)/(x_max - x_min))\n",
    "print(number_title)\n",
    "print(recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tianhang['stemp4'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: 17\n"
     ]
    }
   ],
   "source": [
    "# xiangguan_sensor = ['temperature', 'humidity', 'illuminance', 'soil_temperature', 'soil_humidity', 'pressure', 'wind_speed', 'photosynthetic', 'sun_exposure_time', 'COz', 'soil_ph']\n",
    "# tianhang_sensor = ['co2', 'stemp', 'stemp2', 'stemp3', 'stemp4', 'stemp5', 'shumi', 'shumi2', 'shumi3', 'shumi4', 'shumi5', 'humi', 'pm10', 'pm25', 'press', 'solar', 'temp', 'wind_d', 'wind_sp']\n",
    "tianhang_sensor = ['co2', 'stemp', 'stemp2', 'stemp3', 'stemp5', 'shumi', 'shumi2', 'shumi3', 'shumi5', 'humi', 'pm10', 'pm25', 'press', 'solar', 'temp', 'wind_d', 'wind_sp']\n",
    "\n",
    "df_tianhang['sensor'] = df_tianhang[tianhang_sensor].values.tolist()\n",
    "print(\"input dim:\",len(tianhang_sensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892, 29)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_tianhang\n",
    "if config.debug:\n",
    "    df = df[:100]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tianhang.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0.0    179\n",
       "1.0    179\n",
       "2.0    178\n",
       "3.0    178\n",
       "4.0    178\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)  \n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df,df.date)):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "df.groupby(['fold'])['label'].count()# ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv(\"test_fold.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((config.img_size,config.img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    mean=[0.7136, 0.7118, 0.6788],\n",
    "    std=[0.3338, 0.3453, 0.3020],\n",
    "    \n",
    ")\n",
    "])\n",
    "\n",
    "def load_img(path):\n",
    "    img =  Image.open(path).convert('RGB')\n",
    "    img = myTransforms(img)\n",
    "    return img\n",
    "\n",
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, label=True, transforms=None):\n",
    "        self.df         = df\n",
    "        self.label      = label\n",
    "        self.sensors = df['sensor'].tolist()\n",
    "        self.img_paths  = df['image_path'].tolist()   \n",
    "        if self.label:\n",
    "            self.labels = df['label'].tolist()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        img = load_img(img_path)\n",
    "        sensor = self.sensors[index]\n",
    "        sensor = torch.tensor(sensor).unsqueeze(0) #[1,n]\n",
    "        if self.label:\n",
    "            label = self.labels[index]\n",
    "            return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n",
    "        else:\n",
    "            return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_dataloader(fold:int):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    print(\"train_df.shape:\",train_df.shape)\n",
    "    print(\"valid_df.shape:\",valid_df.shape)\n",
    "\n",
    "    train_data  = BuildDataset(df=train_df,label=True)\n",
    "    valid_data = BuildDataset(df=valid_df,label=True)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.train_batch_size,shuffle=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=config.valid_batch_size,shuffle=False)\n",
    "    # test_loader = DataLoader(test_data, batch_size=config.test_batch_size,shuffle=False)\n",
    "    return train_loader,valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape: (713, 30)\n",
      "valid_df.shape: (179, 30)\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = BuildDataset(df=df)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=config.train_batch_size,shuffle=True)\n",
    "# valid_loader = DataLoader(train_dataset, batch_size=config.valid_batch_size,shuffle=True)\n",
    "train_loader,valid_loader = fetch_dataloader(fold=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_388755/355586058.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 384, 384])\n",
      "torch.Size([32, 1, 17])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "img,sensor,label = next(iter(train_loader))\n",
    "print(img.shape)\n",
    "print(sensor.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorViLOnlyTransformerSS-仅vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sensorViLOnlyTransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self, sensor_class_n, output_class_n):\n",
    "        super().__init__()\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "            pretrained=True, config=vars(config)\n",
    "        )\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "        self.classifier = nn.Linear(config.hidden_size, output_class_n)\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        mask_image=False,\n",
    "        image_token_type_idx=1,\n",
    "        image_embeds=None,\n",
    "        image_masks=None,\n",
    "    ):\n",
    "\n",
    "        if image_embeds is None and image_masks is None:\n",
    "            img = batch[\"image\"].to(config.device)\n",
    "\n",
    "            (\n",
    "                image_embeds,  # torch.Size([1, 217, 768])\n",
    "                image_masks,  # torch.Size([1, 217])\n",
    "                patch_index,\n",
    "                image_labels,\n",
    "            ) = self.transformer.visual_embed(\n",
    "                img,\n",
    "                max_image_len=config.max_image_len,\n",
    "                mask_it=mask_image,\n",
    "            )\n",
    "        else:\n",
    "            patch_index, image_labels = (\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        image_embeds = image_embeds + self.token_type_embeddings(\n",
    "            torch.full_like(image_masks, image_token_type_idx)\n",
    "        )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(batch_size, 1).to(config.device)  # 序列数量\n",
    "        image_masks = image_masks.to(config.device)\n",
    "        co_embeds = image_embeds\n",
    "        co_masks = image_masks\n",
    "\n",
    "        x = co_embeds.to(config.device)  # torch.Size([1, 145, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks):\n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks)  # co_masks = torch.Size([1, 211])\n",
    "\n",
    "        x = self.transformer.norm(x)  # torch.Size([1, 240, 768])\n",
    "        image_feats = x\n",
    "        cls_feats = self.pooler(x)  # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "\n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "\n",
    "        ret = {\n",
    "            \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats,  # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            \"image_labels\": image_labels,\n",
    "            \"image_masks\": image_masks,\n",
    "\n",
    "            \"patch_index\": patch_index,\n",
    "\n",
    "            \"cls_output\": cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "\n",
    "        ret.update(self.infer(batch))\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorViLTransformerSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorViLTransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config.hidden_size) \n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "                pretrained=True, config=vars(config)\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config.hidden_size,output_class_n)\n",
    "\n",
    "        hs = config.hidden_size\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        mask_image=False,\n",
    "        image_token_type_idx=1,\n",
    "        image_embeds=None,\n",
    "        image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config.device)\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        \n",
    "\n",
    "        if image_embeds is None and image_masks is None:\n",
    "            img = batch[\"image\"].to(config.device)\n",
    "       \n",
    "            (\n",
    "                image_embeds, # torch.Size([1, 217, 768])\n",
    "                image_masks, # torch.Size([1, 217])\n",
    "                patch_index,\n",
    "                image_labels,\n",
    "            ) = self.transformer.visual_embed(\n",
    "                img,\n",
    "                max_image_len=config.max_image_len,\n",
    "                mask_it=mask_image,\n",
    "            )\n",
    "        else:\n",
    "            patch_index, image_labels = (\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        image_embeds = image_embeds + self.token_type_embeddings(\n",
    "                torch.full_like(image_masks, image_token_type_idx)\n",
    "            )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(batch_size,1).to(config.device) # 序列数量\n",
    "        image_masks = image_masks.to(config.device)\n",
    "        co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "\n",
    "        x = co_embeds.to(config.device) # torch.Size([1, 211, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks): \n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks) # co_masks = torch.Size([1, 211])\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "            x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "            x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "        \n",
    "        ret = {\n",
    "           \"sensor_feats\":sensor_feats,\n",
    "            \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            \"image_labels\": image_labels,\n",
    "            \"image_masks\": image_masks,\n",
    "           \n",
    "            \"patch_index\": patch_index,\n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorOnlyViLTransformerSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorOnlyViLTransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config.hidden_size) \n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "                pretrained=True, config=vars(config)\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config.hidden_size,output_class_n)\n",
    "\n",
    "        hs = config.hidden_size\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        # mask_image=False,\n",
    "        # image_token_type_idx=1,\n",
    "        # image_embeds=None,\n",
    "        # image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config.device)\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        \n",
    "\n",
    "        # if image_embeds is None and image_masks is None:\n",
    "        #     img = batch[\"image\"].to(config.device)\n",
    "       \n",
    "        #     (\n",
    "        #         image_embeds, # torch.Size([1, 217, 768])\n",
    "        #         image_masks, # torch.Size([1, 217])\n",
    "        #         patch_index,\n",
    "        #         image_labels,\n",
    "        #     ) = self.transformer.visual_embed(\n",
    "        #         img,\n",
    "        #         max_image_len=config.max_image_len,\n",
    "        #         mask_it=mask_image,\n",
    "        #     )\n",
    "        # else:\n",
    "        #     patch_index, image_labels = (\n",
    "        #         None,\n",
    "        #         None,\n",
    "        #     )\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        # image_embeds = image_embeds + self.token_type_embeddings(\n",
    "        #         torch.full_like(image_masks, image_token_type_idx)\n",
    "        #     )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        # batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(sensor_embeds.shape[1],1).to(config.device) # 序列数量\n",
    "        # image_masks = image_masks.to(config.device)\n",
    "        # co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        # co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "        co_embeds = sensor_embeds\n",
    "        co_masks = sensor_masks\n",
    "\n",
    "        x = co_embeds.to(config.device) # torch.Size([1, 1, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks):\n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks)\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        # sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "        #     x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "        #     x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        # )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "        \n",
    "        ret = {\n",
    "        #    \"sensor_feats\":sensor_feats,\n",
    "            # \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            # \"image_labels\": image_labels,\n",
    "            # \"image_masks\": image_masks,\n",
    "           \n",
    "            # \"patch_index\": patch_index,\n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorResnet50TransformerSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorResnet50TransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config.hidden_size) \n",
    "        # resnet model\n",
    "        resnet_model = pretrainedmodels.__dict__[\"resnet50\"](\n",
    "    num_classes=1000, pretrained='imagenet')\n",
    "        features = list([resnet_model.conv1, resnet_model.bn1, resnet_model.relu, resnet_model.maxpool, resnet_model.layer1, resnet_model.layer2, resnet_model.layer3,resnet_model.layer4])\n",
    "        conv = nn.Conv2d(2048, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        bn = nn.BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "        self.resnet_features = nn.Sequential(*features,conv,bn,relu)\n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "                pretrained=True, config=vars(config)\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config.hidden_size,output_class_n)\n",
    "\n",
    "        hs = config.hidden_size\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        mask_image=False,\n",
    "        image_token_type_idx=1,\n",
    "        image_embeds=None,\n",
    "        image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config.device)\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        img = batch[\"image\"].to(config.device)\n",
    "        image_embeds = self.resnet_features(img) \n",
    "        image_embeds = image_embeds.flatten(2).transpose(1, 2)\n",
    "        image_masks = torch.ones(image_embeds.shape[0],image_embeds.shape[1],dtype=torch.int64).to(config.device)\n",
    "\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        image_embeds = image_embeds + self.token_type_embeddings(\n",
    "                torch.full_like(image_masks, image_token_type_idx)\n",
    "            )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(batch_size,1).to(config.device) # 序列数量\n",
    "        image_masks = image_masks.to(config.device)\n",
    "        co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "\n",
    "        x = co_embeds.to(config.device) # torch.Size([1, 211, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks): \n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks) # co_masks = torch.Size([1, 211])\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "            x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "            x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "        \n",
    "        ret = {\n",
    "           \"sensor_feats\":sensor_feats,\n",
    "            \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            \"image_masks\": image_masks,\n",
    "           \n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorResnet101TransformerSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorResnet101TransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config.hidden_size) \n",
    "        # resnet model\n",
    "        resnet_model = pretrainedmodels.__dict__[\"resnet101\"](\n",
    "    num_classes=1000, pretrained='imagenet')\n",
    "        features = list([resnet_model.conv1, resnet_model.bn1, resnet_model.relu, resnet_model.maxpool, resnet_model.layer1, resnet_model.layer2, resnet_model.layer3,resnet_model.layer4])\n",
    "        conv = nn.Conv2d(2048, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        bn = nn.BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "        self.resnet_features = nn.Sequential(*features,conv,bn,relu)\n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "                pretrained=True, config=vars(config)\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config.hidden_size,output_class_n)\n",
    "\n",
    "        hs = config.hidden_size\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        mask_image=False,\n",
    "        image_token_type_idx=1,\n",
    "        image_embeds=None,\n",
    "        image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config.device)\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        img = batch[\"image\"].to(config.device)\n",
    "        image_embeds = self.resnet_features(img) \n",
    "        image_embeds = image_embeds.flatten(2).transpose(1, 2)\n",
    "        image_masks = torch.ones(image_embeds.shape[0],image_embeds.shape[1],dtype=torch.int64).to(config.device)\n",
    "\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        image_embeds = image_embeds + self.token_type_embeddings(\n",
    "                torch.full_like(image_masks, image_token_type_idx)\n",
    "            )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(batch_size,1).to(config.device) # 序列数量\n",
    "        image_masks = image_masks.to(config.device)\n",
    "        co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "\n",
    "        x = co_embeds.to(config.device) # torch.Size([1, 211, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks): \n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks) # co_masks = torch.Size([1, 211])\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "            x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "            x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "        \n",
    "        ret = {\n",
    "           \"sensor_feats\":sensor_feats,\n",
    "            \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            \"image_masks\": image_masks,\n",
    "           \n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No pretrained weights exist or were found for this model. Using random initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "0 sensorViLOnlyTransformerSS(\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (transformer): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      "  (pooler): Pooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n",
      "1 Embedding(2, 768)\n",
      "2 VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      ")\n",
      "3 PatchEmbed(\n",
      "  (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      ")\n",
      "4 Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "5 Dropout(p=0.1, inplace=False)\n",
      "6 ModuleList(\n",
      "  (0): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (2): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (3): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (4): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (5): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (6): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (7): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (8): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (9): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (10): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (11): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "8 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "9 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "10 Linear(in_features=768, out_features=2304, bias=True)\n",
      "11 Dropout(p=0.0, inplace=False)\n",
      "12 Linear(in_features=768, out_features=768, bias=True)\n",
      "13 Dropout(p=0.1, inplace=False)\n",
      "14 Identity()\n",
      "15 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "16 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "17 Linear(in_features=768, out_features=3072, bias=True)\n",
      "18 GELU(approximate=none)\n",
      "19 Linear(in_features=3072, out_features=768, bias=True)\n",
      "20 Dropout(p=0.1, inplace=False)\n",
      "21 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "22 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "23 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "24 Linear(in_features=768, out_features=2304, bias=True)\n",
      "25 Dropout(p=0.0, inplace=False)\n",
      "26 Linear(in_features=768, out_features=768, bias=True)\n",
      "27 Dropout(p=0.1, inplace=False)\n",
      "28 Identity()\n",
      "29 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "30 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "31 Linear(in_features=768, out_features=3072, bias=True)\n",
      "32 GELU(approximate=none)\n",
      "33 Linear(in_features=3072, out_features=768, bias=True)\n",
      "34 Dropout(p=0.1, inplace=False)\n",
      "35 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "36 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "37 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "38 Linear(in_features=768, out_features=2304, bias=True)\n",
      "39 Dropout(p=0.0, inplace=False)\n",
      "40 Linear(in_features=768, out_features=768, bias=True)\n",
      "41 Dropout(p=0.1, inplace=False)\n",
      "42 Identity()\n",
      "43 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "44 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "45 Linear(in_features=768, out_features=3072, bias=True)\n",
      "46 GELU(approximate=none)\n",
      "47 Linear(in_features=3072, out_features=768, bias=True)\n",
      "48 Dropout(p=0.1, inplace=False)\n",
      "49 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "50 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "51 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "52 Linear(in_features=768, out_features=2304, bias=True)\n",
      "53 Dropout(p=0.0, inplace=False)\n",
      "54 Linear(in_features=768, out_features=768, bias=True)\n",
      "55 Dropout(p=0.1, inplace=False)\n",
      "56 Identity()\n",
      "57 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "58 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "59 Linear(in_features=768, out_features=3072, bias=True)\n",
      "60 GELU(approximate=none)\n",
      "61 Linear(in_features=3072, out_features=768, bias=True)\n",
      "62 Dropout(p=0.1, inplace=False)\n",
      "63 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "64 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "65 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "66 Linear(in_features=768, out_features=2304, bias=True)\n",
      "67 Dropout(p=0.0, inplace=False)\n",
      "68 Linear(in_features=768, out_features=768, bias=True)\n",
      "69 Dropout(p=0.1, inplace=False)\n",
      "70 Identity()\n",
      "71 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "72 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "73 Linear(in_features=768, out_features=3072, bias=True)\n",
      "74 GELU(approximate=none)\n",
      "75 Linear(in_features=3072, out_features=768, bias=True)\n",
      "76 Dropout(p=0.1, inplace=False)\n",
      "77 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "78 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "79 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "80 Linear(in_features=768, out_features=2304, bias=True)\n",
      "81 Dropout(p=0.0, inplace=False)\n",
      "82 Linear(in_features=768, out_features=768, bias=True)\n",
      "83 Dropout(p=0.1, inplace=False)\n",
      "84 Identity()\n",
      "85 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "86 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "87 Linear(in_features=768, out_features=3072, bias=True)\n",
      "88 GELU(approximate=none)\n",
      "89 Linear(in_features=3072, out_features=768, bias=True)\n",
      "90 Dropout(p=0.1, inplace=False)\n",
      "91 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "92 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "93 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "94 Linear(in_features=768, out_features=2304, bias=True)\n",
      "95 Dropout(p=0.0, inplace=False)\n",
      "96 Linear(in_features=768, out_features=768, bias=True)\n",
      "97 Dropout(p=0.1, inplace=False)\n",
      "98 Identity()\n",
      "99 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "100 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "101 Linear(in_features=768, out_features=3072, bias=True)\n",
      "102 GELU(approximate=none)\n",
      "103 Linear(in_features=3072, out_features=768, bias=True)\n",
      "104 Dropout(p=0.1, inplace=False)\n",
      "105 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "106 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "107 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "108 Linear(in_features=768, out_features=2304, bias=True)\n",
      "109 Dropout(p=0.0, inplace=False)\n",
      "110 Linear(in_features=768, out_features=768, bias=True)\n",
      "111 Dropout(p=0.1, inplace=False)\n",
      "112 Identity()\n",
      "113 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "114 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "115 Linear(in_features=768, out_features=3072, bias=True)\n",
      "116 GELU(approximate=none)\n",
      "117 Linear(in_features=3072, out_features=768, bias=True)\n",
      "118 Dropout(p=0.1, inplace=False)\n",
      "119 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "120 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "121 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "122 Linear(in_features=768, out_features=2304, bias=True)\n",
      "123 Dropout(p=0.0, inplace=False)\n",
      "124 Linear(in_features=768, out_features=768, bias=True)\n",
      "125 Dropout(p=0.1, inplace=False)\n",
      "126 Identity()\n",
      "127 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "128 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "129 Linear(in_features=768, out_features=3072, bias=True)\n",
      "130 GELU(approximate=none)\n",
      "131 Linear(in_features=3072, out_features=768, bias=True)\n",
      "132 Dropout(p=0.1, inplace=False)\n",
      "133 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "134 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "135 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "136 Linear(in_features=768, out_features=2304, bias=True)\n",
      "137 Dropout(p=0.0, inplace=False)\n",
      "138 Linear(in_features=768, out_features=768, bias=True)\n",
      "139 Dropout(p=0.1, inplace=False)\n",
      "140 Identity()\n",
      "141 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "142 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "143 Linear(in_features=768, out_features=3072, bias=True)\n",
      "144 GELU(approximate=none)\n",
      "145 Linear(in_features=3072, out_features=768, bias=True)\n",
      "146 Dropout(p=0.1, inplace=False)\n",
      "147 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "148 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "149 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "150 Linear(in_features=768, out_features=2304, bias=True)\n",
      "151 Dropout(p=0.0, inplace=False)\n",
      "152 Linear(in_features=768, out_features=768, bias=True)\n",
      "153 Dropout(p=0.1, inplace=False)\n",
      "154 Identity()\n",
      "155 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "156 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "157 Linear(in_features=768, out_features=3072, bias=True)\n",
      "158 GELU(approximate=none)\n",
      "159 Linear(in_features=3072, out_features=768, bias=True)\n",
      "160 Dropout(p=0.1, inplace=False)\n",
      "161 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "162 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "163 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "164 Linear(in_features=768, out_features=2304, bias=True)\n",
      "165 Dropout(p=0.0, inplace=False)\n",
      "166 Linear(in_features=768, out_features=768, bias=True)\n",
      "167 Dropout(p=0.1, inplace=False)\n",
      "168 Identity()\n",
      "169 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "170 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "171 Linear(in_features=768, out_features=3072, bias=True)\n",
      "172 GELU(approximate=none)\n",
      "173 Linear(in_features=3072, out_features=768, bias=True)\n",
      "174 Dropout(p=0.1, inplace=False)\n",
      "175 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "176 Linear(in_features=768, out_features=768, bias=True)\n",
      "177 Tanh()\n",
      "178 Pooler(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n",
      "179 Linear(in_features=768, out_features=768, bias=True)\n",
      "180 Tanh()\n",
      "181 Linear(in_features=768, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import pretrainedmodels\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "def build_model(model_name: str,pre_train):\n",
    "    if model_name[:6] == \"resnet50\":\n",
    "        model = pretrainedmodels.__dict__[config.model_name](\n",
    "            num_classes=1000, pretrained='imagenet')\n",
    "        dim_feats = model.last_linear.in_features  # =2048\n",
    "        nb_classes = 1\n",
    "        model.last_linear = nn.Linear(dim_feats, nb_classes)\n",
    "        return model\n",
    "    if model_name == \"se_resnet50\":\n",
    "        model = pretrainedmodels.__dict__[config.model_name](\n",
    "            num_classes=1000, pretrained='imagenet')\n",
    "        model.last_linear = nn.Linear(204800, 1,bias=True)\n",
    "        return model\n",
    "    if model_name == \"efficientnet-b4\": # efficient net\n",
    "        # refer:https://github.com/lukemelas/EfficientNet-PyTorch#example-classification\n",
    "        nb_classes = 1\n",
    "        if pre_train:\n",
    "            model = EfficientNet.from_pretrained(config.model_name)# 'efficientnet-b4'\n",
    "        else:\n",
    "            model = EfficientNet.from_name(config.model_name)# 'efficientnet-b4'\n",
    "        model._fc = nn.Linear(1792, nb_classes)\n",
    "        return model\n",
    "\n",
    "    if model_name == \"sensorOnlyViLTransformerSS\": #仅传感器\n",
    "        model = sensorOnlyViLTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "        return model\n",
    "    if model_name == \"sensorViLOnlyTransformerSS\": # 仅vit图像\n",
    "        model = sensorViLOnlyTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "        return model\n",
    "        \n",
    "    if model_name == \"sensorResnet50TransformerSS\":\n",
    "        model = sensorResnet50TransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "        return model\n",
    "    if model_name == \"sensorResnet101TransformerSS\":\n",
    "        model = sensorResnet101TransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "        return model\n",
    "\n",
    "    if model_name == \"sensorViLTransformerSS\":\n",
    "        model = sensorViLTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "        return model\n",
    "\n",
    "model = build_model(config.model_name,True)\n",
    "model.to(config.device)\n",
    "print(config.device)\n",
    "for i,m in enumerate(model.modules()):\n",
    "    print(i,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sensor = torch.rand(config.senser_input_num)\n",
    "# # sensor = torch.ones(config.senser_input_num)\n",
    "# print(sensor)\n",
    "# sensor =  torch.tensor(sensor).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 3])\n",
    "# batch = {}\n",
    "# batch['sensor'] = sensor\n",
    "# batch['image'] = \"/home/junsheng/data/xiangguan/pic/xiangguanD4-2021-05-24-10-00-25.jpeg\"\n",
    "# model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.mse_loss #均方误差损失函数\n",
    "# criterion = F.mae_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (img, sensor,label) in pbar:         \n",
    "        # img = img.to(device, dtype=torch.float)\n",
    "        # sensor  = sensor.to(device, dtype=torch.float)\n",
    "        # label  = label.to(device, dtype=torch.float)\n",
    "        batch_size = img.size(0)\n",
    "        \n",
    "        batch = {\"image\":img,\"sensor\":sensor}\n",
    "\n",
    "        y_pred = model(batch)\n",
    "        label = label.to(config.device).unsqueeze(1)\n",
    "        loss = criterion(y_pred['cls_output'], label)\n",
    "        \n",
    "        #一坨优化\n",
    "        optimizer.zero_grad()#每一次反向传播之前都要归零梯度\n",
    "        loss.backward()      #反向传播\n",
    "        optimizer.step()     #固定写法\n",
    "        scheduler.step()\n",
    "     \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, optimizer):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    val_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (img, sensor,label) in pbar:               \n",
    "        \n",
    "        \n",
    "        batch_size = img.size(0)\n",
    "        batch = {\"image\":img,\"sensor\":sensor}\n",
    "\n",
    "        y_pred  = model(batch)\n",
    "        label = label.to(config.device).unsqueeze(1)\n",
    "\n",
    "        loss = criterion(y_pred['cls_output'], label)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "     # init wandb\n",
    "    run = wandb.init(project=\"vilt\",\n",
    "                    config={k: v for k, v in dict(vars(config)).items() if '__' not in k},\n",
    "                    # config={k: v for k, v in dict(config).items() if '__' not in k},\n",
    "                    anonymous=anonymous,\n",
    "                    # name=f\"vilt|fold-{config.valid_fold}\",\n",
    "                    name=config.wandb_name,\n",
    "                    # group=config.wandb_group,\n",
    "                    )\n",
    "    wandb.watch(model, log_freq=100)\n",
    "\n",
    "    best_loss = 9999\n",
    "    best_valid_loss = 9999\n",
    "    history = defaultdict(list)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=device, epoch=epoch)\n",
    "        val_loss = valid_one_epoch(model,valid_loader,device=device,optimizer=optimizer)\n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "\n",
    "        wandb.log({\"Train Loss\": train_loss,\n",
    "                    \"Valid Loss\": val_loss,\n",
    "                \"lr\": scheduler.get_last_lr()[0]\n",
    "                })\n",
    "        if best_valid_loss > val_loss:\n",
    "            best_valid_loss = val_loss\n",
    "            # model_file_path = os.path.join(wandb.run.dir,\"epoch-{}-{}.bin\".format(epoch,wandb.run.id))\n",
    "            model_file_path = os.path.join(wandb.run.dir,\"epoch-best.bin\")\n",
    "            run.summary[\"Best Epoch\"] = epoch\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            print(\"model save to\", model_file_path)\n",
    "            \n",
    "    os.system(\"cp /home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb {}\".format(wandb.run.dir))\n",
    "    run.finish()\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=config.T_max, \n",
    "                                                   eta_min=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:16hpdxgb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/junsheng/ViLT/wandb/offline-run-20221102_170125-16hpdxgb<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221102_170125-16hpdxgb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:16hpdxgb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: NVIDIA GeForce RTX 3090\n",
      "\n",
      "Epoch 1/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/23 [00:00<?, ?it/s]/tmp/ipykernel_388755/355586058.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n",
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.23 GB, lr=0.00100, train_loss=0.2992]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.57it/s, gpu_memory=2.58 GB, lr=0.00100, valid_loss=0.3015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 2/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.73s/it, gpu_mem=6.06 GB, lr=0.00100, train_loss=0.2980]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.59it/s, gpu_memory=2.58 GB, lr=0.00100, valid_loss=0.3015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 3/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.72s/it, gpu_mem=6.06 GB, lr=0.00100, train_loss=0.2979]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.67it/s, gpu_memory=2.58 GB, lr=0.00100, valid_loss=0.3015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 4/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00099, train_loss=0.2979]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.72it/s, gpu_memory=2.58 GB, lr=0.00099, valid_loss=0.3015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 5/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.70s/it, gpu_mem=6.06 GB, lr=0.00099, train_loss=0.2979]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.80it/s, gpu_memory=2.58 GB, lr=0.00099, valid_loss=0.3014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 6/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00098, train_loss=0.2979]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.82it/s, gpu_memory=2.58 GB, lr=0.00098, valid_loss=0.3014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 7/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.68s/it, gpu_mem=6.06 GB, lr=0.00097, train_loss=0.2979]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.68it/s, gpu_memory=2.58 GB, lr=0.00097, valid_loss=0.3014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 8/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.72s/it, gpu_mem=6.06 GB, lr=0.00097, train_loss=0.2978]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.71it/s, gpu_memory=2.58 GB, lr=0.00097, valid_loss=0.3011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 9/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.72s/it, gpu_mem=6.06 GB, lr=0.00096, train_loss=0.2562]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.84it/s, gpu_memory=2.58 GB, lr=0.00096, valid_loss=0.1065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 10/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.72s/it, gpu_mem=6.06 GB, lr=0.00095, train_loss=0.0865]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.72it/s, gpu_memory=2.58 GB, lr=0.00095, valid_loss=0.0723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 11/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00094, train_loss=0.0782]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.71it/s, gpu_memory=2.58 GB, lr=0.00094, valid_loss=0.0835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.70s/it, gpu_mem=6.06 GB, lr=0.00093, train_loss=0.0747]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.86it/s, gpu_memory=2.58 GB, lr=0.00093, valid_loss=0.0739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00091, train_loss=0.0726]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.58it/s, gpu_memory=2.58 GB, lr=0.00091, valid_loss=0.0759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.70s/it, gpu_mem=6.06 GB, lr=0.00090, train_loss=0.0722]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.79it/s, gpu_memory=2.58 GB, lr=0.00090, valid_loss=0.0747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.70s/it, gpu_mem=6.06 GB, lr=0.00089, train_loss=0.0750]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.65it/s, gpu_memory=2.58 GB, lr=0.00089, valid_loss=0.0718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 16/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00087, train_loss=0.0738]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.64it/s, gpu_memory=2.58 GB, lr=0.00087, valid_loss=0.0734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00085, train_loss=0.0749]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.82it/s, gpu_memory=2.58 GB, lr=0.00085, valid_loss=0.0734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00084, train_loss=0.0728]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.58it/s, gpu_memory=2.58 GB, lr=0.00084, valid_loss=0.0736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.73s/it, gpu_mem=6.06 GB, lr=0.00082, train_loss=0.0731]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.59it/s, gpu_memory=2.58 GB, lr=0.00082, valid_loss=0.0775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.70s/it, gpu_mem=6.06 GB, lr=0.00080, train_loss=0.0731]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.67it/s, gpu_memory=2.58 GB, lr=0.00080, valid_loss=0.0731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.72s/it, gpu_mem=6.06 GB, lr=0.00078, train_loss=0.0728]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.74it/s, gpu_memory=2.58 GB, lr=0.00078, valid_loss=0.0737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.73s/it, gpu_mem=6.06 GB, lr=0.00077, train_loss=0.0743]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.75it/s, gpu_memory=2.58 GB, lr=0.00077, valid_loss=0.0756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.70s/it, gpu_mem=6.06 GB, lr=0.00075, train_loss=0.0756]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.79it/s, gpu_memory=2.58 GB, lr=0.00075, valid_loss=0.0719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00073, train_loss=0.0734]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.82it/s, gpu_memory=2.58 GB, lr=0.00073, valid_loss=0.0720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.68s/it, gpu_mem=6.06 GB, lr=0.00070, train_loss=0.0726]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.85it/s, gpu_memory=2.58 GB, lr=0.00070, valid_loss=0.0721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00068, train_loss=0.0723]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.70it/s, gpu_memory=2.58 GB, lr=0.00068, valid_loss=0.0721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00066, train_loss=0.0715]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.78it/s, gpu_memory=2.58 GB, lr=0.00066, valid_loss=0.0718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00064, train_loss=0.0717]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.80it/s, gpu_memory=2.58 GB, lr=0.00064, valid_loss=0.0727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.67s/it, gpu_mem=6.06 GB, lr=0.00062, train_loss=0.0732]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.55it/s, gpu_memory=2.58 GB, lr=0.00062, valid_loss=0.0730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.67s/it, gpu_mem=6.06 GB, lr=0.00060, train_loss=0.0719]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.86it/s, gpu_memory=2.58 GB, lr=0.00060, valid_loss=0.0738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.70s/it, gpu_mem=6.06 GB, lr=0.00057, train_loss=0.0726]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.63it/s, gpu_memory=2.58 GB, lr=0.00057, valid_loss=0.0720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00055, train_loss=0.0732]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.74it/s, gpu_memory=2.58 GB, lr=0.00055, valid_loss=0.0727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00053, train_loss=0.0720]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.82it/s, gpu_memory=2.58 GB, lr=0.00053, valid_loss=0.0756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.72s/it, gpu_mem=6.06 GB, lr=0.00050, train_loss=0.0718]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.80it/s, gpu_memory=2.58 GB, lr=0.00050, valid_loss=0.0717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 35/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00048, train_loss=0.0731]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.66it/s, gpu_memory=2.58 GB, lr=0.00048, valid_loss=0.0740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.72s/it, gpu_mem=6.06 GB, lr=0.00046, train_loss=0.0760]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.91it/s, gpu_memory=2.58 GB, lr=0.00046, valid_loss=0.0731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.70s/it, gpu_mem=6.06 GB, lr=0.00044, train_loss=0.0716]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.63it/s, gpu_memory=2.58 GB, lr=0.00044, valid_loss=0.0732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.70s/it, gpu_mem=6.06 GB, lr=0.00041, train_loss=0.0725]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.75it/s, gpu_memory=2.58 GB, lr=0.00041, valid_loss=0.0723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00039, train_loss=0.0721]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.56it/s, gpu_memory=2.58 GB, lr=0.00039, valid_loss=0.0720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00037, train_loss=0.0719]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.55it/s, gpu_memory=2.58 GB, lr=0.00037, valid_loss=0.0723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.72s/it, gpu_mem=6.06 GB, lr=0.00035, train_loss=0.0728]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.81it/s, gpu_memory=2.58 GB, lr=0.00035, valid_loss=0.0724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.71s/it, gpu_mem=6.06 GB, lr=0.00033, train_loss=0.0718]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.73it/s, gpu_memory=2.58 GB, lr=0.00033, valid_loss=0.0721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00030, train_loss=0.0718]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.81it/s, gpu_memory=2.58 GB, lr=0.00030, valid_loss=0.0722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00028, train_loss=0.0727]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.90it/s, gpu_memory=2.58 GB, lr=0.00028, valid_loss=0.0739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00026, train_loss=0.0720]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.57it/s, gpu_memory=2.58 GB, lr=0.00026, valid_loss=0.0718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00024, train_loss=0.0715]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.66it/s, gpu_memory=2.58 GB, lr=0.00024, valid_loss=0.0723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:39<00:00,  1.70s/it, gpu_mem=6.06 GB, lr=0.00022, train_loss=0.0714]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.72it/s, gpu_memory=2.58 GB, lr=0.00022, valid_loss=0.0716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 48/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00021, train_loss=0.0713]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.85it/s, gpu_memory=2.58 GB, lr=0.00021, valid_loss=0.0710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n",
      "Epoch 49/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00019, train_loss=0.0702]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.79it/s, gpu_memory=2.58 GB, lr=0.00019, valid_loss=0.0762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 23/23 [00:38<00:00,  1.69s/it, gpu_mem=6.06 GB, lr=0.00017, train_loss=0.0710]\n",
      "Valid : 100%|██████████| 45/45 [00:09<00:00,  4.59it/s, gpu_memory=2.58 GB, lr=0.00017, valid_loss=0.0673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq/files/epoch-best.bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>███████▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Valid Loss</td><td>███████▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>████████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Epoch</td><td>50</td></tr><tr><td>Train Loss</td><td>0.071</td></tr><tr><td>Valid Loss</td><td>0.06734</td></tr><tr><td>lr</td><td>0.00017</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/junsheng/ViLT/wandb/offline-run-20221102_171950-1ds1jgsq<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221102_171950-1ds1jgsq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model, history = run_training(model, optimizer, scheduler,device=config.device,num_epochs=config.max_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 384, 384]) torch.Size([4, 1, 17]) tensor([0.2324, 0.2324, 0.2324, 0.2324])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_388755/355586058.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n"
     ]
    }
   ],
   "source": [
    "for (img,sensor,label) in valid_loader:\n",
    "    print(img.shape,sensor.shape,label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'embedding_test_dict.pt')\n",
    "# print(model)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"/home/junsheng/ViLT/wandb/offline-run-20220811_120519-nzfb1xoz/files/epoch-best.bin\"))\n",
    "model.eval()\n",
    "device = config.device\n",
    "model.to(device)\n",
    "def infer(img_filename, sensor):\n",
    "    try:\n",
    "        img_path = os.path.join('pictures',img_filename)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        img = pixelbert_transform(size=384)(image) # 将图像数据归一化torch.Size([3, 384, 576])\n",
    "        img = torch.tensor(img)\n",
    "        img = torch.unsqueeze(img, 0) # torch.Size([1, 3, 384, 576])\n",
    "        img = img.to(device)\n",
    "        print(\"img.shape:\",img.shape)\n",
    "    except :\n",
    "        print(\"图片加载失败！\")\n",
    "        raise\n",
    "\n",
    "    batch = dict()\n",
    "    batch[\"image\"] = img\n",
    "\n",
    "    batch['sensor_masks'] = torch.ones(1,1).to(device)\n",
    "    with torch.no_grad():\n",
    "        batch['sensor'] = sensor.to(device)       \n",
    "        infer = model(batch)\n",
    "\n",
    "        print(infer)\n",
    "        sensor_emb, img_emb = infer[\"sensor_feats\"], infer[\"image_feats\"]# torch.Size([1, 23, 768]) torch.Size([1, 217, 768])\n",
    "        cls_output = infer['cls_output']\n",
    "        \n",
    "\n",
    "    return [cls_output]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7422, 0.0631, 0.7486, 0.2106, 0.8904, 0.4381, 0.4997, 0.9500, 0.2477,\n",
      "        0.7770, 0.3519, 0.5381, 0.2060, 0.8002, 0.9734, 0.2843, 0.9574])\n",
      "img.shape: torch.Size([1, 3, 352, 608])\n",
      "{'image_feats': tensor([[[ 0.3549, -0.0411, -0.2753,  ..., -0.3269, -0.0970,  0.0171],\n",
      "         [ 0.3544, -0.0434, -0.2657,  ..., -0.3201, -0.0915,  0.0119],\n",
      "         [ 0.3188, -0.0426, -0.2969,  ..., -0.2632, -0.0357,  0.0282],\n",
      "         ...,\n",
      "         [ 0.3317, -0.0335, -0.3041,  ..., -0.3023, -0.0716,  0.0266],\n",
      "         [ 0.3445, -0.0585, -0.2269,  ..., -0.3745, -0.1150,  0.0455],\n",
      "         [ 0.3418, -0.0629, -0.2068,  ..., -0.3746, -0.1386,  0.0832]]],\n",
      "       device='cuda:0'), 'cls_feats': tensor([[-1.1051e-01, -6.7240e-02,  6.6834e-01,  1.2067e-02,  7.4169e-01,\n",
      "          8.6638e-01,  7.0650e-01,  3.4268e-01, -1.3820e-01, -1.5876e-01,\n",
      "          8.2049e-01,  7.9051e-01,  1.7966e-01, -7.4182e-01,  1.0311e-01,\n",
      "         -1.9821e-01,  8.9963e-03,  9.5318e-02, -6.4642e-03,  6.9058e-02,\n",
      "         -6.3525e-02,  7.8345e-01, -9.3507e-02,  8.0053e-01,  3.5259e-01,\n",
      "          8.1097e-01,  2.1688e-02, -8.2220e-01,  1.0181e-01, -1.5377e-03,\n",
      "          4.3633e-02,  7.9853e-01, -2.3719e-02,  4.8285e-02,  7.1446e-01,\n",
      "          7.3664e-02,  7.8067e-01,  7.1861e-02, -1.1486e-01,  6.7040e-01,\n",
      "          7.9385e-01, -8.0589e-01, -4.9001e-02, -5.7378e-02,  6.4163e-01,\n",
      "          9.0538e-03,  2.5792e-02, -7.8448e-02, -7.4742e-01,  7.6704e-02,\n",
      "         -1.6280e-01,  2.2081e-02, -2.7934e-03,  7.7672e-01,  1.0852e-01,\n",
      "          7.0406e-03,  5.0169e-03, -8.3590e-01,  7.2886e-01, -8.5018e-01,\n",
      "         -1.7019e-03,  2.4656e-02, -8.4927e-01, -1.1741e-01, -8.2041e-01,\n",
      "         -7.1297e-02,  2.3711e-01, -7.5462e-01, -8.2774e-01,  8.3617e-01,\n",
      "          7.7966e-01,  7.9894e-02,  1.1689e-01, -7.9728e-01, -2.4033e-01,\n",
      "          7.5723e-02,  8.2097e-01,  7.4908e-01,  8.0468e-01, -1.0155e-01,\n",
      "         -7.6719e-01, -2.0849e-03, -1.0805e-01, -7.4978e-01, -7.2873e-01,\n",
      "          8.4736e-01, -9.6632e-02, -1.4323e-01,  7.5922e-01, -3.6569e-02,\n",
      "         -1.9444e-01, -9.0491e-02, -4.9980e-02, -7.6879e-01, -6.1463e-02,\n",
      "         -6.9444e-01,  7.1066e-01, -5.4778e-02, -3.0662e-01, -9.6543e-02,\n",
      "         -1.1546e-01, -1.5895e-04,  7.0969e-02,  1.1757e-02,  9.4992e-02,\n",
      "         -2.9643e-01,  2.2594e-02,  8.0051e-01,  8.2994e-01,  4.3527e-02,\n",
      "          7.9772e-01, -3.7037e-02,  7.4265e-01, -1.9011e-02, -7.6630e-01,\n",
      "          8.9785e-02,  1.2193e-01, -7.8251e-01,  7.8564e-01, -1.0873e-02,\n",
      "          8.3830e-01,  4.7987e-01, -8.1908e-01,  7.5909e-01,  8.1763e-01,\n",
      "         -1.0108e-02,  7.2017e-01,  1.2160e-02,  2.9941e-01, -8.1999e-01,\n",
      "         -5.2941e-01,  7.6375e-01,  8.3267e-01, -8.0472e-01,  2.4150e-02,\n",
      "          1.0595e-02,  7.6712e-01, -2.6056e-02, -7.2199e-01,  7.9280e-01,\n",
      "         -4.8893e-02,  6.7964e-01, -8.1206e-01,  1.2458e-01,  5.3740e-02,\n",
      "         -3.1905e-02,  8.1089e-01, -1.3869e-02, -9.2837e-02, -2.9813e-01,\n",
      "         -8.6373e-01,  7.6242e-01, -4.7681e-02,  5.1750e-02,  7.0557e-01,\n",
      "         -6.8384e-01, -8.0826e-01, -1.6420e-01,  7.2453e-02, -1.6476e-01,\n",
      "          6.0516e-02, -1.5560e-02, -7.8486e-01, -1.2144e-01,  6.4291e-02,\n",
      "          5.2840e-01, -7.0797e-02,  1.1090e-01,  7.9076e-01,  1.3836e-02,\n",
      "         -7.6836e-01, -8.8865e-03, -6.0171e-01,  4.6687e-01,  6.2787e-02,\n",
      "          7.3391e-01,  1.2599e-01,  2.5228e-01,  8.2026e-01, -1.2457e-02,\n",
      "         -1.6610e-01, -8.1561e-01, -7.6559e-01,  7.7073e-01, -3.2243e-02,\n",
      "         -6.6886e-02,  2.7337e-02, -6.0675e-01,  2.1741e-01, -2.1383e-01,\n",
      "          8.2175e-01,  8.6516e-01,  2.7832e-01, -1.9668e-01,  2.4158e-02,\n",
      "         -3.1284e-02, -8.1904e-01,  1.7319e-01, -1.9442e-01,  2.0996e-01,\n",
      "         -7.8200e-01, -1.6384e-01,  2.3829e-01, -2.5453e-01, -1.9526e-01,\n",
      "         -5.2768e-01, -2.8235e-01,  1.4653e-01,  9.0813e-04,  1.3757e-01,\n",
      "         -8.2500e-01,  7.4224e-01,  7.5616e-02,  7.6557e-01, -7.8820e-01,\n",
      "          8.3056e-01,  7.0624e-01, -1.8950e-02, -2.1069e-01,  3.1423e-01,\n",
      "          3.3904e-02, -9.7196e-03, -7.9607e-01,  7.2915e-01,  2.4562e-01,\n",
      "          1.2955e-01, -7.1517e-01,  1.3816e-01, -5.8365e-01,  8.1905e-01,\n",
      "          5.0353e-02,  2.9254e-02,  1.1397e-01, -4.6749e-01,  8.0798e-01,\n",
      "         -7.8233e-01, -1.8999e-01, -7.8375e-01,  4.4461e-02, -8.0523e-01,\n",
      "         -5.4156e-03, -9.7407e-02,  5.4640e-02, -1.7994e-01, -4.0584e-02,\n",
      "          8.6296e-01,  5.5227e-02, -7.5450e-01,  1.2915e-02, -1.3288e-02,\n",
      "          1.0371e-01,  7.8655e-01,  3.0892e-03,  4.5135e-01,  1.5113e-03,\n",
      "         -8.0024e-01, -7.4700e-01, -7.9387e-01,  6.4337e-01,  2.3589e-03,\n",
      "         -7.4003e-01, -8.1526e-01, -8.2211e-01, -2.2113e-01,  8.9371e-03,\n",
      "          9.8518e-02,  1.1919e-02,  8.2506e-01,  7.9333e-01,  6.8312e-01,\n",
      "          7.3972e-04,  9.6816e-02,  1.8560e-01,  8.6286e-01, -3.9476e-03,\n",
      "         -7.9384e-01,  7.2767e-01, -9.7022e-03, -8.1788e-01, -8.0638e-01,\n",
      "          4.5638e-02,  1.4325e-01, -7.6223e-01,  7.4872e-03,  9.8954e-03,\n",
      "          7.4868e-02, -8.3558e-01,  7.8399e-01,  7.2092e-01, -3.7058e-02,\n",
      "         -2.0473e-01, -6.5940e-02,  3.7759e-02,  1.7011e-02,  3.9298e-02,\n",
      "          1.4035e-02, -5.5545e-01, -8.9289e-02,  2.3970e-02,  8.1916e-01,\n",
      "         -4.1900e-02,  7.2969e-01,  5.0533e-01, -2.3726e-02, -1.6793e-01,\n",
      "         -1.6922e-02,  1.3642e-01,  1.2860e-01, -6.6767e-01,  7.6903e-03,\n",
      "          1.5673e-01,  3.7421e-02, -4.7220e-02,  7.6328e-02,  3.9559e-01,\n",
      "          8.5619e-01,  1.6759e-01, -1.4147e-01,  1.3450e-01, -1.6564e-02,\n",
      "          1.3999e-01,  1.7517e-01,  1.1958e-01,  1.5556e-01,  4.9305e-02,\n",
      "          3.0116e-01, -3.7221e-03, -1.0041e-01, -1.1149e-01, -5.2465e-01,\n",
      "          6.2779e-03,  2.0862e-01,  3.5465e-04,  7.6700e-01, -1.0663e-01,\n",
      "         -1.5773e-01, -2.8351e-01,  6.8434e-02,  5.6318e-01, -8.1623e-01,\n",
      "         -6.9182e-01,  6.1521e-01, -1.5093e-01,  7.8783e-01, -8.1704e-02,\n",
      "          7.6744e-01,  1.0362e-01, -8.5358e-01,  7.5626e-01,  8.7571e-02,\n",
      "         -2.5910e-02, -7.4269e-01,  2.2367e-01, -7.9567e-01,  4.4996e-02,\n",
      "          2.0387e-01, -7.8958e-01, -4.1551e-01,  1.6213e-01, -7.8226e-01,\n",
      "          7.9029e-01, -8.1993e-01, -6.0979e-02,  1.5514e-01, -1.6734e-02,\n",
      "          5.3957e-01, -8.6962e-01,  7.5994e-01,  7.7105e-01, -9.9671e-03,\n",
      "         -8.2224e-01, -3.6517e-02,  9.6152e-02,  7.2159e-01,  8.0181e-01,\n",
      "         -5.6228e-02,  8.0491e-01, -1.8373e-01,  7.3572e-01, -7.4733e-01,\n",
      "          1.5170e-02, -6.9388e-02,  1.9336e-02, -7.5356e-02,  5.6106e-01,\n",
      "         -7.2411e-01,  2.2144e-01,  6.0193e-02,  8.2993e-01, -2.2226e-02,\n",
      "         -1.2372e-01, -8.0753e-02, -2.0635e-01,  6.2643e-01,  6.9077e-01,\n",
      "         -8.0680e-01, -1.0812e-01, -7.8645e-01,  2.0797e-01, -7.2371e-01,\n",
      "          8.1809e-01,  2.6581e-02,  6.1166e-02,  8.6887e-03,  4.6160e-03,\n",
      "          8.2459e-01, -8.1981e-01, -3.5874e-02,  4.5515e-02, -7.6809e-01,\n",
      "         -5.2003e-02, -1.1778e-01,  5.9494e-01, -2.7414e-02,  8.0721e-04,\n",
      "         -7.4369e-01,  8.4173e-01, -9.8342e-02, -8.1985e-01, -7.7967e-01,\n",
      "          1.4129e-02, -1.1827e-01,  7.4590e-01, -7.7226e-01, -8.2374e-01,\n",
      "          1.5065e-01, -2.7336e-02, -5.2745e-01, -1.5423e-01, -1.1206e-01,\n",
      "          6.0688e-03,  6.2443e-02,  8.6300e-01,  8.5800e-02,  3.3435e-02,\n",
      "          7.2396e-01,  1.3613e-01, -7.7494e-01,  7.8389e-03, -7.9836e-02,\n",
      "          1.3643e-03,  5.7592e-02,  8.1942e-01,  8.4564e-02, -2.8313e-02,\n",
      "         -7.7466e-01, -1.3092e-01,  2.6126e-01, -1.5995e-01,  4.9819e-02,\n",
      "          7.9930e-01, -1.9243e-02,  7.5094e-01,  6.8884e-02, -7.9224e-01,\n",
      "         -5.2882e-04, -8.5580e-01,  7.7596e-01, -7.9366e-01,  1.9127e-01,\n",
      "          7.3033e-01, -6.8311e-01, -2.7964e-04, -1.5757e-01, -3.2681e-02,\n",
      "         -1.7877e-02, -4.5028e-02,  5.8612e-01,  1.7243e-01,  5.1519e-01,\n",
      "         -7.9070e-01, -1.6492e-01, -2.5100e-03, -3.3490e-02,  8.8023e-02,\n",
      "          2.7426e-02, -8.2946e-01, -2.4557e-01,  8.4387e-01, -6.0800e-02,\n",
      "          2.1098e-03,  7.4457e-01, -9.6586e-02,  1.2861e-01,  1.0655e-01,\n",
      "          6.8849e-01,  5.3786e-01,  8.0179e-02, -4.9974e-01, -1.3518e-02,\n",
      "          2.9343e-02,  1.0585e-01,  5.1845e-02,  1.0822e-01, -7.5613e-01,\n",
      "         -7.5940e-01, -7.0275e-01,  1.8844e-02,  6.3590e-01, -2.4807e-01,\n",
      "         -1.2408e-01,  2.9067e-01, -3.3839e-01,  7.8899e-01, -7.0711e-01,\n",
      "         -4.8321e-02, -7.4106e-03,  1.3662e-01,  1.0901e-03, -7.5186e-01,\n",
      "         -4.1981e-02,  1.0894e-02,  2.1885e-01, -7.4439e-01,  6.9328e-01,\n",
      "         -1.7750e-01,  2.8491e-02, -8.2303e-01,  7.7923e-01,  7.5334e-01,\n",
      "         -8.3852e-01,  1.2585e-01, -1.3307e-01,  8.0482e-01,  1.0712e-01,\n",
      "          2.4063e-01,  3.6184e-02,  7.7605e-01,  8.8968e-02, -4.5131e-02,\n",
      "          8.0800e-01,  7.8407e-01, -2.8935e-01,  3.7134e-02,  7.6894e-04,\n",
      "         -2.6964e-03,  6.9425e-01,  7.8088e-01, -6.2578e-02,  8.1909e-01,\n",
      "          5.5913e-01, -7.6773e-01, -8.6041e-02, -3.9894e-02,  4.5889e-02,\n",
      "          8.2372e-01,  1.4434e-01, -2.6865e-01,  9.2074e-02, -7.9666e-01,\n",
      "          2.5327e-02, -7.6845e-01, -1.4440e-02,  1.8930e-01, -2.6960e-01,\n",
      "          1.3273e-01, -4.2464e-02, -2.6210e-01, -2.6097e-01, -7.8169e-01,\n",
      "         -3.2138e-01, -6.0480e-02,  2.3931e-02, -9.6902e-02, -8.2329e-01,\n",
      "          5.6228e-01,  7.7199e-01,  1.2094e-01, -6.5952e-01,  8.3597e-01,\n",
      "          7.7472e-01,  7.9243e-01,  8.2482e-01,  2.1139e-02, -1.9888e-01,\n",
      "          8.4762e-01, -1.2685e-01, -8.0528e-01, -1.7705e-02,  2.7450e-01,\n",
      "          8.1321e-01,  1.3056e-02, -7.6570e-02, -2.5630e-01,  2.7908e-01,\n",
      "          6.7400e-01, -1.1019e-01, -2.9230e-01,  7.8628e-01, -9.8269e-02,\n",
      "         -7.9644e-01,  7.2236e-02,  5.4170e-03, -2.1495e-02, -8.0259e-01,\n",
      "         -3.6497e-02,  2.0571e-02,  8.2471e-02, -8.0952e-01,  6.5781e-03,\n",
      "          8.5175e-02,  1.2232e-01,  1.4876e-02,  7.4451e-01,  8.3239e-01,\n",
      "         -4.3995e-02, -7.8889e-01,  6.3477e-01, -6.6075e-01,  1.0089e-01,\n",
      "          6.3579e-01, -7.7036e-01,  2.0290e-01, -1.0087e-01, -1.2924e-01,\n",
      "          8.0035e-01,  2.5999e-01, -1.4715e-01, -1.5171e-01,  2.4863e-01,\n",
      "          6.4199e-01, -7.2836e-01, -7.3487e-02, -7.4765e-01,  7.4420e-01,\n",
      "          8.2245e-01, -2.8432e-03,  7.6808e-02,  2.3718e-01, -8.1476e-01,\n",
      "          7.0044e-02, -5.7995e-02, -8.3093e-01,  1.0298e-01, -3.6469e-02,\n",
      "         -6.3650e-01,  3.2402e-02,  9.8700e-02,  9.2501e-03, -7.2674e-01,\n",
      "         -1.8900e-01, -1.0091e-01, -1.3557e-01, -7.6771e-01, -8.2558e-02,\n",
      "         -8.2519e-01,  8.4657e-01,  4.6467e-01, -7.4788e-02,  7.4936e-02,\n",
      "         -6.2110e-01, -1.7998e-01,  1.1201e-01,  1.9873e-01, -9.4701e-03,\n",
      "         -3.1300e-01, -1.3950e-01,  7.7339e-01, -7.6097e-01,  8.0385e-01,\n",
      "         -2.7089e-01, -1.0934e-01, -2.0628e-01,  7.8828e-01,  8.7172e-03,\n",
      "          7.6088e-01,  7.5734e-01,  4.1768e-02, -1.2559e-01, -7.6770e-01,\n",
      "         -2.7308e-02,  5.2903e-02, -6.7805e-02,  8.2549e-01,  3.0451e-02,\n",
      "         -1.0032e-02,  1.0057e-02,  6.7961e-01,  7.6803e-01, -6.3113e-02,\n",
      "         -1.1054e-01, -7.6954e-01, -1.1715e-01,  6.6363e-01,  7.2579e-01,\n",
      "          2.1164e-02,  4.8763e-03, -5.5896e-02,  8.2522e-01, -8.1290e-01,\n",
      "         -2.8154e-02,  7.6602e-01, -1.5339e-01,  1.4195e-02,  8.4869e-01,\n",
      "         -7.2873e-01, -1.5088e-03,  1.1149e-01, -6.6674e-01,  1.8561e-02,\n",
      "          2.2205e-01,  2.3036e-02, -2.9494e-02,  7.5067e-01, -7.9786e-01,\n",
      "          1.9745e-01, -6.7568e-02, -6.6001e-01, -6.0853e-01, -5.0784e-02,\n",
      "         -1.6539e-01,  5.8331e-02, -3.2895e-02, -4.6719e-02,  1.9303e-01,\n",
      "         -3.0466e-02, -2.7643e-01, -6.6728e-01,  7.6731e-01, -3.6244e-02,\n",
      "          1.1881e-01,  7.9546e-01,  7.7909e-03,  3.1959e-02,  7.5914e-01,\n",
      "         -5.7850e-02,  1.4017e-01,  6.9877e-03, -6.4794e-01,  8.4509e-01,\n",
      "          1.3065e-01, -7.2656e-01,  2.9443e-01, -8.1316e-01,  8.0051e-01,\n",
      "         -4.6918e-02, -1.2958e-01,  5.9525e-01, -7.5841e-01,  7.8398e-01,\n",
      "          2.7752e-02,  6.3690e-02,  9.7745e-02, -6.2172e-02, -3.3385e-02,\n",
      "         -1.3628e-01, -1.0050e-02,  8.3592e-01, -1.0548e-01, -8.4721e-01,\n",
      "          7.2606e-01, -3.7944e-02,  6.9653e-01, -8.1451e-01, -9.1934e-02,\n",
      "          2.5172e-02, -2.7764e-02, -7.7381e-03, -8.1976e-01,  8.2719e-01,\n",
      "         -7.1315e-01, -6.4860e-01, -2.1033e-02,  8.5371e-01,  7.1894e-01,\n",
      "          7.9079e-01, -8.7131e-02, -1.3245e-01]], device='cuda:0'), 'raw_cls_feats': tensor([[ 3.5489e-01, -4.1134e-02, -2.7526e-01, -8.7750e-01,  6.7980e-02,\n",
      "          3.0993e-01,  3.9715e-01, -7.6749e-01,  5.3743e-01, -7.2470e-02,\n",
      "          3.0402e-01,  1.1581e+00,  1.6177e-01,  3.0843e-02, -6.6631e-01,\n",
      "         -1.2375e-01, -8.0102e-01,  1.8169e-01, -4.5628e-01, -4.4279e-01,\n",
      "          5.2932e-01,  7.9123e-01,  4.7422e-01, -8.9756e-02,  2.3815e-01,\n",
      "          9.6916e-02,  2.6868e-01, -2.1485e-01,  1.6434e-01, -4.5841e-01,\n",
      "         -5.1496e-02, -4.7701e-01,  1.7781e-01,  2.8853e-01,  1.3260e-01,\n",
      "         -3.7962e-01, -3.2185e-01, -1.6098e-01, -3.4585e-01,  5.7788e-01,\n",
      "         -7.0904e-02, -4.0988e-01, -5.5215e-01,  6.4845e-01,  1.8803e-01,\n",
      "          1.6917e-01,  1.4853e-01,  8.9460e-02, -2.9416e-01,  8.5341e-02,\n",
      "          3.0606e-01, -2.6933e-02, -2.7208e-01, -3.9427e-01,  3.6969e-01,\n",
      "          1.4549e-01, -2.4571e-01,  1.6904e-01,  4.3257e-02,  4.5505e-01,\n",
      "          3.8699e-01,  2.2187e-01, -3.3785e-01, -1.6093e-01,  3.3497e-01,\n",
      "         -1.0592e+00,  5.2425e-02, -2.1826e-01,  4.2850e-01,  7.0848e-01,\n",
      "         -3.7433e-02,  1.6198e-01, -3.8195e-01, -8.8607e-01,  8.9637e-01,\n",
      "         -4.7632e-01,  2.7596e-01, -4.3313e-01, -6.0511e-01, -2.0134e-01,\n",
      "          5.2926e-01,  6.2173e-01, -1.0106e+00, -5.5216e-02, -1.9894e-01,\n",
      "          6.5700e-01, -2.3668e-02,  5.4443e-01, -7.2311e-01, -2.8352e-01,\n",
      "          1.3646e+00,  2.2740e-01, -2.3719e-01, -3.2545e-01, -1.2261e-01,\n",
      "          3.8506e-02, -6.8709e-01,  6.0712e-01,  1.1349e-01, -1.1112e-01,\n",
      "         -4.5905e-01, -4.2295e-01,  6.2629e-01, -3.8567e-01,  3.1285e-01,\n",
      "         -1.8711e-03,  7.5655e-01, -3.9926e-01,  2.9129e-01, -5.7388e-01,\n",
      "         -6.7075e-02,  1.3666e-01, -3.9355e-01,  2.3275e-01, -1.4496e-02,\n",
      "          1.4117e-01,  1.2414e-01, -4.1589e-01, -1.9855e-01,  7.0134e-02,\n",
      "         -5.4721e-01,  7.9819e-03, -2.2470e-01, -6.4894e-01, -7.1910e-01,\n",
      "          1.3165e+00,  3.9579e-01, -1.9396e-01, -8.1897e-01,  3.2124e-01,\n",
      "         -9.5081e-02,  1.3463e-01,  4.9991e-01, -9.4561e-01, -7.0233e-01,\n",
      "          8.7233e-03,  8.3170e-03,  7.0501e-02, -3.7007e-01, -1.2259e-01,\n",
      "         -5.0552e-01,  7.6702e-01, -3.5471e-01,  6.0657e-01, -4.0382e-01,\n",
      "         -4.5677e-01,  1.2477e-02,  3.6150e-01,  2.7089e-02,  4.8992e-01,\n",
      "         -1.2913e-02,  4.7334e-01, -9.9222e-01,  7.1896e-02,  3.4034e-01,\n",
      "          6.4627e-02,  7.0180e-01,  5.5803e-01, -4.5536e-01, -6.6856e-01,\n",
      "          7.7131e-01,  6.7159e-02, -6.3359e-01,  8.3340e-02, -4.5267e-01,\n",
      "          2.5939e-01,  5.3607e-01,  3.1247e-01, -3.8264e-01, -6.4611e-02,\n",
      "         -1.0016e-01, -1.4560e-02,  8.2473e-02,  7.2907e-01, -2.4043e-01,\n",
      "         -3.7214e-01, -6.3684e-02, -2.3585e-01, -1.6034e-01, -1.9883e-01,\n",
      "         -6.9894e-01, -4.9947e-01,  2.8343e-01,  4.9258e-01, -5.4387e-02,\n",
      "          3.2298e-01, -1.1313e+00, -3.5488e-01,  3.3174e-01, -1.7429e-01,\n",
      "         -4.3302e-01, -9.4488e-02,  2.1814e-02, -6.2183e-01,  1.2220e-01,\n",
      "          4.4484e-01,  2.7029e-01, -5.4679e-02, -4.8092e-01,  7.3322e-01,\n",
      "         -2.7660e-01, -9.5061e-01, -5.8440e-01, -1.4171e-01, -3.4900e-01,\n",
      "          3.6408e-01,  1.6304e-01, -6.2341e-02, -1.1178e+00,  4.2205e-01,\n",
      "          9.9012e-02,  9.7076e-01, -9.1780e-01,  4.0801e-01, -4.4567e-01,\n",
      "         -2.6638e-01,  9.8529e-01,  2.3605e-01, -2.5339e-01, -1.1650e-01,\n",
      "         -1.7053e-01,  8.9921e-02, -6.9287e-01, -1.3356e-01, -3.4847e-01,\n",
      "         -5.6630e-01, -5.3667e-01, -1.0493e-01, -1.5600e-01,  8.8421e-02,\n",
      "          4.5782e-01,  6.0930e-01,  7.8739e-01,  5.9160e-01,  1.6812e-01,\n",
      "          1.8780e-01,  7.7977e-01,  3.2524e-02, -5.4029e-02,  7.6281e-02,\n",
      "         -9.6768e-02, -6.9575e-02,  1.4189e-01,  4.1982e-01,  2.7400e-02,\n",
      "          8.8793e-01, -3.3656e-01, -7.5767e-02, -7.3455e-02, -2.8181e-01,\n",
      "         -3.8200e-01,  1.3561e-01, -5.1827e-01,  3.6069e-01,  7.9252e-01,\n",
      "         -2.5418e-01,  2.6767e-02,  3.0460e-01, -4.0732e-02,  3.7415e-01,\n",
      "         -1.2074e+00,  2.0786e-01, -7.3277e-01,  6.0776e-02, -1.9658e-01,\n",
      "         -2.5216e-01,  2.3013e-01,  2.6930e-01,  6.6833e-01,  1.9307e-01,\n",
      "          6.2759e-02, -2.3990e-01, -6.7783e-01,  5.3903e-01, -6.0887e-01,\n",
      "         -7.8009e-01, -2.5054e-01,  8.3238e-02,  3.9838e-01, -3.8195e-01,\n",
      "          5.9611e-01,  4.1977e-02,  8.6904e-01, -1.1159e-02,  3.3030e-02,\n",
      "          1.9494e-01,  2.5089e-01,  1.9745e-01,  6.9291e-01,  3.8216e-01,\n",
      "         -1.4746e-01, -2.1860e-01,  5.1892e-01, -7.0327e-01,  5.2241e-02,\n",
      "          5.5150e-01,  2.3448e-01,  4.7255e-01,  3.0325e-01, -2.1076e-01,\n",
      "         -5.6471e-01, -4.6084e-01, -6.0314e-01,  1.4822e-01, -2.3151e-01,\n",
      "         -1.2601e-01,  2.1470e-02, -4.7302e-01,  2.6324e-01, -1.4905e-01,\n",
      "         -8.3039e-01,  4.0654e-01,  5.4696e-01,  6.3885e-01, -6.7350e-01,\n",
      "         -1.0555e+00, -3.0217e-01, -3.3150e-01,  6.6441e-01, -7.8591e-01,\n",
      "          2.5043e-02, -9.0837e-03, -5.4493e-01,  1.1560e-01, -2.1961e-01,\n",
      "         -4.1877e-01,  6.6870e-01, -4.0663e-01, -5.8124e-01, -6.6895e-01,\n",
      "         -4.2650e-01, -4.5722e-01, -1.9530e-01, -2.6783e-02,  1.2473e+00,\n",
      "          2.6435e-01, -6.2696e-04,  5.5256e-01,  5.2602e-01, -4.4811e-01,\n",
      "          2.4344e-01, -2.1367e-01,  3.3697e-01, -7.9546e-01,  6.8947e-02,\n",
      "          8.0526e-02,  4.2116e-01, -8.9083e-02,  2.6425e-01, -6.8232e-01,\n",
      "          4.4467e-02, -1.1066e+00,  5.6053e-01,  8.1443e-02,  5.5211e-01,\n",
      "          5.5193e-01,  1.7467e-03, -3.6806e-01, -4.2674e-01,  1.7984e-02,\n",
      "         -6.2472e-01,  1.2389e-01,  1.7091e-01, -6.3533e-01,  8.3452e-01,\n",
      "          2.2050e-01, -4.3032e-03, -8.6737e-02, -2.6707e-01,  3.5556e-02,\n",
      "          1.0977e+00,  6.6880e-01, -8.6288e-01, -3.6798e-01,  2.2939e-01,\n",
      "         -1.0310e+00, -5.7204e-01, -1.1626e-01, -7.0020e-01,  1.6373e-01,\n",
      "          5.0241e-01,  1.9518e-01,  7.4155e-01, -6.5431e-02,  2.5087e-01,\n",
      "          1.4842e-01, -4.2359e-01, -9.5244e-01, -1.1307e-01,  6.0956e-01,\n",
      "          2.9937e-01,  2.9182e-01,  1.0460e-01,  4.8915e-01,  9.4468e-01,\n",
      "         -1.1114e-01,  1.0483e+00,  5.8955e-01,  2.8723e-01, -1.2268e-01,\n",
      "          1.6990e-01,  1.2473e+00,  7.2669e-01,  2.6571e-01, -4.6596e-01,\n",
      "         -6.3278e-01, -5.4448e-01,  9.4000e-01, -8.2940e-01,  1.8666e-01,\n",
      "          9.2382e-01,  1.5644e-01, -1.4024e-01,  4.2533e-01, -1.0052e-01,\n",
      "         -5.6182e-01,  5.7353e-01, -5.8028e-01, -6.7367e-02, -9.4115e-01,\n",
      "         -5.5842e-02,  3.2093e-01,  1.7525e-01,  7.0758e-01,  6.8629e-01,\n",
      "          1.2023e+00,  4.3219e-02, -8.8733e-02, -7.2785e-01, -4.8292e-01,\n",
      "         -4.2907e-01,  1.0585e-02,  6.9565e-02,  6.2581e-01,  6.9744e-01,\n",
      "         -8.9352e-02,  3.9699e-01, -5.7254e-01, -7.0381e-01,  8.5795e-02,\n",
      "          3.6437e-01, -2.1141e-01,  4.5573e-01, -8.7085e-01, -2.4835e-01,\n",
      "         -1.1313e+00,  2.1895e-01,  3.6093e-01, -5.8327e-01, -5.7153e-01,\n",
      "         -5.1269e-01, -7.1864e-01,  1.9292e-01,  6.5362e-01,  3.0836e-01,\n",
      "         -3.4385e-01, -1.7748e-01,  1.2529e-01,  8.7050e-01, -3.3513e-01,\n",
      "         -1.0739e-01,  1.8660e-01, -1.0179e+00, -6.5652e-01,  7.6853e-01,\n",
      "         -3.3200e-01,  3.1703e-01,  3.6246e-01,  1.2663e-01,  4.2829e-01,\n",
      "         -7.2820e-02,  1.2914e-01, -9.5089e-01,  5.0429e-01,  1.3870e-01,\n",
      "         -7.2615e-01, -2.9555e-01,  3.3689e-01, -2.7624e-01,  1.1043e+00,\n",
      "         -5.9680e-01,  1.6519e-01,  1.2587e-01,  2.1548e-01, -1.5248e+00,\n",
      "          6.6331e-02,  6.2712e-01,  2.6684e-01,  9.7245e-01,  3.2201e-01,\n",
      "         -5.9012e-01, -7.3055e-02, -9.3811e-02,  5.5205e-02, -6.6163e-01,\n",
      "          9.2334e-03,  2.1013e-01, -1.4552e-01, -4.6962e-02, -6.9324e-01,\n",
      "          1.7060e-01, -4.4048e-01, -4.5476e-01,  3.5393e-01, -8.5478e-02,\n",
      "         -5.8190e-01, -4.9094e-01,  6.0166e-02,  8.3119e-02, -7.9897e-01,\n",
      "         -4.4402e-01,  2.1538e-01,  4.9356e-01,  1.4453e-02, -5.0128e-02,\n",
      "          1.5205e-01,  5.5160e-02,  1.8763e-01,  7.9227e-01,  4.3725e-01,\n",
      "          1.5431e-01,  7.1619e-01, -6.4495e-01,  4.0855e-02, -7.6289e-01,\n",
      "          3.1357e-01, -9.5260e-03,  3.8148e-01, -8.9926e-01, -5.2499e-01,\n",
      "          2.4361e-01,  7.0723e-01,  2.3616e-01,  5.4876e-01,  2.7510e-01,\n",
      "          4.4455e-01, -3.2681e-01,  5.1869e-02,  1.0672e+00, -3.1642e-01,\n",
      "          8.2728e-01,  6.3722e-01,  5.4445e-02, -1.7821e-01, -2.5071e-01,\n",
      "         -2.0299e-01, -2.6465e-01, -2.0373e-01, -3.1213e-02,  4.5763e-01,\n",
      "          1.9836e-01, -4.4944e-02,  2.3030e-01, -2.4885e-01, -3.2058e-01,\n",
      "          2.5899e-01, -4.2656e-01, -4.0257e-02,  6.3692e-01, -1.2709e+00,\n",
      "          9.3385e-02, -4.2578e-01, -4.1320e-01,  3.4859e-01,  5.5305e-01,\n",
      "         -2.8866e-01, -3.0488e-01,  8.2563e-02, -4.5109e-01,  5.6193e-01,\n",
      "         -3.7796e-01,  5.9856e-02,  5.4909e-01, -8.4421e-02, -4.2756e-01,\n",
      "         -5.8584e-01, -4.9895e-01, -1.6223e-01, -1.8430e-01,  2.9065e-01,\n",
      "         -3.0859e-01,  3.0260e-01, -3.6456e-01,  6.6869e-02,  2.2964e-02,\n",
      "          1.2373e-01, -4.2327e-01, -3.3892e-01, -9.8374e-01, -4.4626e-01,\n",
      "         -3.8854e-02,  1.0298e+00, -7.2130e-01,  7.0885e-01, -5.1722e-02,\n",
      "         -6.8433e-01,  8.3748e-01,  5.8037e-02, -9.2980e-02, -9.7654e-02,\n",
      "         -7.7283e-01,  9.9662e-03, -1.2155e-01,  1.1052e+00,  2.1482e-01,\n",
      "         -6.5894e-01,  4.0965e-01, -9.7042e-01, -6.9801e-02,  2.7911e-01,\n",
      "         -1.7742e-01,  3.0620e-01,  3.5111e-01, -7.8713e-01, -8.7654e-01,\n",
      "         -4.7032e-01,  4.8497e-01,  3.1350e-02,  1.3219e-01,  1.7454e-01,\n",
      "         -2.0238e-01,  6.4542e-01, -4.0847e-01, -1.1493e+00, -1.5873e-01,\n",
      "          9.7027e-01, -5.5932e-02, -5.8455e-01,  1.8032e-01,  1.7845e-01,\n",
      "          1.6618e-01,  7.0984e-01, -3.2761e-01,  7.9067e-01,  6.2683e-01,\n",
      "         -5.3577e-01, -3.3202e-01,  1.0873e+00, -3.4965e-01, -2.3462e-01,\n",
      "          2.1302e-01,  1.0590e+00,  6.3450e-01,  1.6874e-01, -1.2456e-02,\n",
      "          4.9740e-01,  4.0665e-01,  4.2031e-01,  1.7801e-01,  4.3889e-01,\n",
      "          1.8035e-01, -8.2098e-01, -8.9344e-01, -2.1994e-01, -6.8119e-01,\n",
      "         -1.8951e-01,  7.9128e-01, -8.4458e-02, -3.8766e-04,  2.8507e-01,\n",
      "         -2.6816e-01, -9.2945e-02, -8.5785e-02,  5.6324e-02,  1.6193e-01,\n",
      "         -8.0036e-01,  1.1099e-01, -3.5875e-02,  5.4976e-01, -1.3869e-01,\n",
      "         -3.1177e-01,  4.2629e-01,  2.3530e-01, -7.8356e-01,  2.7417e-02,\n",
      "         -6.4050e-02,  6.3978e-01,  5.3641e-01,  6.5303e-01,  2.5205e-01,\n",
      "          7.8802e-02,  3.7553e-02, -5.8332e-01,  9.2676e-03, -3.7366e-01,\n",
      "          4.2378e-02, -7.2885e-02,  5.0597e-01,  6.7262e-01,  2.7614e-01,\n",
      "         -4.2003e-01, -3.5521e-02, -4.9873e-01, -1.0141e+00,  4.9901e-01,\n",
      "          1.5041e-01,  1.1120e+00, -2.8078e-01, -5.5844e-01,  2.3866e-01,\n",
      "         -3.3214e-01, -1.9439e-02, -9.7556e-02, -7.2952e-01, -7.4949e-02,\n",
      "          3.8229e-01, -1.5159e+00, -2.2469e-01, -2.8887e-01,  4.6923e-01,\n",
      "          4.1234e-01, -2.9033e-01, -5.7912e-01,  6.4877e-01, -4.3839e-01,\n",
      "         -3.8998e-01,  6.8833e-03, -1.7306e-01, -7.9766e-01, -1.5462e+00,\n",
      "          7.8052e-01, -7.2211e-01,  1.4715e-01,  5.8215e-01, -5.6079e-01,\n",
      "          9.7403e-01, -2.3353e-02,  9.1976e-02,  4.6832e-01, -7.0045e-01,\n",
      "         -4.6077e-01, -4.5716e-01,  1.5190e-01, -6.5950e-01,  5.7146e-01,\n",
      "          2.8092e-01, -4.2257e-01,  5.1815e-01,  5.8435e-01,  6.2352e-01,\n",
      "         -4.7454e-02,  6.6192e-01,  3.0161e-02,  3.3208e-01, -1.1933e-01,\n",
      "          7.5050e-01, -4.5174e-02, -7.6478e-01, -8.2852e-01,  5.6270e-01,\n",
      "          2.1548e-01, -3.5119e-01,  7.4000e-01,  2.0953e-01,  3.2744e-01,\n",
      "          8.2053e-01,  6.9430e-01,  4.4394e-01,  2.5057e-01,  7.1677e-01,\n",
      "          1.3426e-01, -5.8836e-01,  7.3650e-01,  3.4434e-01,  1.6257e-01,\n",
      "         -3.2691e-01, -9.7022e-02,  1.7118e-02]], device='cuda:0'), 'image_labels': None, 'image_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0'), 'patch_index': (tensor([[[ 2, 16],\n",
      "         [ 8, 10],\n",
      "         [ 2,  7],\n",
      "         [ 9,  9],\n",
      "         [ 2,  9],\n",
      "         [ 4,  3],\n",
      "         [ 7, 16],\n",
      "         [ 2, 14],\n",
      "         [ 8, 15],\n",
      "         [ 2, 17],\n",
      "         [ 0, 13],\n",
      "         [ 3, 11],\n",
      "         [ 5, 10],\n",
      "         [ 9, 11],\n",
      "         [ 2, 10],\n",
      "         [ 6,  3],\n",
      "         [ 9,  7],\n",
      "         [ 7,  9],\n",
      "         [ 4,  4],\n",
      "         [ 7,  7],\n",
      "         [ 9, 10],\n",
      "         [ 8, 12],\n",
      "         [ 3, 13],\n",
      "         [ 0,  7],\n",
      "         [ 1, 18],\n",
      "         [ 0, 16],\n",
      "         [ 3, 18],\n",
      "         [ 4,  1],\n",
      "         [ 0, 14],\n",
      "         [ 1,  8],\n",
      "         [ 1,  4],\n",
      "         [ 5, 12],\n",
      "         [ 9, 18],\n",
      "         [ 8,  9],\n",
      "         [ 7,  4],\n",
      "         [ 6,  1],\n",
      "         [ 8,  8],\n",
      "         [ 3, 12],\n",
      "         [ 5,  1],\n",
      "         [ 2,  8],\n",
      "         [ 2,  5],\n",
      "         [ 6, 14],\n",
      "         [ 3,  2],\n",
      "         [ 1, 11],\n",
      "         [ 2, 13],\n",
      "         [ 7, 13],\n",
      "         [ 8, 17],\n",
      "         [ 5, 14],\n",
      "         [ 1, 14],\n",
      "         [ 5, 15],\n",
      "         [ 2,  4],\n",
      "         [ 7, 15],\n",
      "         [ 4, 12],\n",
      "         [10, 18],\n",
      "         [ 9,  1],\n",
      "         [ 7, 14],\n",
      "         [ 1,  5],\n",
      "         [ 3,  4],\n",
      "         [ 8, 18],\n",
      "         [ 5, 16],\n",
      "         [ 8,  2],\n",
      "         [ 0,  0],\n",
      "         [ 1, 17],\n",
      "         [ 6,  6],\n",
      "         [ 4, 14],\n",
      "         [ 7,  0],\n",
      "         [ 2,  6],\n",
      "         [10,  6],\n",
      "         [ 9, 13],\n",
      "         [ 0,  8],\n",
      "         [ 7, 12],\n",
      "         [ 7, 11],\n",
      "         [ 1,  6],\n",
      "         [ 6, 12],\n",
      "         [ 0, 12],\n",
      "         [ 9,  0],\n",
      "         [ 9, 14],\n",
      "         [ 3,  6],\n",
      "         [ 6,  9],\n",
      "         [ 7,  5],\n",
      "         [ 7,  8],\n",
      "         [ 1, 15],\n",
      "         [ 6, 13],\n",
      "         [ 0, 17],\n",
      "         [ 7, 17],\n",
      "         [ 7,  2],\n",
      "         [ 6,  0],\n",
      "         [ 0,  3],\n",
      "         [ 0, 11],\n",
      "         [10,  8],\n",
      "         [ 5,  4],\n",
      "         [ 4, 15],\n",
      "         [ 2,  2],\n",
      "         [ 0,  5],\n",
      "         [10, 13],\n",
      "         [10,  9],\n",
      "         [ 1,  7],\n",
      "         [ 3, 17],\n",
      "         [ 3,  0],\n",
      "         [ 5, 17],\n",
      "         [ 4,  7],\n",
      "         [ 8,  1],\n",
      "         [ 1, 10],\n",
      "         [ 1,  2],\n",
      "         [ 9,  2],\n",
      "         [ 3, 15],\n",
      "         [ 2, 15],\n",
      "         [ 6,  2],\n",
      "         [ 3,  9],\n",
      "         [ 4, 13],\n",
      "         [ 5,  6],\n",
      "         [ 5,  0],\n",
      "         [ 1, 12],\n",
      "         [10,  3],\n",
      "         [ 7,  6],\n",
      "         [10,  5],\n",
      "         [10, 15],\n",
      "         [ 7,  3],\n",
      "         [ 6, 11],\n",
      "         [ 2, 12],\n",
      "         [ 3,  7],\n",
      "         [ 9,  4],\n",
      "         [ 8,  0],\n",
      "         [10,  0],\n",
      "         [ 6, 15],\n",
      "         [ 6,  5],\n",
      "         [ 4,  5],\n",
      "         [10, 11],\n",
      "         [ 4, 17],\n",
      "         [ 4,  8],\n",
      "         [ 8, 13],\n",
      "         [ 8, 16],\n",
      "         [ 2,  1],\n",
      "         [ 4, 16],\n",
      "         [ 5,  5],\n",
      "         [ 1, 13],\n",
      "         [ 5,  3],\n",
      "         [ 4, 18],\n",
      "         [ 0, 15],\n",
      "         [ 0,  1],\n",
      "         [ 0, 18],\n",
      "         [10, 12],\n",
      "         [ 4,  0],\n",
      "         [ 8,  3],\n",
      "         [ 9, 15],\n",
      "         [10, 14],\n",
      "         [ 1,  9],\n",
      "         [10,  2],\n",
      "         [ 7,  1],\n",
      "         [ 5,  2],\n",
      "         [ 1,  0],\n",
      "         [ 0,  2],\n",
      "         [ 9,  6],\n",
      "         [ 7, 18],\n",
      "         [ 6, 16],\n",
      "         [ 8,  4],\n",
      "         [ 6, 10],\n",
      "         [ 3,  5],\n",
      "         [ 6,  8],\n",
      "         [ 8,  5],\n",
      "         [ 4,  6],\n",
      "         [ 9,  8],\n",
      "         [ 4, 11],\n",
      "         [ 2, 18],\n",
      "         [ 8, 11],\n",
      "         [10,  7],\n",
      "         [ 9, 16],\n",
      "         [ 3, 10],\n",
      "         [ 0,  6],\n",
      "         [ 0, 10],\n",
      "         [10, 17],\n",
      "         [ 8,  7],\n",
      "         [ 3,  1],\n",
      "         [ 9,  5],\n",
      "         [10, 16],\n",
      "         [ 8,  6],\n",
      "         [ 5, 13],\n",
      "         [ 8, 14],\n",
      "         [ 9,  3],\n",
      "         [ 1, 16],\n",
      "         [ 2,  0],\n",
      "         [ 5, 18],\n",
      "         [ 6,  7],\n",
      "         [ 3,  3],\n",
      "         [ 7, 10],\n",
      "         [ 1,  3],\n",
      "         [10, 10],\n",
      "         [ 3, 14],\n",
      "         [ 4,  2],\n",
      "         [10,  4],\n",
      "         [ 3, 16],\n",
      "         [ 2,  3],\n",
      "         [ 9, 12],\n",
      "         [ 4,  9],\n",
      "         [10,  1],\n",
      "         [ 0,  4],\n",
      "         [ 9, 17],\n",
      "         [ 3,  8],\n",
      "         [ 5, 11],\n",
      "         [ 6,  4],\n",
      "         [ 5,  7],\n",
      "         [ 6, 18],\n",
      "         [ 5,  9],\n",
      "         [ 2, 11],\n",
      "         [ 1,  1],\n",
      "         [ 4, 10],\n",
      "         [ 6, 17],\n",
      "         [ 0,  9],\n",
      "         [ 5,  8]]]), (11, 19)), 'cls_output': tensor([[0.0790]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_388755/3499233738.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sensor =  torch.tensor(sensor).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 3])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sensor_feats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb Cell 59\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(sensor)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m sensor \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mtensor(sensor)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39m# torch.Size([1, 1, 3])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m out \u001b[39m=\u001b[39m infer(examples[\u001b[39m0\u001b[39;49m],sensor)\n",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb Cell 59\u001b[0m in \u001b[0;36minfer\u001b[0;34m(img_filename, sensor)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     infer \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mprint\u001b[39m(infer)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     sensor_emb, img_emb \u001b[39m=\u001b[39m infer[\u001b[39m\"\u001b[39;49m\u001b[39msensor_feats\u001b[39;49m\u001b[39m\"\u001b[39;49m], infer[\u001b[39m\"\u001b[39m\u001b[39mimage_feats\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m# torch.Size([1, 23, 768]) torch.Size([1, 217, 768])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     cls_output \u001b[39m=\u001b[39m infer[\u001b[39m'\u001b[39m\u001b[39mcls_output\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [cls_output]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sensor_feats'"
     ]
    }
   ],
   "source": [
    "\n",
    "examples=[\n",
    "            \"/home/junsheng/data/xiangguan/pic/xiangguanD4-2021-05-24-10-00-25.jpeg\", #0\n",
    "            \n",
    "            \"/home/junsheng/data/xiangguan/pic/xiangguanD4-2021-07-18-04-22-30-preset-18.jpeg\", # 3\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "n = 1\n",
    "sensor = torch.rand(config.senser_input_num)\n",
    "# sensor = torch.ones(config.senser_input_num)\n",
    "print(sensor)\n",
    "sensor =  torch.tensor(sensor).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 3])\n",
    "out = infer(examples[0],sensor)\n",
    "# print(\"out:\",out,\"000\\n\")\n",
    "# print(\"out0.shape:\",out[0].shape)\n",
    "# cv2.imwrite('output.png',out[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.8166]], device='cuda:0')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8166\n"
     ]
    }
   ],
   "source": [
    "print(out[0].cpu().numpy()[0][0])\n",
    "#0.00031266143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test by valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择三组生长期不同的数据去验证训练的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.query(\"fold==0\").reset_index(drop=True)\n",
    "df_test.to_csv(\"test_by_valid.csv\",index=False)\n",
    "sensor_test_list = df_test.sensor.tolist()\n",
    "image_test_list = df_test.image_path.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: torch.Size([1, 3, 352, 608])\n",
      "{'sensor_feats': tensor([[[ 2.7024e-01,  8.4886e-01,  3.5035e-01,  5.3281e-02,  5.2474e-02,\n",
      "          -1.7046e-01,  7.3329e-02,  3.0590e-02,  6.7037e-02, -3.7755e-01,\n",
      "          -8.7652e-01,  1.3844e-01,  2.5090e-01, -3.3451e-01, -1.6991e-01,\n",
      "          -2.3502e-02, -6.9722e-02, -1.1445e-01, -1.7391e-01,  3.5070e-01,\n",
      "          -1.2979e+00,  2.7135e-01, -6.4320e-02, -9.8884e-01,  3.2600e-02,\n",
      "          -4.4981e-01,  1.7270e-01,  3.7485e-01, -8.4396e-01, -6.4098e-02,\n",
      "           1.6703e-01,  3.6598e-01, -4.2784e-02, -1.1087e-01,  1.1336e-02,\n",
      "          -2.0030e+00, -7.8494e-01, -9.4766e-02, -1.2019e-01,  1.6362e-01,\n",
      "          -1.2572e-01,  2.2219e-01, -3.8874e-02,  6.9456e-01, -6.6659e-01,\n",
      "          -7.5572e-02, -6.5935e-02, -2.7468e-02,  1.0221e+00, -2.5591e-01,\n",
      "           1.8912e-01, -5.2756e-01,  4.2142e-02,  1.3391e+00,  6.7435e-02,\n",
      "           9.3807e-01,  1.4467e+00,  4.8933e-01,  2.6360e-01, -6.8080e-02,\n",
      "           1.7264e-01,  7.1070e-02,  3.0559e-01,  1.0487e+00, -1.0531e-01,\n",
      "           1.4899e-01, -1.4601e-01,  7.0311e-02, -6.1047e-01,  3.2517e-01,\n",
      "           9.6615e-02, -4.9635e-01,  3.9653e-01, -8.1497e-01,  4.3536e-01,\n",
      "          -1.7965e-01, -1.8054e-02, -7.7346e-02,  3.7056e-01, -1.1527e-01,\n",
      "          -5.1328e-02,  2.2571e-01, -1.4052e-01,  3.9916e-01, -1.5368e+00,\n",
      "          -2.2687e-01,  6.8785e-01,  4.7555e-03,  4.0235e-01, -3.9818e-01,\n",
      "           4.5255e-01,  1.8249e-01,  2.4254e-02,  5.4363e-01,  3.1668e-01,\n",
      "           1.4741e-01, -1.2045e+00,  5.6026e-01,  1.8129e-02, -5.2342e-01,\n",
      "          -2.5647e-01, -5.9585e-01,  1.6685e-01, -2.0819e-01, -2.7393e-01,\n",
      "          -5.4547e-02,  8.3671e-01,  1.0122e+00,  3.0082e-01, -4.0947e-01,\n",
      "          -3.5765e-01, -8.6501e-04,  1.6294e-01, -4.0080e-01, -8.3902e-01,\n",
      "           2.2061e-01, -4.1820e-02, -4.1544e-01, -2.5201e+00, -9.8932e-02,\n",
      "          -5.8175e-01, -7.2491e-02, -8.2113e-01, -1.3048e-01, -4.9790e-01,\n",
      "          -2.5302e-01,  9.9828e-02,  3.8401e-01, -1.0704e-01, -1.3460e-01,\n",
      "          -5.2490e-01,  1.6422e-01, -7.2538e-02,  3.1729e-01, -1.8784e-01,\n",
      "           8.4847e-01,  2.7782e-01,  3.9456e-01,  7.3581e-01, -4.6038e-01,\n",
      "          -1.2405e-01,  3.6507e-01,  1.0595e+00, -3.3720e-01, -1.7847e-01,\n",
      "           6.9445e-02,  5.5660e-02,  6.6612e-01, -1.5342e-01, -1.0245e-01,\n",
      "          -4.1698e-01, -4.7990e-01, -4.3741e-02,  7.5446e-01, -8.5839e-01,\n",
      "          -2.9759e-01,  7.4105e-02,  3.6936e-01,  2.2517e-01,  2.0445e-01,\n",
      "          -2.2520e-01, -7.0262e-01,  1.7491e+00,  1.5410e-01,  2.4333e-01,\n",
      "           1.1808e-01,  2.0031e-01, -4.1765e-01, -4.4570e-02, -7.5414e-02,\n",
      "          -1.7943e-01,  2.9114e-01, -5.1989e-01,  5.7214e-02,  3.4968e-03,\n",
      "          -5.4809e-02,  9.5891e-02, -1.0574e-01,  1.3325e-01,  6.3144e-01,\n",
      "           5.8261e-02, -5.3787e-01,  4.9443e-01,  8.5900e-01,  3.4082e-02,\n",
      "           8.8916e-04, -2.6900e-02,  2.4115e-01,  3.4658e-01, -6.3444e-02,\n",
      "           1.6090e-01,  6.9500e-01, -3.7949e-01,  1.2788e-01,  1.5003e-01,\n",
      "          -4.2237e-02, -2.5673e-01, -3.3161e-01, -2.3348e-01,  5.5662e-01,\n",
      "          -4.5105e-01,  1.1752e-01,  5.5362e-01,  1.0310e+00,  5.0748e-03,\n",
      "          -1.2152e+00, -4.7172e-01,  1.2711e-01,  6.1709e-02,  4.8978e-01,\n",
      "           2.5862e-01, -1.6091e-01, -2.9285e-01, -2.4275e-01,  3.7013e-01,\n",
      "          -6.4637e-01,  4.7067e-01, -1.3941e-01,  8.2075e-02, -4.9278e-02,\n",
      "          -2.3442e-01,  2.8614e-01, -2.1160e-01, -1.1124e+00,  9.2892e-01,\n",
      "           3.1191e-01,  8.5168e-02,  1.1483e-01,  8.2778e-01,  3.2094e-01,\n",
      "          -4.2826e-01, -4.3217e-01,  9.0470e-02,  1.4781e-01,  6.4168e-01,\n",
      "          -4.0168e-01, -3.3907e-01,  1.7142e-01, -1.4673e-01,  8.6523e-02,\n",
      "          -4.7792e-03, -1.9192e-01, -3.2239e-01, -2.2403e-01, -2.6295e-02,\n",
      "          -1.5122e-01,  6.5477e-02,  1.5560e-01,  1.1998e-01,  1.4690e-01,\n",
      "           5.6724e-01, -9.5334e-01,  1.0883e-01, -4.6437e-01, -2.8476e-01,\n",
      "          -2.8313e-01,  5.9793e-01, -1.3925e+00,  5.2537e-02,  1.7755e-01,\n",
      "           4.5361e-02,  1.0916e-01, -1.9150e-01, -1.3015e-01, -5.1746e-01,\n",
      "          -5.5892e-01, -1.6779e-01,  9.6007e-01,  1.4014e+00, -3.8179e-01,\n",
      "          -2.3898e-01,  9.5665e-02,  5.4185e-01,  7.8480e-02, -7.4198e-01,\n",
      "           3.7485e-02, -1.1244e-01,  5.6840e-01, -1.5983e-01,  3.1847e-01,\n",
      "          -2.8043e-01,  1.3540e-01, -9.7404e-02, -7.2468e-01,  9.9290e-01,\n",
      "           6.1460e-01,  3.0556e-01, -9.4487e-01,  1.0193e+00, -1.0106e-01,\n",
      "          -1.5386e+00,  3.4158e-01,  4.2114e-01, -3.2881e-01, -1.3621e-02,\n",
      "          -2.3702e-01, -5.9156e-01, -6.2746e-02, -9.9363e-01, -3.5500e-03,\n",
      "          -1.1910e-02, -1.5673e-01, -1.3858e-01, -1.2728e-01,  3.2764e-01,\n",
      "           1.5330e-01,  3.4395e-01, -1.7346e+00,  4.2143e-01,  2.9009e-01,\n",
      "          -2.0314e-01, -1.6999e-01, -5.6043e-01,  1.5592e+00,  9.0695e-01,\n",
      "          -2.3074e-01,  2.6335e-01,  1.0063e-02,  3.3536e-01, -1.0068e+00,\n",
      "           3.3994e-01,  3.1071e-01,  5.5808e-04, -1.8070e-01,  3.1451e-01,\n",
      "           3.3578e-01, -2.1316e-02,  1.2061e-01, -2.9430e-01,  1.0108e-01,\n",
      "           3.9898e-02,  3.1339e-01,  4.6233e-01, -6.2455e-02, -4.8597e-01,\n",
      "          -1.1414e-01, -2.3682e-01,  3.2588e-01,  2.1854e-01,  2.1128e-01,\n",
      "          -6.2360e-01, -1.0117e-01,  4.4842e-01, -7.2232e-01,  8.1424e-02,\n",
      "          -1.1417e-01, -1.5510e-01,  1.9553e+00,  1.4658e-01,  8.1736e-01,\n",
      "          -1.5598e-01, -1.1353e-01,  7.0220e-01,  3.5282e-03, -2.4982e-01,\n",
      "          -2.7995e+00, -1.3884e+00,  9.2986e-01, -3.0575e-01,  4.1183e-01,\n",
      "          -5.4223e-01, -2.7192e-01,  3.2496e-01, -2.3899e-01, -3.1130e-02,\n",
      "          -1.0525e+00,  2.2014e+00, -7.1531e-01,  3.3892e-02, -3.3486e-01,\n",
      "           6.7763e-01,  2.0083e-01, -1.8894e-01, -1.0283e+00, -9.1044e-02,\n",
      "           4.8329e-03, -1.0640e-01,  4.0725e-01, -2.3403e-01,  6.0655e-01,\n",
      "           3.4804e-01, -3.5779e-01, -1.3233e-02, -1.0694e-01,  6.3256e-01,\n",
      "           1.0990e-01,  2.3830e-02,  3.6173e-01,  5.7738e-01, -1.9464e-01,\n",
      "           4.8241e-01, -2.5946e-02, -1.9019e-01, -7.8480e-01,  6.8758e-02,\n",
      "          -4.7497e-02, -1.3609e+00,  6.1587e-01,  5.8165e-02, -1.9913e-01,\n",
      "           9.7329e-01,  1.0289e-02,  1.6345e-01, -1.8136e-01, -2.1239e-01,\n",
      "          -7.4947e-02,  3.7483e-01, -1.4315e+00,  9.2524e-01,  5.4806e-02,\n",
      "           4.1944e-01,  2.0483e-02,  7.2994e-01,  2.1012e+00, -1.2746e+00,\n",
      "          -2.7914e-01, -4.1034e-01,  1.5823e-01, -1.2046e-01,  2.5009e-01,\n",
      "          -2.6848e-01,  9.3349e-03, -6.9723e-01, -1.1454e+00,  2.8049e-01,\n",
      "           1.7298e-01,  1.3442e-02, -3.6490e-01,  2.7565e-01, -5.0091e-01,\n",
      "           5.6422e-01, -4.3578e-01,  1.3744e+00,  2.6284e-01, -3.6305e-01,\n",
      "           1.8917e-01,  6.6354e-01, -6.3040e-01, -7.2850e-01, -8.3665e-02,\n",
      "          -2.6176e-01,  7.0304e-02,  1.4631e-01, -5.3198e-01,  6.2124e-01,\n",
      "           4.9013e-01,  7.6268e-02,  3.4316e-02, -1.7787e-01, -1.4833e-01,\n",
      "           1.1812e+00,  1.1317e+00, -4.8711e-01, -1.6038e-01,  2.3041e-01,\n",
      "           1.3259e+00,  9.8977e-02,  8.9631e-02,  1.8019e-01,  3.3693e-01,\n",
      "          -3.6393e-02,  1.1927e-01, -2.7777e-01, -9.0305e-02, -5.1156e-02,\n",
      "          -2.2291e-01, -8.1878e-01,  7.2951e-01,  2.9266e-01,  2.8071e+00,\n",
      "           2.3238e-01,  1.9978e-01,  4.6962e-01, -6.9338e-01,  2.1595e-02,\n",
      "           5.8179e-01, -8.0825e-03,  4.0437e-02,  4.6131e-01, -8.8928e-02,\n",
      "           1.0060e+00, -3.3248e-01, -4.9280e-01,  7.4792e-01,  1.4398e+00,\n",
      "          -1.4240e-01,  5.4036e-01,  3.3272e-01, -1.4869e-01, -3.5158e-01,\n",
      "          -2.0619e+00, -1.1094e-01, -3.5929e-01, -9.2581e-03, -6.2078e-01,\n",
      "          -3.0006e-01,  1.2676e-01, -3.4668e-01,  4.0886e-01, -1.8963e-01,\n",
      "          -3.1097e-01,  3.9580e-01, -8.1414e-02,  1.1727e-01, -1.0543e-01,\n",
      "          -1.1591e-01,  9.5239e-02,  1.2715e+00,  9.5719e-01, -1.0286e+00,\n",
      "          -1.2770e+00,  8.1440e-02, -1.8329e+00,  1.0241e-01, -3.5173e-01,\n",
      "          -5.2059e-01, -2.3979e-03, -1.6086e-01,  5.2218e-01,  1.0047e+00,\n",
      "           8.4269e-01,  7.7826e-02,  1.0640e-01, -3.7783e-02, -1.3345e+00,\n",
      "           5.3439e-01,  9.4980e-02,  1.7555e+00, -1.7011e-01,  6.6691e-02,\n",
      "           6.1246e-02,  5.6022e-01,  1.3658e-01, -1.5076e+00,  1.5500e-01,\n",
      "          -2.7122e-01, -2.7139e-01,  1.8960e-01, -1.3290e-01, -8.1194e-02,\n",
      "           2.3106e-02, -6.0200e-01,  2.4592e-01,  9.4521e-02, -3.6338e-01,\n",
      "           4.7547e-01, -1.4175e+00, -3.1754e-01,  2.4655e-02,  1.7531e+00,\n",
      "           2.2224e-01, -6.8889e-02,  1.7817e-01, -2.8154e-01,  1.2842e-01,\n",
      "          -1.1765e-01, -2.4398e-01,  6.9239e-01,  4.9469e-03, -1.0554e-01,\n",
      "          -2.1135e-01, -8.2615e-01, -1.2064e+00, -9.0425e-02, -3.6638e-01,\n",
      "          -1.1402e-01,  3.5683e-01, -4.8989e-01, -3.2952e-01, -1.4446e-01,\n",
      "           1.1521e-01,  5.4473e-01,  4.6421e-01, -4.7061e-01,  4.1033e-02,\n",
      "           3.0311e-02,  3.8718e-01,  3.9273e-02, -4.2830e-02, -2.2708e-02,\n",
      "           1.9289e+00,  2.8577e-02,  3.5952e-01,  4.2292e-02, -1.2712e+00,\n",
      "           4.9575e-01, -1.7472e-01,  6.2497e-01,  7.0061e-01,  1.0168e+00,\n",
      "           2.0898e-01,  2.9583e-01,  2.6145e+00,  7.3840e-01, -4.0931e-02,\n",
      "           1.6071e-01, -1.3981e+00, -6.6715e-02, -1.3173e-01, -1.1371e-01,\n",
      "           3.8258e-01,  1.4547e-01, -1.7297e-01,  3.8544e-02, -3.1107e-01,\n",
      "          -1.8706e+00, -2.0439e-01, -1.0771e-01,  3.1944e-01,  4.9499e-02,\n",
      "          -1.0994e-01,  1.5210e-01, -1.4176e+00,  5.2413e-02, -8.5459e-01,\n",
      "          -9.9805e-01,  1.9167e+00, -6.7263e-03,  2.3618e+00, -2.4710e-01,\n",
      "          -1.2896e-01,  3.7116e-01,  8.9034e-01, -6.4879e-02,  4.0245e-01,\n",
      "           3.8369e-01, -3.5353e-01,  5.1265e-01, -3.5775e-01,  6.3312e-02,\n",
      "          -1.3479e+00, -1.6700e-01, -2.2919e-01, -1.7324e-01, -3.7457e-01,\n",
      "          -1.0357e-01, -1.8559e-01, -5.9229e-01, -1.9978e-01,  4.4437e-01,\n",
      "          -8.8195e-01,  6.1009e-01,  5.7204e-01, -1.4240e+00, -3.9134e-01,\n",
      "           4.3413e-01,  5.6744e-01, -5.3973e-01,  1.3536e-01, -1.7571e-02,\n",
      "           4.3265e-01, -2.3575e+00, -2.0904e-01, -2.3189e+00, -6.9198e-01,\n",
      "           4.8116e-02,  4.4486e-01, -8.9616e-02, -3.0280e-01, -2.8890e-02,\n",
      "           1.9719e-01, -1.6125e+00, -1.0723e-02, -1.2308e+00,  2.7813e-02,\n",
      "           7.9382e-01, -3.8642e-01,  1.1324e-02,  3.2542e-02,  3.3886e-02,\n",
      "           8.7939e-02,  3.2446e-02, -4.3876e-01, -5.7848e-01,  2.2803e-01,\n",
      "          -5.0407e-02,  6.0831e-01, -1.8474e-01,  2.5290e+00,  4.7034e-01,\n",
      "          -7.4563e-01,  1.8814e-01,  5.8178e-02,  1.7588e-01, -2.3231e-01,\n",
      "          -2.6213e-01, -3.2092e-01,  3.5052e-01,  2.3856e-02, -9.3220e-02,\n",
      "          -1.4070e+00,  8.7897e-01, -1.7089e-01,  1.5757e-01,  6.0234e-01,\n",
      "           1.0688e-01, -5.8827e-02,  4.0119e-01, -8.5685e-02, -2.9215e-01,\n",
      "           3.3505e-02,  5.2877e-01,  8.5433e-02, -1.3682e-01,  5.6899e-02,\n",
      "           3.0420e-02, -1.6028e+00,  1.9255e-01,  1.2622e-01, -9.5260e-01,\n",
      "           2.0320e-01,  2.3399e-01,  2.6022e-01, -4.4882e-02, -3.5379e-01,\n",
      "          -4.8428e-01,  7.3951e-01,  3.5998e-01, -3.1704e-02,  6.6309e-01,\n",
      "           1.2429e-01,  1.0664e-01, -4.8499e-01, -1.4012e+00,  6.6858e-01,\n",
      "          -5.0829e-01,  3.4053e-02, -7.1859e-02,  2.4280e-01,  1.2617e-01,\n",
      "           3.1691e-01,  5.0482e-01, -1.4471e-01,  5.6196e-01, -1.0742e+00,\n",
      "          -3.1774e+00, -5.2434e-01, -7.6493e-01, -3.8002e-01, -7.4135e-02,\n",
      "          -1.2321e-01, -4.9928e-01,  3.1236e-01,  4.7799e-01,  9.0799e-01,\n",
      "          -6.3907e-02, -3.8825e-01,  1.3708e-01, -1.9597e-01, -6.9311e-01,\n",
      "          -2.2167e-01,  8.6342e-02,  5.5120e-03,  1.1685e+00, -1.1648e-01,\n",
      "           2.3934e-01,  1.8242e+00, -2.1611e-01, -2.9277e-01,  2.9649e-01,\n",
      "          -2.1038e-01, -2.2648e-01, -7.3345e-02,  1.4272e+00, -1.9541e-01,\n",
      "          -7.2778e-02,  5.3655e-01,  8.1853e-02]]], device='cuda:0'), 'image_feats': tensor([[[ 0.2431,  0.8703,  0.4091,  ..., -0.1364,  0.5865, -0.0774],\n",
      "         [ 0.1377,  1.0587,  0.3401,  ..., -0.0132,  0.5184,  1.2675],\n",
      "         [ 1.2541,  0.5216,  0.6157,  ...,  0.0277,  0.6304,  0.1008],\n",
      "         ...,\n",
      "         [-0.1858,  1.0811,  0.0942,  ..., -0.1176,  0.2101,  1.4752],\n",
      "         [ 0.2074,  0.9274,  0.3214,  ..., -0.2068,  0.5712, -0.3430],\n",
      "         [ 0.9357,  0.9592,  0.3450,  ..., -0.1386,  0.4405,  0.8156]]],\n",
      "       device='cuda:0'), 'cls_feats': tensor([[ 0.6861,  0.9635,  0.9189, -0.6999, -0.9506, -0.9428,  0.8898, -0.9481,\n",
      "         -0.4192, -0.7655, -0.9380, -0.7018, -0.8167,  0.9557, -0.9731,  0.9530,\n",
      "         -0.0454,  0.6914,  0.7266, -0.0052, -0.9271,  0.6346,  0.9023,  0.9638,\n",
      "         -0.3695,  0.9387, -0.8322,  0.9430, -0.2531,  0.8075, -0.6678, -0.6310,\n",
      "          0.7473,  0.9280, -0.0177,  0.3133, -0.8889,  0.1552, -0.9467, -0.9320,\n",
      "         -0.6951, -0.8687,  0.1766,  0.3877, -0.9530, -0.9646,  0.7337, -0.5759,\n",
      "          0.9306,  0.4362, -0.6669, -0.9406,  0.8098, -0.8067, -0.6465,  0.8948,\n",
      "          0.6083, -0.0344, -0.3722, -0.6427, -0.9051,  0.0540, -0.9654, -0.5094,\n",
      "          0.9314, -0.4041,  0.9361,  0.7168,  0.9392, -0.9849, -0.6538,  0.9099,\n",
      "         -0.8167, -0.6269, -0.8203, -0.8790, -0.9354,  0.9654,  0.9002,  0.8086,\n",
      "          0.6134,  0.8996,  0.4390, -0.9166,  0.7954,  0.4243,  0.5765, -0.4910,\n",
      "         -0.0837, -0.7827, -0.9418, -0.9364,  0.8557,  0.8651,  0.8614,  0.9193,\n",
      "          0.8506,  0.6370, -0.7113, -0.9676, -0.6871, -0.2314,  0.7330,  0.9065,\n",
      "         -0.9324,  0.3956,  0.7447, -0.8064,  0.9067,  0.8631,  0.4799,  0.6384,\n",
      "          0.8402, -0.8473, -0.8665,  0.1329,  0.9430,  0.9106, -0.9522, -0.8534,\n",
      "          0.8711,  0.2717, -0.5412,  0.7744, -0.9263,  0.0793,  0.4515, -0.9735,\n",
      "         -0.0066,  0.7723, -0.9771, -0.5410, -0.8353, -0.3052, -0.9695,  0.8457,\n",
      "          0.4923, -0.8924,  0.6764, -0.9508,  0.0490,  0.8915,  0.9543,  0.9395,\n",
      "          0.8224,  0.2361, -0.9094, -0.7523,  0.9566, -0.4121, -0.7178, -0.8682,\n",
      "         -0.9594, -0.5169,  0.9100, -0.0268, -0.2220,  0.8911,  0.8748, -0.5452,\n",
      "          0.9679, -0.0137, -0.6876,  0.9694,  0.2526, -0.8979,  0.1786, -0.8641,\n",
      "         -0.5407,  0.9638,  0.5739, -0.3002, -0.9697, -0.8552,  0.4265, -0.8314,\n",
      "          0.1260, -0.7668,  0.9569,  0.8464,  0.8809, -0.8522, -0.4863, -0.9610,\n",
      "          0.9031, -0.2059,  0.9832,  0.6457, -0.8745, -0.8451,  0.7987, -0.9393,\n",
      "         -0.9211,  0.3932, -0.8454, -0.7477,  0.9450,  0.9613,  0.8656,  0.0195,\n",
      "          0.6211, -0.4546,  0.9077,  0.5471,  0.5030,  0.9209,  0.6497, -0.8848,\n",
      "          0.4744,  0.2030, -0.9027, -0.8507, -0.2835, -0.0010,  0.9581, -0.9146,\n",
      "          0.9396, -0.2140, -0.4562,  0.8399, -0.3735,  0.5367, -0.6889,  0.8266,\n",
      "          0.8667,  0.6894, -0.0769,  0.1583, -0.0120,  0.7468, -0.4944, -0.9677,\n",
      "          0.8974,  0.9041, -0.7135,  0.7476,  0.8049, -0.7467,  0.8361, -0.1140,\n",
      "         -0.9609, -0.9281, -0.8294, -0.8841,  0.7275, -0.8979, -0.7762, -0.7321,\n",
      "         -0.7858, -0.7055,  0.9645, -0.9546,  0.8950,  0.9380, -0.4398, -0.9443,\n",
      "         -0.7640, -0.8377, -0.9044, -0.7822,  0.5797,  0.6652,  0.8443, -0.7218,\n",
      "         -0.9397, -0.7241, -0.9334, -0.7932, -0.9124, -0.9315, -0.9212,  0.9657,\n",
      "         -0.9403, -0.9138, -0.9086, -0.2287, -0.9148, -0.7972, -0.4978, -0.9206,\n",
      "         -0.9397, -0.3000, -0.8109, -0.9089,  0.8219, -0.9187, -0.9375,  0.1631,\n",
      "          0.9176, -0.4643,  0.0486,  0.8334,  0.9211, -0.9416, -0.4710, -0.8741,\n",
      "          0.4695, -0.8994,  0.0282,  0.8080, -0.6750, -0.8064,  0.9439, -0.3361,\n",
      "         -0.8883,  0.9143, -0.7095, -0.0080, -0.9304, -0.0989,  0.8746, -0.9472,\n",
      "         -0.9569, -0.5521,  0.1029,  0.9448,  0.9725, -0.9444, -0.8032,  0.6849,\n",
      "         -0.8741, -0.8476, -0.8543, -0.8867,  0.3841, -0.9577,  0.9002,  0.8944,\n",
      "          0.8741,  0.9605,  0.9298,  0.7942,  0.0601,  0.0177,  0.8477, -0.7911,\n",
      "         -0.7208,  0.6451, -0.7525,  0.9019,  0.9625, -0.6047, -0.4711, -0.7241,\n",
      "         -0.8680, -0.0926,  0.9080,  0.9230, -0.8913, -0.7550, -0.9705,  0.9343,\n",
      "          0.9556, -0.3745,  0.0613,  0.0245,  0.8374, -0.8194,  0.4525,  0.1838,\n",
      "         -0.1391, -0.8964, -0.9057, -0.9511, -0.8785, -0.9473, -0.9584, -0.9404,\n",
      "         -0.9258, -0.9336, -0.4731, -0.6960, -0.0861, -0.4606,  0.8067, -0.9468,\n",
      "          0.8689,  0.9710,  0.9321, -0.9172, -0.5130, -0.9465, -0.3851,  0.0096,\n",
      "         -0.8701,  0.7197,  0.1344, -0.2644,  0.8965,  0.0093, -0.8958, -0.1762,\n",
      "         -0.7720,  0.9036,  0.7997,  0.5176,  0.7928, -0.4390,  0.0357, -0.4593,\n",
      "         -0.1821,  0.7816, -0.4445, -0.6764,  0.9206, -0.5247, -0.8472,  0.6751,\n",
      "         -0.4740,  0.5442,  0.5204, -0.9465, -0.5485, -0.5013,  0.4493, -0.7130,\n",
      "         -0.9599, -0.0396, -0.8417, -0.8242, -0.8399, -0.9091, -0.9375,  0.3721,\n",
      "         -0.9502, -0.9258,  0.9106,  0.7854, -0.9354, -0.5029,  0.7846, -0.8933,\n",
      "          0.8479, -0.7099, -0.9312, -0.4060,  0.9086,  0.4037, -0.9608, -0.9267,\n",
      "          0.0818,  0.8091, -0.9481, -0.9064, -0.6212,  0.6837, -0.6029, -0.0268,\n",
      "         -0.1795,  0.8621, -0.4785,  0.1611, -0.9613,  0.6329, -0.8598, -0.8511,\n",
      "         -0.9122, -0.7216, -0.7042,  0.9457,  0.3143,  0.7789,  0.2101,  0.8547,\n",
      "          0.7129,  0.5477, -0.4509,  0.8447, -0.8087,  0.0530, -0.8974, -0.6889,\n",
      "          0.9161,  0.8877, -0.8584,  0.8737,  0.8873, -0.9335, -0.6944,  0.9046,\n",
      "          0.2264,  0.2252,  0.4507,  0.9608, -0.4124,  0.7434, -0.9581, -0.8339,\n",
      "          0.0081,  0.7294,  0.9500,  0.8169, -0.7480,  0.8812,  0.0795, -0.7554,\n",
      "         -0.9528, -0.5903, -0.8181, -0.6516, -0.9364, -0.7622,  0.7517,  0.8241,\n",
      "          0.6484, -0.7409, -0.8043,  0.8486, -0.3270,  0.7394, -0.9655, -0.8375,\n",
      "         -0.4116, -0.0213, -0.4419, -0.9021, -0.8633,  0.6484,  0.8442, -0.0075,\n",
      "          0.9237, -0.8946, -0.9126, -0.7234,  0.9336, -0.0032, -0.8876,  0.5668,\n",
      "          0.7643, -0.9399,  0.9520,  0.8163, -0.9074,  0.8824, -0.0571, -0.8952,\n",
      "         -0.9411,  0.9370, -0.9421,  0.5225,  0.3039,  0.9505,  0.8541,  0.9092,\n",
      "         -0.8648,  0.8545, -0.7344,  0.8958,  0.9592,  0.6203,  0.9080,  0.0415,\n",
      "         -0.9120,  0.2949,  0.9180, -0.9235, -0.8646, -0.1513,  0.3003, -0.7236,\n",
      "          0.1011,  0.9349, -0.7686, -0.8321,  0.8599, -0.8982, -0.9394,  0.9132,\n",
      "          0.4026,  0.5501,  0.9313, -0.9104,  0.8664, -0.0157,  0.9230, -0.9348,\n",
      "         -0.6024,  0.3617,  0.7102,  0.3783,  0.9083,  0.9204,  0.9442, -0.7189,\n",
      "          0.9407,  0.4892,  0.9174, -0.5663, -0.6324, -0.7260,  0.6909,  0.9679,\n",
      "          0.9625, -0.5346, -0.8391,  0.9468,  0.7944,  0.5043, -0.1009, -0.9703,\n",
      "          0.9267, -0.0780,  0.3834,  0.6234, -0.9261,  0.8249, -0.9312, -0.6229,\n",
      "         -0.8443,  0.8005, -0.3518,  0.9231,  0.9207,  0.9443,  0.8111, -0.9530,\n",
      "          0.9275,  0.0298, -0.8262, -0.6245,  0.9380,  0.6245, -0.5522,  0.6369,\n",
      "          0.9122,  0.9521, -0.6275,  0.5342,  0.0438,  0.6407,  0.5023,  0.9227,\n",
      "          0.4988,  0.3001,  0.9290,  0.7555, -0.8777, -0.9615,  0.7393,  0.7521,\n",
      "          0.4154,  0.9627, -0.7893,  0.8038,  0.9428, -0.4511, -0.0362, -0.2598,\n",
      "          0.0159,  0.1406,  0.4937,  0.4351,  0.5316, -0.9096, -0.9051,  0.0515,\n",
      "         -0.8954, -0.9084, -0.3198,  0.8460,  0.8972,  0.8789,  0.0014,  0.9582,\n",
      "         -0.9012, -0.8863,  0.9037,  0.1938,  0.8355, -0.6972,  0.8905,  0.9534,\n",
      "          0.2107,  0.5049, -0.9387, -0.7600, -0.9061, -0.9502, -0.0081, -0.9196,\n",
      "         -0.8195,  0.0489,  0.3990,  0.7317, -0.8240, -0.5181, -0.0454,  0.0215,\n",
      "          0.8402, -0.6998,  0.8516,  0.2863, -0.8246, -0.9624,  0.0259,  0.4900,\n",
      "         -0.6030, -0.8088, -0.9358, -0.6502, -0.7431, -0.5907, -0.5223, -0.1334,\n",
      "          0.8094, -0.6562,  0.8715, -0.4621, -0.8301,  0.3937, -0.8643,  0.5434,\n",
      "          0.3503, -0.7083,  0.5814,  0.7330, -0.4296, -0.9077, -0.9078, -0.9718,\n",
      "          0.9640,  0.3906,  0.8785,  0.6919, -0.9295,  0.0940,  0.4989, -0.8747,\n",
      "          0.7955,  0.7242,  0.8476, -0.9083,  0.6682,  0.9036,  0.0162, -0.5133,\n",
      "         -0.9446, -0.8102,  0.9813,  0.5234,  0.6895,  0.8091, -0.8560, -0.9017,\n",
      "          0.1673,  0.8996,  0.0289, -0.4581, -0.9003,  0.4672,  0.9173, -0.8879,\n",
      "         -0.7248, -0.9403,  0.3426,  0.2516, -0.9224, -0.9453,  0.9738,  0.5616,\n",
      "          0.9058, -0.8701,  0.9186,  0.7613,  0.3678,  0.2124, -0.5984,  0.3086]],\n",
      "       device='cuda:0'), 'raw_cls_feats': tensor([[ 2.7024e-01,  8.4886e-01,  3.5035e-01,  5.3281e-02,  5.2474e-02,\n",
      "         -1.7046e-01,  7.3329e-02,  3.0590e-02,  6.7037e-02, -3.7755e-01,\n",
      "         -8.7652e-01,  1.3844e-01,  2.5090e-01, -3.3451e-01, -1.6991e-01,\n",
      "         -2.3502e-02, -6.9722e-02, -1.1445e-01, -1.7391e-01,  3.5070e-01,\n",
      "         -1.2979e+00,  2.7135e-01, -6.4320e-02, -9.8884e-01,  3.2600e-02,\n",
      "         -4.4981e-01,  1.7270e-01,  3.7485e-01, -8.4396e-01, -6.4098e-02,\n",
      "          1.6703e-01,  3.6598e-01, -4.2784e-02, -1.1087e-01,  1.1336e-02,\n",
      "         -2.0030e+00, -7.8494e-01, -9.4766e-02, -1.2019e-01,  1.6362e-01,\n",
      "         -1.2572e-01,  2.2219e-01, -3.8874e-02,  6.9456e-01, -6.6659e-01,\n",
      "         -7.5572e-02, -6.5935e-02, -2.7468e-02,  1.0221e+00, -2.5591e-01,\n",
      "          1.8912e-01, -5.2756e-01,  4.2142e-02,  1.3391e+00,  6.7435e-02,\n",
      "          9.3807e-01,  1.4467e+00,  4.8933e-01,  2.6360e-01, -6.8080e-02,\n",
      "          1.7264e-01,  7.1070e-02,  3.0559e-01,  1.0487e+00, -1.0531e-01,\n",
      "          1.4899e-01, -1.4601e-01,  7.0311e-02, -6.1047e-01,  3.2517e-01,\n",
      "          9.6615e-02, -4.9635e-01,  3.9653e-01, -8.1497e-01,  4.3536e-01,\n",
      "         -1.7965e-01, -1.8054e-02, -7.7346e-02,  3.7056e-01, -1.1527e-01,\n",
      "         -5.1328e-02,  2.2571e-01, -1.4052e-01,  3.9916e-01, -1.5368e+00,\n",
      "         -2.2687e-01,  6.8785e-01,  4.7555e-03,  4.0235e-01, -3.9818e-01,\n",
      "          4.5255e-01,  1.8249e-01,  2.4254e-02,  5.4363e-01,  3.1668e-01,\n",
      "          1.4741e-01, -1.2045e+00,  5.6026e-01,  1.8129e-02, -5.2342e-01,\n",
      "         -2.5647e-01, -5.9585e-01,  1.6685e-01, -2.0819e-01, -2.7393e-01,\n",
      "         -5.4547e-02,  8.3671e-01,  1.0122e+00,  3.0082e-01, -4.0947e-01,\n",
      "         -3.5765e-01, -8.6501e-04,  1.6294e-01, -4.0080e-01, -8.3902e-01,\n",
      "          2.2061e-01, -4.1820e-02, -4.1544e-01, -2.5201e+00, -9.8932e-02,\n",
      "         -5.8175e-01, -7.2491e-02, -8.2113e-01, -1.3048e-01, -4.9790e-01,\n",
      "         -2.5302e-01,  9.9828e-02,  3.8401e-01, -1.0704e-01, -1.3460e-01,\n",
      "         -5.2490e-01,  1.6422e-01, -7.2538e-02,  3.1729e-01, -1.8784e-01,\n",
      "          8.4847e-01,  2.7782e-01,  3.9456e-01,  7.3581e-01, -4.6038e-01,\n",
      "         -1.2405e-01,  3.6507e-01,  1.0595e+00, -3.3720e-01, -1.7847e-01,\n",
      "          6.9445e-02,  5.5660e-02,  6.6612e-01, -1.5342e-01, -1.0245e-01,\n",
      "         -4.1698e-01, -4.7990e-01, -4.3741e-02,  7.5446e-01, -8.5839e-01,\n",
      "         -2.9759e-01,  7.4105e-02,  3.6936e-01,  2.2517e-01,  2.0445e-01,\n",
      "         -2.2520e-01, -7.0262e-01,  1.7491e+00,  1.5410e-01,  2.4333e-01,\n",
      "          1.1808e-01,  2.0031e-01, -4.1765e-01, -4.4570e-02, -7.5414e-02,\n",
      "         -1.7943e-01,  2.9114e-01, -5.1989e-01,  5.7214e-02,  3.4968e-03,\n",
      "         -5.4809e-02,  9.5891e-02, -1.0574e-01,  1.3325e-01,  6.3144e-01,\n",
      "          5.8261e-02, -5.3787e-01,  4.9443e-01,  8.5900e-01,  3.4082e-02,\n",
      "          8.8916e-04, -2.6900e-02,  2.4115e-01,  3.4658e-01, -6.3444e-02,\n",
      "          1.6090e-01,  6.9500e-01, -3.7949e-01,  1.2788e-01,  1.5003e-01,\n",
      "         -4.2237e-02, -2.5673e-01, -3.3161e-01, -2.3348e-01,  5.5662e-01,\n",
      "         -4.5105e-01,  1.1752e-01,  5.5362e-01,  1.0310e+00,  5.0748e-03,\n",
      "         -1.2152e+00, -4.7172e-01,  1.2711e-01,  6.1709e-02,  4.8978e-01,\n",
      "          2.5862e-01, -1.6091e-01, -2.9285e-01, -2.4275e-01,  3.7013e-01,\n",
      "         -6.4637e-01,  4.7067e-01, -1.3941e-01,  8.2075e-02, -4.9278e-02,\n",
      "         -2.3442e-01,  2.8614e-01, -2.1160e-01, -1.1124e+00,  9.2892e-01,\n",
      "          3.1191e-01,  8.5168e-02,  1.1483e-01,  8.2778e-01,  3.2094e-01,\n",
      "         -4.2826e-01, -4.3217e-01,  9.0470e-02,  1.4781e-01,  6.4168e-01,\n",
      "         -4.0168e-01, -3.3907e-01,  1.7142e-01, -1.4673e-01,  8.6523e-02,\n",
      "         -4.7792e-03, -1.9192e-01, -3.2239e-01, -2.2403e-01, -2.6295e-02,\n",
      "         -1.5122e-01,  6.5477e-02,  1.5560e-01,  1.1998e-01,  1.4690e-01,\n",
      "          5.6724e-01, -9.5334e-01,  1.0883e-01, -4.6437e-01, -2.8476e-01,\n",
      "         -2.8313e-01,  5.9793e-01, -1.3925e+00,  5.2537e-02,  1.7755e-01,\n",
      "          4.5361e-02,  1.0916e-01, -1.9150e-01, -1.3015e-01, -5.1746e-01,\n",
      "         -5.5892e-01, -1.6779e-01,  9.6007e-01,  1.4014e+00, -3.8179e-01,\n",
      "         -2.3898e-01,  9.5665e-02,  5.4185e-01,  7.8480e-02, -7.4198e-01,\n",
      "          3.7485e-02, -1.1244e-01,  5.6840e-01, -1.5983e-01,  3.1847e-01,\n",
      "         -2.8043e-01,  1.3540e-01, -9.7404e-02, -7.2468e-01,  9.9290e-01,\n",
      "          6.1460e-01,  3.0556e-01, -9.4487e-01,  1.0193e+00, -1.0106e-01,\n",
      "         -1.5386e+00,  3.4158e-01,  4.2114e-01, -3.2881e-01, -1.3621e-02,\n",
      "         -2.3702e-01, -5.9156e-01, -6.2746e-02, -9.9363e-01, -3.5500e-03,\n",
      "         -1.1910e-02, -1.5673e-01, -1.3858e-01, -1.2728e-01,  3.2764e-01,\n",
      "          1.5330e-01,  3.4395e-01, -1.7346e+00,  4.2143e-01,  2.9009e-01,\n",
      "         -2.0314e-01, -1.6999e-01, -5.6043e-01,  1.5592e+00,  9.0695e-01,\n",
      "         -2.3074e-01,  2.6335e-01,  1.0063e-02,  3.3536e-01, -1.0068e+00,\n",
      "          3.3994e-01,  3.1071e-01,  5.5808e-04, -1.8070e-01,  3.1451e-01,\n",
      "          3.3578e-01, -2.1316e-02,  1.2061e-01, -2.9430e-01,  1.0108e-01,\n",
      "          3.9898e-02,  3.1339e-01,  4.6233e-01, -6.2455e-02, -4.8597e-01,\n",
      "         -1.1414e-01, -2.3682e-01,  3.2588e-01,  2.1854e-01,  2.1128e-01,\n",
      "         -6.2360e-01, -1.0117e-01,  4.4842e-01, -7.2232e-01,  8.1424e-02,\n",
      "         -1.1417e-01, -1.5510e-01,  1.9553e+00,  1.4658e-01,  8.1736e-01,\n",
      "         -1.5598e-01, -1.1353e-01,  7.0220e-01,  3.5282e-03, -2.4982e-01,\n",
      "         -2.7995e+00, -1.3884e+00,  9.2986e-01, -3.0575e-01,  4.1183e-01,\n",
      "         -5.4223e-01, -2.7192e-01,  3.2496e-01, -2.3899e-01, -3.1130e-02,\n",
      "         -1.0525e+00,  2.2014e+00, -7.1531e-01,  3.3892e-02, -3.3486e-01,\n",
      "          6.7763e-01,  2.0083e-01, -1.8894e-01, -1.0283e+00, -9.1044e-02,\n",
      "          4.8329e-03, -1.0640e-01,  4.0725e-01, -2.3403e-01,  6.0655e-01,\n",
      "          3.4804e-01, -3.5779e-01, -1.3233e-02, -1.0694e-01,  6.3256e-01,\n",
      "          1.0990e-01,  2.3830e-02,  3.6173e-01,  5.7738e-01, -1.9464e-01,\n",
      "          4.8241e-01, -2.5946e-02, -1.9019e-01, -7.8480e-01,  6.8758e-02,\n",
      "         -4.7497e-02, -1.3609e+00,  6.1587e-01,  5.8165e-02, -1.9913e-01,\n",
      "          9.7329e-01,  1.0289e-02,  1.6345e-01, -1.8136e-01, -2.1239e-01,\n",
      "         -7.4947e-02,  3.7483e-01, -1.4315e+00,  9.2524e-01,  5.4806e-02,\n",
      "          4.1944e-01,  2.0483e-02,  7.2994e-01,  2.1012e+00, -1.2746e+00,\n",
      "         -2.7914e-01, -4.1034e-01,  1.5823e-01, -1.2046e-01,  2.5009e-01,\n",
      "         -2.6848e-01,  9.3349e-03, -6.9723e-01, -1.1454e+00,  2.8049e-01,\n",
      "          1.7298e-01,  1.3442e-02, -3.6490e-01,  2.7565e-01, -5.0091e-01,\n",
      "          5.6422e-01, -4.3578e-01,  1.3744e+00,  2.6284e-01, -3.6305e-01,\n",
      "          1.8917e-01,  6.6354e-01, -6.3040e-01, -7.2850e-01, -8.3665e-02,\n",
      "         -2.6176e-01,  7.0304e-02,  1.4631e-01, -5.3198e-01,  6.2124e-01,\n",
      "          4.9013e-01,  7.6268e-02,  3.4316e-02, -1.7787e-01, -1.4833e-01,\n",
      "          1.1812e+00,  1.1317e+00, -4.8711e-01, -1.6038e-01,  2.3041e-01,\n",
      "          1.3259e+00,  9.8977e-02,  8.9631e-02,  1.8019e-01,  3.3693e-01,\n",
      "         -3.6393e-02,  1.1927e-01, -2.7777e-01, -9.0305e-02, -5.1156e-02,\n",
      "         -2.2291e-01, -8.1878e-01,  7.2951e-01,  2.9266e-01,  2.8071e+00,\n",
      "          2.3238e-01,  1.9978e-01,  4.6962e-01, -6.9338e-01,  2.1595e-02,\n",
      "          5.8179e-01, -8.0825e-03,  4.0437e-02,  4.6131e-01, -8.8928e-02,\n",
      "          1.0060e+00, -3.3248e-01, -4.9280e-01,  7.4792e-01,  1.4398e+00,\n",
      "         -1.4240e-01,  5.4036e-01,  3.3272e-01, -1.4869e-01, -3.5158e-01,\n",
      "         -2.0619e+00, -1.1094e-01, -3.5929e-01, -9.2581e-03, -6.2078e-01,\n",
      "         -3.0006e-01,  1.2676e-01, -3.4668e-01,  4.0886e-01, -1.8963e-01,\n",
      "         -3.1097e-01,  3.9580e-01, -8.1414e-02,  1.1727e-01, -1.0543e-01,\n",
      "         -1.1591e-01,  9.5239e-02,  1.2715e+00,  9.5719e-01, -1.0286e+00,\n",
      "         -1.2770e+00,  8.1440e-02, -1.8329e+00,  1.0241e-01, -3.5173e-01,\n",
      "         -5.2059e-01, -2.3979e-03, -1.6086e-01,  5.2218e-01,  1.0047e+00,\n",
      "          8.4269e-01,  7.7826e-02,  1.0640e-01, -3.7783e-02, -1.3345e+00,\n",
      "          5.3439e-01,  9.4980e-02,  1.7555e+00, -1.7011e-01,  6.6691e-02,\n",
      "          6.1246e-02,  5.6022e-01,  1.3658e-01, -1.5076e+00,  1.5500e-01,\n",
      "         -2.7122e-01, -2.7139e-01,  1.8960e-01, -1.3290e-01, -8.1194e-02,\n",
      "          2.3106e-02, -6.0200e-01,  2.4592e-01,  9.4521e-02, -3.6338e-01,\n",
      "          4.7547e-01, -1.4175e+00, -3.1754e-01,  2.4655e-02,  1.7531e+00,\n",
      "          2.2224e-01, -6.8889e-02,  1.7817e-01, -2.8154e-01,  1.2842e-01,\n",
      "         -1.1765e-01, -2.4398e-01,  6.9239e-01,  4.9469e-03, -1.0554e-01,\n",
      "         -2.1135e-01, -8.2615e-01, -1.2064e+00, -9.0425e-02, -3.6638e-01,\n",
      "         -1.1402e-01,  3.5683e-01, -4.8989e-01, -3.2952e-01, -1.4446e-01,\n",
      "          1.1521e-01,  5.4473e-01,  4.6421e-01, -4.7061e-01,  4.1033e-02,\n",
      "          3.0311e-02,  3.8718e-01,  3.9273e-02, -4.2830e-02, -2.2708e-02,\n",
      "          1.9289e+00,  2.8577e-02,  3.5952e-01,  4.2292e-02, -1.2712e+00,\n",
      "          4.9575e-01, -1.7472e-01,  6.2497e-01,  7.0061e-01,  1.0168e+00,\n",
      "          2.0898e-01,  2.9583e-01,  2.6145e+00,  7.3840e-01, -4.0931e-02,\n",
      "          1.6071e-01, -1.3981e+00, -6.6715e-02, -1.3173e-01, -1.1371e-01,\n",
      "          3.8258e-01,  1.4547e-01, -1.7297e-01,  3.8544e-02, -3.1107e-01,\n",
      "         -1.8706e+00, -2.0439e-01, -1.0771e-01,  3.1944e-01,  4.9499e-02,\n",
      "         -1.0994e-01,  1.5210e-01, -1.4176e+00,  5.2413e-02, -8.5459e-01,\n",
      "         -9.9805e-01,  1.9167e+00, -6.7263e-03,  2.3618e+00, -2.4710e-01,\n",
      "         -1.2896e-01,  3.7116e-01,  8.9034e-01, -6.4879e-02,  4.0245e-01,\n",
      "          3.8369e-01, -3.5353e-01,  5.1265e-01, -3.5775e-01,  6.3312e-02,\n",
      "         -1.3479e+00, -1.6700e-01, -2.2919e-01, -1.7324e-01, -3.7457e-01,\n",
      "         -1.0357e-01, -1.8559e-01, -5.9229e-01, -1.9978e-01,  4.4437e-01,\n",
      "         -8.8195e-01,  6.1009e-01,  5.7204e-01, -1.4240e+00, -3.9134e-01,\n",
      "          4.3413e-01,  5.6744e-01, -5.3973e-01,  1.3536e-01, -1.7571e-02,\n",
      "          4.3265e-01, -2.3575e+00, -2.0904e-01, -2.3189e+00, -6.9198e-01,\n",
      "          4.8116e-02,  4.4486e-01, -8.9616e-02, -3.0280e-01, -2.8890e-02,\n",
      "          1.9719e-01, -1.6125e+00, -1.0723e-02, -1.2308e+00,  2.7813e-02,\n",
      "          7.9382e-01, -3.8642e-01,  1.1324e-02,  3.2542e-02,  3.3886e-02,\n",
      "          8.7939e-02,  3.2446e-02, -4.3876e-01, -5.7848e-01,  2.2803e-01,\n",
      "         -5.0407e-02,  6.0831e-01, -1.8474e-01,  2.5290e+00,  4.7034e-01,\n",
      "         -7.4563e-01,  1.8814e-01,  5.8178e-02,  1.7588e-01, -2.3231e-01,\n",
      "         -2.6213e-01, -3.2092e-01,  3.5052e-01,  2.3856e-02, -9.3220e-02,\n",
      "         -1.4070e+00,  8.7897e-01, -1.7089e-01,  1.5757e-01,  6.0234e-01,\n",
      "          1.0688e-01, -5.8827e-02,  4.0119e-01, -8.5685e-02, -2.9215e-01,\n",
      "          3.3505e-02,  5.2877e-01,  8.5433e-02, -1.3682e-01,  5.6899e-02,\n",
      "          3.0420e-02, -1.6028e+00,  1.9255e-01,  1.2622e-01, -9.5260e-01,\n",
      "          2.0320e-01,  2.3399e-01,  2.6022e-01, -4.4882e-02, -3.5379e-01,\n",
      "         -4.8428e-01,  7.3951e-01,  3.5998e-01, -3.1704e-02,  6.6309e-01,\n",
      "          1.2429e-01,  1.0664e-01, -4.8499e-01, -1.4012e+00,  6.6858e-01,\n",
      "         -5.0829e-01,  3.4053e-02, -7.1859e-02,  2.4280e-01,  1.2617e-01,\n",
      "          3.1691e-01,  5.0482e-01, -1.4471e-01,  5.6196e-01, -1.0742e+00,\n",
      "         -3.1774e+00, -5.2434e-01, -7.6493e-01, -3.8002e-01, -7.4135e-02,\n",
      "         -1.2321e-01, -4.9928e-01,  3.1236e-01,  4.7799e-01,  9.0799e-01,\n",
      "         -6.3907e-02, -3.8825e-01,  1.3708e-01, -1.9597e-01, -6.9311e-01,\n",
      "         -2.2167e-01,  8.6342e-02,  5.5120e-03,  1.1685e+00, -1.1648e-01,\n",
      "          2.3934e-01,  1.8242e+00, -2.1611e-01, -2.9277e-01,  2.9649e-01,\n",
      "         -2.1038e-01, -2.2648e-01, -7.3345e-02,  1.4272e+00, -1.9541e-01,\n",
      "         -7.2778e-02,  5.3655e-01,  8.1853e-02]], device='cuda:0'), 'image_labels': None, 'image_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0'), 'patch_index': (tensor([[[ 1,  8],\n",
      "         [ 2, 14],\n",
      "         [ 9,  8],\n",
      "         [ 3,  9],\n",
      "         [ 9,  3],\n",
      "         [ 7,  9],\n",
      "         [ 8,  1],\n",
      "         [ 4, 14],\n",
      "         [ 0,  5],\n",
      "         [ 6,  5],\n",
      "         [ 1, 14],\n",
      "         [ 2, 17],\n",
      "         [ 9, 10],\n",
      "         [10,  8],\n",
      "         [ 9, 13],\n",
      "         [ 9, 14],\n",
      "         [ 7, 15],\n",
      "         [ 7, 14],\n",
      "         [ 9,  0],\n",
      "         [ 9,  5],\n",
      "         [ 3,  8],\n",
      "         [ 5, 14],\n",
      "         [ 1,  5],\n",
      "         [10,  7],\n",
      "         [ 5, 15],\n",
      "         [10,  6],\n",
      "         [ 4,  8],\n",
      "         [ 4,  2],\n",
      "         [ 9, 12],\n",
      "         [ 8,  2],\n",
      "         [ 0,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  0],\n",
      "         [ 0,  3],\n",
      "         [ 5, 11],\n",
      "         [ 9,  6],\n",
      "         [ 6,  0],\n",
      "         [10, 14],\n",
      "         [ 2, 11],\n",
      "         [ 8, 18],\n",
      "         [ 6,  1],\n",
      "         [ 2, 16],\n",
      "         [ 0, 15],\n",
      "         [ 5, 17],\n",
      "         [ 6,  9],\n",
      "         [10,  9],\n",
      "         [ 9, 11],\n",
      "         [ 1, 13],\n",
      "         [ 3, 11],\n",
      "         [ 6,  7],\n",
      "         [ 3, 16],\n",
      "         [ 4, 17],\n",
      "         [ 4, 13],\n",
      "         [ 1, 17],\n",
      "         [ 7,  0],\n",
      "         [ 9, 18],\n",
      "         [ 3,  7],\n",
      "         [ 0, 17],\n",
      "         [ 3, 12],\n",
      "         [ 2, 10],\n",
      "         [ 0,  8],\n",
      "         [ 8, 10],\n",
      "         [ 8, 12],\n",
      "         [ 4,  3],\n",
      "         [ 6,  6],\n",
      "         [ 7, 10],\n",
      "         [ 5,  3],\n",
      "         [ 5,  0],\n",
      "         [10,  1],\n",
      "         [ 9,  4],\n",
      "         [ 2,  6],\n",
      "         [ 3,  0],\n",
      "         [ 0, 14],\n",
      "         [ 8, 14],\n",
      "         [ 6, 17],\n",
      "         [ 6, 14],\n",
      "         [ 5,  6],\n",
      "         [10, 17],\n",
      "         [ 9,  2],\n",
      "         [ 4,  9],\n",
      "         [ 2,  1],\n",
      "         [ 5,  9],\n",
      "         [ 7, 11],\n",
      "         [ 1,  4],\n",
      "         [ 3, 10],\n",
      "         [ 3, 15],\n",
      "         [ 4, 18],\n",
      "         [ 1,  7],\n",
      "         [ 4,  6],\n",
      "         [ 5, 12],\n",
      "         [ 6,  3],\n",
      "         [ 7,  2],\n",
      "         [ 0,  4],\n",
      "         [ 8, 13],\n",
      "         [ 2,  7],\n",
      "         [ 4,  7],\n",
      "         [ 6, 11],\n",
      "         [ 7, 13],\n",
      "         [ 4, 16],\n",
      "         [ 7,  1],\n",
      "         [ 8, 15],\n",
      "         [ 4,  4],\n",
      "         [ 3, 17],\n",
      "         [ 1,  0],\n",
      "         [ 8,  0],\n",
      "         [ 5, 18],\n",
      "         [ 8,  8],\n",
      "         [ 1,  1],\n",
      "         [ 0, 10],\n",
      "         [ 8,  5],\n",
      "         [ 0, 18],\n",
      "         [ 3,  4],\n",
      "         [ 9,  7],\n",
      "         [ 2,  0],\n",
      "         [10, 16],\n",
      "         [ 8, 17],\n",
      "         [10,  4],\n",
      "         [ 1, 10],\n",
      "         [ 3,  2],\n",
      "         [ 5, 16],\n",
      "         [ 3,  6],\n",
      "         [ 6, 10],\n",
      "         [ 2,  2],\n",
      "         [ 3, 18],\n",
      "         [10,  0],\n",
      "         [10, 10],\n",
      "         [ 7,  8],\n",
      "         [ 1,  2],\n",
      "         [ 8,  4],\n",
      "         [ 9,  1],\n",
      "         [ 5,  4],\n",
      "         [ 7, 12],\n",
      "         [ 0,  1],\n",
      "         [ 5,  8],\n",
      "         [ 3, 13],\n",
      "         [ 0,  7],\n",
      "         [ 7, 18],\n",
      "         [ 2,  3],\n",
      "         [ 2,  5],\n",
      "         [ 5,  5],\n",
      "         [ 7,  3],\n",
      "         [ 6, 18],\n",
      "         [ 8, 16],\n",
      "         [ 0, 16],\n",
      "         [ 6,  8],\n",
      "         [ 4, 11],\n",
      "         [ 2,  4],\n",
      "         [ 2, 15],\n",
      "         [ 8,  9],\n",
      "         [ 5, 13],\n",
      "         [ 3, 14],\n",
      "         [ 2, 12],\n",
      "         [ 4, 10],\n",
      "         [ 2, 18],\n",
      "         [ 9, 15],\n",
      "         [ 1, 16],\n",
      "         [ 7,  7],\n",
      "         [ 4,  5],\n",
      "         [ 7,  4],\n",
      "         [ 7,  6],\n",
      "         [ 7, 17],\n",
      "         [ 6, 15],\n",
      "         [ 6, 16],\n",
      "         [ 1,  3],\n",
      "         [ 4,  1],\n",
      "         [ 8,  6],\n",
      "         [ 1,  6],\n",
      "         [ 9, 16],\n",
      "         [ 8,  3],\n",
      "         [ 0, 12],\n",
      "         [ 0,  0],\n",
      "         [ 4, 15],\n",
      "         [ 5,  7],\n",
      "         [ 3,  5],\n",
      "         [ 1,  9],\n",
      "         [ 9, 17],\n",
      "         [ 5, 10],\n",
      "         [ 6, 13],\n",
      "         [ 8, 11],\n",
      "         [ 5,  2],\n",
      "         [ 1, 11],\n",
      "         [ 0,  9],\n",
      "         [10,  2],\n",
      "         [ 3,  1],\n",
      "         [ 2,  8],\n",
      "         [ 6,  2],\n",
      "         [10, 12],\n",
      "         [ 4, 12],\n",
      "         [ 1, 12],\n",
      "         [10,  3],\n",
      "         [10, 18],\n",
      "         [10,  5],\n",
      "         [10, 15],\n",
      "         [ 2, 13],\n",
      "         [ 0, 13],\n",
      "         [ 9,  9],\n",
      "         [ 2,  9],\n",
      "         [ 0, 11],\n",
      "         [ 7, 16],\n",
      "         [ 7,  5],\n",
      "         [ 8,  7],\n",
      "         [ 1, 15],\n",
      "         [ 6,  4],\n",
      "         [ 0,  6],\n",
      "         [ 1, 18],\n",
      "         [10, 13],\n",
      "         [10, 11],\n",
      "         [ 6, 12],\n",
      "         [ 5,  1]]]), (11, 19)), 'cls_output': tensor([[0.3804]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2814811/3734256495.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img)\n"
     ]
    }
   ],
   "source": [
    "idx = 64\n",
    "sensor =  torch.tensor(sensor_test_list[idx]).unsqueeze(0).unsqueeze(0)\n",
    "out = infer(image_test_list[idx],sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb Cell 60\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m876\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m sensor \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mtensor(sensor_test_list[idx])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m out \u001b[39m=\u001b[39m infer(image_test_list[idx],sensor)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "idx = 876\n",
    "sensor =  torch.tensor(sensor_test_list[idx]).unsqueeze(0).unsqueeze(0)\n",
    "out = infer(image_test_list[idx],sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1817\n",
    "sensor =  torch.tensor(sensor_test_list[idx]).unsqueeze(0).unsqueeze(0)\n",
    "out = infer(image_test_list[idx],sensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch_junsheng_39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29fd19f11c6b89e267402bb3227bc1208f7e2c9719aa03eba13baf7684fe5867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
