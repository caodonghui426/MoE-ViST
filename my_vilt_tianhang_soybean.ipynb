{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from vilt.modules import heads, objectives\n",
    "import vilt.modules.vision_transformer as vit\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from typing import OrderedDict\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vilt.transforms import pixelbert_transform\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class config:\n",
    "    debug = False\n",
    "    exp_name = \"vilt\"\n",
    "    seed = 101\n",
    "    batch_size = 4096  # this is a desired batch size; pl trainer will accumulate gradients when per step batch is smaller.\n",
    "    train_batch_size = 32\n",
    "    valid_batch_size = 4\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_fold = 5\n",
    "\n",
    "    # wandb \n",
    "    wandb_name = \"vilt|大豆|290图片加传感器\"\n",
    "    \n",
    "\n",
    "    # Image setting\n",
    "    train_transform_keys = [\"pixelbert\"]\n",
    "    val_transform_keys = [\"pixelbert\"]\n",
    "    img_size = 384\n",
    "    max_image_len = -1\n",
    "    patch_size = 32\n",
    "    draw_false_image = 1\n",
    "    image_only = False\n",
    "\n",
    "    # Sensor\n",
    "    # senser_input_num = 11 # 翔冠的传感器参数\n",
    "    senser_input_num = 19 # 天航的传感器参数\n",
    "    \n",
    "    # Text Setting\n",
    "    vqav2_label_size = 3129\n",
    "    max_text_len = 40\n",
    "    tokenizer = \"bert-base-uncased\"\n",
    "    vocab_size = 30522 # vocabulary词汇数量\n",
    "    whole_word_masking = False\n",
    "    mlm_prob = 0.15\n",
    "    draw_false_text = 0\n",
    "\n",
    "    # Transformer Setting\n",
    "    vit = \"vit_base_patch32_384\"\n",
    "    hidden_size = 768  # 嵌入向量大小\n",
    "    num_heads = 12\n",
    "    num_layers = 12\n",
    "    mlp_ratio = 4\n",
    "    drop_rate = 0.1\n",
    "\n",
    "    # Optimizer Setting\n",
    "    optim_type = \"adamw\"\n",
    "    learning_rate = 1e-3\n",
    "    weight_decay = 1e-4 # 0.01 ->1e-4\n",
    "    decay_power = 1\n",
    "    max_epoch = 50\n",
    "    max_steps = 25000\n",
    "    warmup_steps = 2500\n",
    "    end_lr = 0\n",
    "    lr_mult = 1  # multiply lr for downstream heads\n",
    "    # T_max = 8000/train_batch_size*max_epoch \n",
    "    T_max = 1000/train_batch_size*max_epoch \n",
    "\n",
    "    # Downstream Setting\n",
    "    get_recall_metric = False\n",
    "\n",
    "\n",
    "    # below params varies with the environment\n",
    "    data_root = \"\"\n",
    "    log_dir = \"result\"\n",
    "    per_gpu_batchsize = 0  # you should define this manually with per_gpu_batch_size=#\n",
    "    num_gpus = 1\n",
    "    num_nodes = 1\n",
    "    load_path = \"weights/vilt_200k_mlm_itm.ckpt\"\n",
    "    # load_path = \"save_model_dict.pt\"\n",
    "    num_workers = 1\n",
    "    precision = 16\n",
    "\n",
    "# config = vars(config)\n",
    "# config = dict(config)\n",
    "config\n",
    "\n",
    "if config.debug:\n",
    "    config.max_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "\n",
    "    torch.manual_seed(seed)  # 为CPU设置随机种子\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.manual_seed(seed)  # 为当前GPU设置随机种子\n",
    "    torch.cuda.manual_seed_all(seed)  # 为所有GPU设置随机种子\n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "setup_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_MODE\"] = 'dryrun' # 离线模式\n",
    "try:\n",
    "    # wandb.log(key=\"*******\") # if debug\n",
    "    wandb.login() # storage in ~/.netrc file\n",
    "    anonymous = None\n",
    "except:\n",
    "    anonymous = \"must\"\n",
    "    print('\\nGet your W&B access token from here: https://wandb.ai/authorize\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2658, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pic_key</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date</th>\n",
       "      <th>co2</th>\n",
       "      <th>stemp</th>\n",
       "      <th>stemp2</th>\n",
       "      <th>stemp3</th>\n",
       "      <th>stemp4</th>\n",
       "      <th>stemp5</th>\n",
       "      <th>...</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm25</th>\n",
       "      <th>press</th>\n",
       "      <th>solar</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind_d</th>\n",
       "      <th>wind_sp</th>\n",
       "      <th>LAI</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>/794/1655497027_1655496664_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022/6/18</td>\n",
       "      <td>419.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>991.1</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.26</td>\n",
       "      <td>274.3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>/home/junsheng/data/tianhang_soybean/165549702...</td>\n",
       "      <td>1.3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>/794/1655497027_1655496664_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022/6/18</td>\n",
       "      <td>419.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>991.2</td>\n",
       "      <td>5.93</td>\n",
       "      <td>17.18</td>\n",
       "      <td>268.7</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>/home/junsheng/data/tianhang_soybean/165549702...</td>\n",
       "      <td>1.3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>/794/1655497027_1655496664_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022/6/18</td>\n",
       "      <td>418.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>991.1</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.26</td>\n",
       "      <td>274.3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>/home/junsheng/data/tianhang_soybean/165549702...</td>\n",
       "      <td>1.3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>/794/1655497027_1655496664_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022/6/18</td>\n",
       "      <td>418.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>991.2</td>\n",
       "      <td>5.93</td>\n",
       "      <td>17.18</td>\n",
       "      <td>268.7</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>/home/junsheng/data/tianhang_soybean/165549702...</td>\n",
       "      <td>1.3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>/794/1655504185_1655503864_4.jpg</td>\n",
       "      <td>2022-06-18 06</td>\n",
       "      <td>2022/6/18</td>\n",
       "      <td>419.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>991.9</td>\n",
       "      <td>8.84</td>\n",
       "      <td>17.75</td>\n",
       "      <td>248.6</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>/home/junsheng/data/tianhang_soybean/165550418...</td>\n",
       "      <td>1.3175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                           pic_key      date_hour       date    co2  \\\n",
       "0     32  /794/1655497027_1655496664_4.jpg  2022-06-18 04  2022/6/18  419.0   \n",
       "1     33  /794/1655497027_1655496664_4.jpg  2022-06-18 04  2022/6/18  419.0   \n",
       "2     34  /794/1655497027_1655496664_4.jpg  2022-06-18 04  2022/6/18  418.0   \n",
       "3     35  /794/1655497027_1655496664_4.jpg  2022-06-18 04  2022/6/18  418.0   \n",
       "4     36  /794/1655504185_1655503864_4.jpg  2022-06-18 06  2022/6/18  419.0   \n",
       "\n",
       "   stemp  stemp2  stemp3  stemp4  stemp5  ...  pm10  pm25  press  solar  \\\n",
       "0   19.2    19.3    19.1    18.8    18.4  ...   6.0   6.0  991.1   2.52   \n",
       "1   19.2    19.3    19.1    18.8    18.4  ...   7.0   7.0  991.2   5.93   \n",
       "2   19.1    19.2    19.1    18.8    18.4  ...   6.0   6.0  991.1   2.52   \n",
       "3   19.1    19.2    19.1    18.8    18.4  ...   7.0   7.0  991.2   5.93   \n",
       "4   18.8    19.0    18.9    18.7    18.3  ...   5.0   5.0  991.9   8.84   \n",
       "\n",
       "    temp wind_d wind_sp     LAI  \\\n",
       "0  17.26  274.3    3.75  1.3175   \n",
       "1  17.18  268.7    2.67  1.3175   \n",
       "2  17.26  274.3    3.75  1.3175   \n",
       "3  17.18  268.7    2.67  1.3175   \n",
       "4  17.75  248.6    2.07  1.3175   \n",
       "\n",
       "                                          image_path   label  \n",
       "0  /home/junsheng/data/tianhang_soybean/165549702...  1.3175  \n",
       "1  /home/junsheng/data/tianhang_soybean/165549702...  1.3175  \n",
       "2  /home/junsheng/data/tianhang_soybean/165549702...  1.3175  \n",
       "3  /home/junsheng/data/tianhang_soybean/165549702...  1.3175  \n",
       "4  /home/junsheng/data/tianhang_soybean/165550418...  1.3175  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tianhang = pd.read_csv(\"/home/junsheng/ViLT/data/290-tianhang-soybean.csv\")\n",
    "df_tianhang['image_path'] = df_tianhang['pic_key'].map(lambda x:os.path.join('/home/junsheng/data/tianhang_soybean',x.split('/')[-1]))\n",
    "df_tianhang['label'] = df_tianhang['LAI']\n",
    "df_tianhang = df_tianhang.dropna()\n",
    "df_tianhang = df_tianhang.reset_index()\n",
    "print(df_tianhang.shape)\n",
    "df_tianhang.to_csv(\"test.csv\",index=False)\n",
    "df_tianhang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n",
      "811\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "# 检查图片下载的全不全\n",
    "pic = df_tianhang.image_path.map(lambda x:x.split('/')[-1]).unique()\n",
    "print(len(pic))\n",
    "file_ls = os.listdir(\"/home/junsheng/data/tianhang_soybean\")\n",
    "print(len(file_ls))\n",
    "ret = list(set(pic) ^ set(file_ls))\n",
    "print(len(ret)) #差集\n",
    "# assert len(pic)==len(file_ls),\"请检查下载的图片，缺了{}个\".format(len(pic)-len(file_ls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化非object列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'pic_key',\n",
       " 'date_hour',\n",
       " 'date',\n",
       " 'co2',\n",
       " 'stemp',\n",
       " 'stemp2',\n",
       " 'stemp3',\n",
       " 'stemp4',\n",
       " 'stemp5',\n",
       " 'shumi',\n",
       " 'shumi2',\n",
       " 'shumi3',\n",
       " 'shumi4',\n",
       " 'shumi5',\n",
       " 'ts',\n",
       " 'insert_time',\n",
       " 'humi',\n",
       " 'pm10',\n",
       " 'pm25',\n",
       " 'press',\n",
       " 'solar',\n",
       " 'temp',\n",
       " 'wind_d',\n",
       " 'wind_sp',\n",
       " 'LAI',\n",
       " 'image_path',\n",
       " 'label']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_tianhang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'co2', 'stemp', 'stemp2', 'stemp3', 'stemp4', 'stemp5', 'shumi', 'shumi2', 'shumi3', 'shumi4', 'shumi5', 'humi', 'pm10', 'pm25', 'press', 'solar', 'temp', 'wind_d', 'wind_sp', 'LAI', 'label']\n",
      "{'index': (32, 3161), 'co2': (341.0, 751.0), 'stemp': (14.0, 29.0), 'stemp2': (14.8, 27.5), 'stemp3': (15.5, 25.7), 'stemp4': (15.6, 24.6), 'stemp5': (16.0, 24.3), 'shumi': (44.6, 75.7), 'shumi2': (36.5, 71.3), 'shumi3': (38.9, 71.7), 'shumi4': (43.6, 75.0), 'shumi5': (61.6, 80.0), 'humi': (31.0, 100.0), 'pm10': (0.0, 1333.0), 'pm25': (0.0, 1333.0), 'press': (981.1, 1014.8), 'solar': (0.0, 200.0), 'temp': (7.25, 32.0), 'wind_d': (0.0, 359.8), 'wind_sp': (0.0, 10.27), 'LAI': (1.3175, 2.23), 'label': (1.3175, 2.23)}\n"
     ]
    }
   ],
   "source": [
    "number_title = []\n",
    "recorder = {}\n",
    "for title in df_tianhang:\n",
    "    # print(df_xiangguan[title].head())\n",
    "    if title == 'raw_label':\n",
    "        continue\n",
    "    if df_tianhang[title].dtype != \"object\":\n",
    "        \n",
    "        number_title.append(title)\n",
    "        x_min = df_tianhang[title].min()\n",
    "        x_max = df_tianhang[title].max()\n",
    "        # print(x_min,x_max)\n",
    "        recorder[title] = (x_min,x_max)\n",
    "        df_tianhang[title] = df_tianhang[title].map(lambda x:(x-x_min)/(x_max - x_min))\n",
    "print(number_title)\n",
    "print(recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tianhang['stemp4'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: 19\n"
     ]
    }
   ],
   "source": [
    "# xiangguan_sensor = ['temperature', 'humidity', 'illuminance', 'soil_temperature', 'soil_humidity', 'pressure', 'wind_speed', 'photosynthetic', 'sun_exposure_time', 'COz', 'soil_ph']\n",
    "tianhang_sensor = ['co2', 'stemp', 'stemp2', 'stemp3', 'stemp4', 'stemp5', 'shumi', 'shumi2', 'shumi3', 'shumi4', 'shumi5', 'humi', 'pm10', 'pm25', 'press', 'solar', 'temp', 'wind_d', 'wind_sp']\n",
    "# tianhang_sensor = ['co2', 'stemp', 'stemp2', 'stemp3', 'stemp5', 'shumi', 'shumi2', 'shumi3', 'shumi5', 'humi', 'pm10', 'pm25', 'press', 'solar', 'temp', 'wind_d', 'wind_sp']\n",
    "\n",
    "df_tianhang['sensor'] = df_tianhang[tianhang_sensor].values.tolist()\n",
    "print(\"input dim:\",len(tianhang_sensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2658, 29)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_tianhang\n",
    "if config.debug:\n",
    "    df = df[:100]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tianhang.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0.0    532\n",
       "1.0    532\n",
       "2.0    532\n",
       "3.0    531\n",
       "4.0    531\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)  \n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df,df.date)):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "df.groupby(['fold'])['label'].count()# ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv(\"test_fold.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((config.img_size,config.img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    mean=[0.7136, 0.7118, 0.6788],\n",
    "    std=[0.3338, 0.3453, 0.3020],\n",
    "    \n",
    ")\n",
    "])\n",
    "\n",
    "def load_img(path):\n",
    "    img =  Image.open(path).convert('RGB')\n",
    "    img = myTransforms(img)\n",
    "    return img\n",
    "\n",
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, label=True, transforms=None):\n",
    "        self.df         = df\n",
    "        self.label      = label\n",
    "        self.sensors = df['sensor'].tolist()\n",
    "        self.img_paths  = df['image_path'].tolist()   \n",
    "        if self.label:\n",
    "            self.labels = df['label'].tolist()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        img = load_img(img_path)\n",
    "        sensor = self.sensors[index]\n",
    "        sensor = torch.tensor(sensor).unsqueeze(0) #[1,n]\n",
    "        if self.label:\n",
    "            label = self.labels[index]\n",
    "            return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n",
    "        else:\n",
    "            return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_dataloader(fold:int):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    print(\"train_df.shape:\",train_df.shape)\n",
    "    print(\"valid_df.shape:\",valid_df.shape)\n",
    "\n",
    "    train_data  = BuildDataset(df=train_df,label=True)\n",
    "    valid_data = BuildDataset(df=valid_df,label=True)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.train_batch_size,shuffle=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=config.valid_batch_size,shuffle=False)\n",
    "    # test_loader = DataLoader(test_data, batch_size=config.test_batch_size,shuffle=False)\n",
    "    return train_loader,valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape: (2126, 30)\n",
      "valid_df.shape: (532, 30)\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = BuildDataset(df=df)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=config.train_batch_size,shuffle=True)\n",
    "# valid_loader = DataLoader(train_dataset, batch_size=config.valid_batch_size,shuffle=True)\n",
    "train_loader,valid_loader = fetch_dataloader(fold=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2984942/355586058.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 384, 384])\n",
      "torch.Size([32, 1, 19])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "img,sensor,label = next(iter(train_loader))\n",
    "print(img.shape)\n",
    "print(sensor.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorViLTransformerSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorViLTransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config.hidden_size) \n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "                pretrained=True, config=vars(config)\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config.hidden_size,output_class_n)\n",
    "\n",
    "        hs = config.hidden_size\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        mask_image=False,\n",
    "        image_token_type_idx=1,\n",
    "        image_embeds=None,\n",
    "        image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config.device)\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        \n",
    "\n",
    "        if image_embeds is None and image_masks is None:\n",
    "            img = batch[\"image\"].to(config.device)\n",
    "       \n",
    "            (\n",
    "                image_embeds, # torch.Size([1, 217, 768])\n",
    "                image_masks, # torch.Size([1, 217])\n",
    "                patch_index,\n",
    "                image_labels,\n",
    "            ) = self.transformer.visual_embed(\n",
    "                img,\n",
    "                max_image_len=config.max_image_len,\n",
    "                mask_it=mask_image,\n",
    "            )\n",
    "        else:\n",
    "            patch_index, image_labels = (\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        image_embeds = image_embeds + self.token_type_embeddings(\n",
    "                torch.full_like(image_masks, image_token_type_idx)\n",
    "            )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(batch_size,1).to(config.device) # 序列数量\n",
    "        image_masks = image_masks.to(config.device)\n",
    "        co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "\n",
    "        x = co_embeds.to(config.device) # torch.Size([1, 211, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks): \n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks) # co_masks = torch.Size([1, 211])\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "            x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "            x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "        \n",
    "        ret = {\n",
    "           \"sensor_feats\":sensor_feats,\n",
    "            \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            \"image_labels\": image_labels,\n",
    "            \"image_masks\": image_masks,\n",
    "           \n",
    "            \"patch_index\": patch_index,\n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorOnlyViLTransformerSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorOnlyViLTransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config.hidden_size) \n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "                pretrained=True, config=vars(config)\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config.hidden_size,output_class_n)\n",
    "\n",
    "        hs = config.hidden_size\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        # mask_image=False,\n",
    "        # image_token_type_idx=1,\n",
    "        # image_embeds=None,\n",
    "        # image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config.device)\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        \n",
    "\n",
    "        # if image_embeds is None and image_masks is None:\n",
    "        #     img = batch[\"image\"].to(config.device)\n",
    "       \n",
    "        #     (\n",
    "        #         image_embeds, # torch.Size([1, 217, 768])\n",
    "        #         image_masks, # torch.Size([1, 217])\n",
    "        #         patch_index,\n",
    "        #         image_labels,\n",
    "        #     ) = self.transformer.visual_embed(\n",
    "        #         img,\n",
    "        #         max_image_len=config.max_image_len,\n",
    "        #         mask_it=mask_image,\n",
    "        #     )\n",
    "        # else:\n",
    "        #     patch_index, image_labels = (\n",
    "        #         None,\n",
    "        #         None,\n",
    "        #     )\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        # image_embeds = image_embeds + self.token_type_embeddings(\n",
    "        #         torch.full_like(image_masks, image_token_type_idx)\n",
    "        #     )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        # batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(sensor_embeds.shape[1],1).to(config.device) # 序列数量\n",
    "        # image_masks = image_masks.to(config.device)\n",
    "        # co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        # co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "        co_embeds = sensor_embeds\n",
    "        co_masks = sensor_masks\n",
    "\n",
    "        x = co_embeds.to(config.device) # torch.Size([1, 1, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks):\n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks)\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        # sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "        #     x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "        #     x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        # )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "        \n",
    "        ret = {\n",
    "        #    \"sensor_feats\":sensor_feats,\n",
    "            # \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            # \"image_labels\": image_labels,\n",
    "            # \"image_masks\": image_masks,\n",
    "           \n",
    "            # \"patch_index\": patch_index,\n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No pretrained weights exist or were found for this model. Using random initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "0 sensorViLTransformerSS(\n",
      "  (sensor_linear): Linear(in_features=19, out_features=768, bias=True)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (transformer): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      "  (pooler): Pooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n",
      "1 Linear(in_features=19, out_features=768, bias=True)\n",
      "2 Embedding(2, 768)\n",
      "3 VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      ")\n",
      "4 PatchEmbed(\n",
      "  (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      ")\n",
      "5 Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "6 Dropout(p=0.1, inplace=False)\n",
      "7 ModuleList(\n",
      "  (0): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (2): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (3): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (4): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (5): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (6): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (7): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (8): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (9): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (10): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (11): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "8 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "9 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "10 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "11 Linear(in_features=768, out_features=2304, bias=True)\n",
      "12 Dropout(p=0.0, inplace=False)\n",
      "13 Linear(in_features=768, out_features=768, bias=True)\n",
      "14 Dropout(p=0.1, inplace=False)\n",
      "15 Identity()\n",
      "16 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "17 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "18 Linear(in_features=768, out_features=3072, bias=True)\n",
      "19 GELU(approximate=none)\n",
      "20 Linear(in_features=3072, out_features=768, bias=True)\n",
      "21 Dropout(p=0.1, inplace=False)\n",
      "22 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "23 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "24 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "25 Linear(in_features=768, out_features=2304, bias=True)\n",
      "26 Dropout(p=0.0, inplace=False)\n",
      "27 Linear(in_features=768, out_features=768, bias=True)\n",
      "28 Dropout(p=0.1, inplace=False)\n",
      "29 Identity()\n",
      "30 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "31 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "32 Linear(in_features=768, out_features=3072, bias=True)\n",
      "33 GELU(approximate=none)\n",
      "34 Linear(in_features=3072, out_features=768, bias=True)\n",
      "35 Dropout(p=0.1, inplace=False)\n",
      "36 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "37 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "38 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "39 Linear(in_features=768, out_features=2304, bias=True)\n",
      "40 Dropout(p=0.0, inplace=False)\n",
      "41 Linear(in_features=768, out_features=768, bias=True)\n",
      "42 Dropout(p=0.1, inplace=False)\n",
      "43 Identity()\n",
      "44 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "45 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "46 Linear(in_features=768, out_features=3072, bias=True)\n",
      "47 GELU(approximate=none)\n",
      "48 Linear(in_features=3072, out_features=768, bias=True)\n",
      "49 Dropout(p=0.1, inplace=False)\n",
      "50 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "51 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "52 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "53 Linear(in_features=768, out_features=2304, bias=True)\n",
      "54 Dropout(p=0.0, inplace=False)\n",
      "55 Linear(in_features=768, out_features=768, bias=True)\n",
      "56 Dropout(p=0.1, inplace=False)\n",
      "57 Identity()\n",
      "58 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "59 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "60 Linear(in_features=768, out_features=3072, bias=True)\n",
      "61 GELU(approximate=none)\n",
      "62 Linear(in_features=3072, out_features=768, bias=True)\n",
      "63 Dropout(p=0.1, inplace=False)\n",
      "64 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "65 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "66 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "67 Linear(in_features=768, out_features=2304, bias=True)\n",
      "68 Dropout(p=0.0, inplace=False)\n",
      "69 Linear(in_features=768, out_features=768, bias=True)\n",
      "70 Dropout(p=0.1, inplace=False)\n",
      "71 Identity()\n",
      "72 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "73 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "74 Linear(in_features=768, out_features=3072, bias=True)\n",
      "75 GELU(approximate=none)\n",
      "76 Linear(in_features=3072, out_features=768, bias=True)\n",
      "77 Dropout(p=0.1, inplace=False)\n",
      "78 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "79 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "80 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "81 Linear(in_features=768, out_features=2304, bias=True)\n",
      "82 Dropout(p=0.0, inplace=False)\n",
      "83 Linear(in_features=768, out_features=768, bias=True)\n",
      "84 Dropout(p=0.1, inplace=False)\n",
      "85 Identity()\n",
      "86 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "87 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "88 Linear(in_features=768, out_features=3072, bias=True)\n",
      "89 GELU(approximate=none)\n",
      "90 Linear(in_features=3072, out_features=768, bias=True)\n",
      "91 Dropout(p=0.1, inplace=False)\n",
      "92 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "93 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "94 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "95 Linear(in_features=768, out_features=2304, bias=True)\n",
      "96 Dropout(p=0.0, inplace=False)\n",
      "97 Linear(in_features=768, out_features=768, bias=True)\n",
      "98 Dropout(p=0.1, inplace=False)\n",
      "99 Identity()\n",
      "100 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "101 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "102 Linear(in_features=768, out_features=3072, bias=True)\n",
      "103 GELU(approximate=none)\n",
      "104 Linear(in_features=3072, out_features=768, bias=True)\n",
      "105 Dropout(p=0.1, inplace=False)\n",
      "106 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "107 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "108 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "109 Linear(in_features=768, out_features=2304, bias=True)\n",
      "110 Dropout(p=0.0, inplace=False)\n",
      "111 Linear(in_features=768, out_features=768, bias=True)\n",
      "112 Dropout(p=0.1, inplace=False)\n",
      "113 Identity()\n",
      "114 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "115 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "116 Linear(in_features=768, out_features=3072, bias=True)\n",
      "117 GELU(approximate=none)\n",
      "118 Linear(in_features=3072, out_features=768, bias=True)\n",
      "119 Dropout(p=0.1, inplace=False)\n",
      "120 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "121 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "122 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "123 Linear(in_features=768, out_features=2304, bias=True)\n",
      "124 Dropout(p=0.0, inplace=False)\n",
      "125 Linear(in_features=768, out_features=768, bias=True)\n",
      "126 Dropout(p=0.1, inplace=False)\n",
      "127 Identity()\n",
      "128 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "129 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "130 Linear(in_features=768, out_features=3072, bias=True)\n",
      "131 GELU(approximate=none)\n",
      "132 Linear(in_features=3072, out_features=768, bias=True)\n",
      "133 Dropout(p=0.1, inplace=False)\n",
      "134 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "135 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "136 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "137 Linear(in_features=768, out_features=2304, bias=True)\n",
      "138 Dropout(p=0.0, inplace=False)\n",
      "139 Linear(in_features=768, out_features=768, bias=True)\n",
      "140 Dropout(p=0.1, inplace=False)\n",
      "141 Identity()\n",
      "142 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "143 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "144 Linear(in_features=768, out_features=3072, bias=True)\n",
      "145 GELU(approximate=none)\n",
      "146 Linear(in_features=3072, out_features=768, bias=True)\n",
      "147 Dropout(p=0.1, inplace=False)\n",
      "148 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "149 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "150 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "151 Linear(in_features=768, out_features=2304, bias=True)\n",
      "152 Dropout(p=0.0, inplace=False)\n",
      "153 Linear(in_features=768, out_features=768, bias=True)\n",
      "154 Dropout(p=0.1, inplace=False)\n",
      "155 Identity()\n",
      "156 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "157 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "158 Linear(in_features=768, out_features=3072, bias=True)\n",
      "159 GELU(approximate=none)\n",
      "160 Linear(in_features=3072, out_features=768, bias=True)\n",
      "161 Dropout(p=0.1, inplace=False)\n",
      "162 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "163 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "164 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "165 Linear(in_features=768, out_features=2304, bias=True)\n",
      "166 Dropout(p=0.0, inplace=False)\n",
      "167 Linear(in_features=768, out_features=768, bias=True)\n",
      "168 Dropout(p=0.1, inplace=False)\n",
      "169 Identity()\n",
      "170 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "171 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "172 Linear(in_features=768, out_features=3072, bias=True)\n",
      "173 GELU(approximate=none)\n",
      "174 Linear(in_features=3072, out_features=768, bias=True)\n",
      "175 Dropout(p=0.1, inplace=False)\n",
      "176 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "177 Linear(in_features=768, out_features=768, bias=True)\n",
      "178 Tanh()\n",
      "179 Pooler(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n",
      "180 Linear(in_features=768, out_features=768, bias=True)\n",
      "181 Tanh()\n",
      "182 Linear(in_features=768, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# model = sensorOnlyViLTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "model = sensorViLTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "model.to(config.device)\n",
    "print(config.device)\n",
    "for i,m in enumerate(model.modules()):\n",
    "    print(i,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sensor = torch.rand(config.senser_input_num)\n",
    "# # sensor = torch.ones(config.senser_input_num)\n",
    "# print(sensor)\n",
    "# sensor =  torch.tensor(sensor).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 3])\n",
    "# batch = {}\n",
    "# batch['sensor'] = sensor\n",
    "# batch['image'] = \"/home/junsheng/data/xiangguan/pic/xiangguanD4-2021-05-24-10-00-25.jpeg\"\n",
    "# model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.mse_loss #均方误差损失函数\n",
    "# criterion = F.mae_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (img, sensor,label) in pbar:         \n",
    "        # img = img.to(device, dtype=torch.float)\n",
    "        # sensor  = sensor.to(device, dtype=torch.float)\n",
    "        # label  = label.to(device, dtype=torch.float)\n",
    "        batch_size = img.size(0)\n",
    "        \n",
    "        batch = {\"image\":img,\"sensor\":sensor}\n",
    "\n",
    "        y_pred = model(batch)\n",
    "        label = label.to(config.device).unsqueeze(1)\n",
    "        loss = criterion(y_pred['cls_output'], label)\n",
    "        \n",
    "        #一坨优化\n",
    "        optimizer.zero_grad()#每一次反向传播之前都要归零梯度\n",
    "        loss.backward()      #反向传播\n",
    "        optimizer.step()     #固定写法\n",
    "        scheduler.step()\n",
    "     \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, optimizer):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    val_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (img, sensor,label) in pbar:               \n",
    "        \n",
    "        \n",
    "        batch_size = img.size(0)\n",
    "        batch = {\"image\":img,\"sensor\":sensor}\n",
    "\n",
    "        y_pred  = model(batch)\n",
    "        label = label.to(config.device).unsqueeze(1)\n",
    "\n",
    "        loss = criterion(y_pred['cls_output'], label)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "     # init wandb\n",
    "    run = wandb.init(project=\"vilt\",\n",
    "                    config={k: v for k, v in dict(vars(config)).items() if '__' not in k},\n",
    "                    # config={k: v for k, v in dict(config).items() if '__' not in k},\n",
    "                    anonymous=anonymous,\n",
    "                    # name=f\"vilt|fold-{config.valid_fold}\",\n",
    "                    name=config.wandb_name,\n",
    "                    # group=config.wandb_group,\n",
    "                    )\n",
    "    wandb.watch(model, log_freq=100)\n",
    "\n",
    "    best_loss = 9999\n",
    "    best_valid_loss = 9999\n",
    "    history = defaultdict(list)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=device, epoch=epoch)\n",
    "        val_loss = valid_one_epoch(model,valid_loader,device=device,optimizer=optimizer)\n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "\n",
    "        wandb.log({\"Train Loss\": train_loss,\n",
    "                    \"Valid Loss\": val_loss,\n",
    "                \"lr\": scheduler.get_last_lr()[0]\n",
    "                })\n",
    "        if best_valid_loss > val_loss:\n",
    "            best_valid_loss = val_loss\n",
    "            # model_file_path = os.path.join(wandb.run.dir,\"epoch-{}-{}.bin\".format(epoch,wandb.run.id))\n",
    "            model_file_path = os.path.join(wandb.run.dir,\"epoch-best.bin\")\n",
    "            run.summary[\"Best Epoch\"] = epoch\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            print(\"model save to\", model_file_path)\n",
    "            \n",
    "    os.system(\"cp /home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb {}\".format(wandb.run.dir))\n",
    "    run.finish()\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=config.T_max, \n",
    "                                                   eta_min=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:36l1tf7k) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/junsheng/ViLT/wandb/offline-run-20221017_183404-36l1tf7k<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221017_183404-36l1tf7k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:36l1tf7k). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: NVIDIA GeForce RTX 3090\n",
      "\n",
      "Epoch 1/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/67 [00:00<?, ?it/s]/tmp/ipykernel_2984942/355586058.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n",
      "/home/junsheng/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Train :  42%|████▏     | 28/67 [01:00<01:24,  2.17s/it, gpu_mem=6.99 GB, lr=0.00100, train_loss=0.2759]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb Cell 48\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model, history \u001b[39m=\u001b[39m run_training(model, optimizer, scheduler,device\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdevice,num_epochs\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mmax_epoch)\n",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb Cell 48\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, scheduler, device, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m train_loss \u001b[39m=\u001b[39m train_one_epoch(model, optimizer, scheduler, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                                    dataloader\u001b[39m=\u001b[39;49mtrain_loader, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                                    device\u001b[39m=\u001b[39;49mdevice, epoch\u001b[39m=\u001b[39;49mepoch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m val_loss \u001b[39m=\u001b[39m valid_one_epoch(model,valid_loader,device\u001b[39m=\u001b[39mdevice,optimizer\u001b[39m=\u001b[39moptimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m history[\u001b[39m'\u001b[39m\u001b[39mTrain Loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(train_loss)\n",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb Cell 48\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(dataloader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataloader), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, (img, sensor,label) \u001b[39min\u001b[39;00m pbar:         \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# img = img.to(device, dtype=torch.float)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# sensor  = sensor.to(device, dtype=torch.float)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# label  = label.to(device, dtype=torch.float)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     batch_size \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     batch \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m:img,\u001b[39m\"\u001b[39m\u001b[39msensor\u001b[39m\u001b[39m\"\u001b[39m:sensor}\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb Cell 48\u001b[0m in \u001b[0;36mBuildDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     img_path  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_paths[index]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     img \u001b[39m=\u001b[39m load_img(img_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     sensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msensors[index]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     sensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(sensor)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39m#[1,n]\u001b[39;00m\n",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb Cell 48\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_img\u001b[39m(path):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     img \u001b[39m=\u001b[39m  Image\u001b[39m.\u001b[39;49mopen(path)\u001b[39m.\u001b[39;49mconvert(\u001b[39m'\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     img \u001b[39m=\u001b[39m myTransforms(img)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/PIL/Image.py:901\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\n\u001b[1;32m    857\u001b[0m     \u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dither\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39mPalette\u001b[39m.\u001b[39mWEB, colors\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m\n\u001b[1;32m    858\u001b[0m ):\n\u001b[1;32m    859\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    903\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    905\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/PIL/ImageFile.py:257\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m         )\n\u001b[1;32m    256\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 257\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    259\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model, history = run_training(model, optimizer, scheduler,device=config.device,num_epochs=config.max_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 384, 384]) torch.Size([4, 1, 17]) tensor([0.2324, 0.2324, 0.2324, 0.2324])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2814811/355586058.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n"
     ]
    }
   ],
   "source": [
    "for (img,sensor,label) in valid_loader:\n",
    "    print(img.shape,sensor.shape,label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'embedding_test_dict.pt')\n",
    "# print(model)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"/home/junsheng/ViLT/wandb/offline-run-20220811_120519-nzfb1xoz/files/epoch-best.bin\"))\n",
    "model.eval()\n",
    "device = config.device\n",
    "model.to(device)\n",
    "def infer(img_filename, sensor):\n",
    "    try:\n",
    "        img_path = os.path.join('pictures',img_filename)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        img = pixelbert_transform(size=384)(image) # 将图像数据归一化torch.Size([3, 384, 576])\n",
    "        img = torch.tensor(img)\n",
    "        img = torch.unsqueeze(img, 0) # torch.Size([1, 3, 384, 576])\n",
    "        img = img.to(device)\n",
    "        print(\"img.shape:\",img.shape)\n",
    "    except :\n",
    "        print(\"图片加载失败！\")\n",
    "        raise\n",
    "\n",
    "    batch = dict()\n",
    "    batch[\"image\"] = img\n",
    "\n",
    "    batch['sensor_masks'] = torch.ones(1,1).to(device)\n",
    "    with torch.no_grad():\n",
    "        batch['sensor'] = sensor.to(device)       \n",
    "        infer = model(batch)\n",
    "\n",
    "        print(infer)\n",
    "        sensor_emb, img_emb = infer[\"sensor_feats\"], infer[\"image_feats\"]# torch.Size([1, 23, 768]) torch.Size([1, 217, 768])\n",
    "        cls_output = infer['cls_output']\n",
    "        \n",
    "\n",
    "    return [cls_output]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5856, 0.6569, 0.7049, 0.7733, 0.5712, 0.3017, 0.5760, 0.2010, 0.5094,\n",
      "        0.5726, 0.4939, 0.3343, 0.6596, 0.6443, 0.5250, 0.8158, 0.3441])\n",
      "img.shape: torch.Size([1, 3, 352, 608])\n",
      "{'cls_feats': tensor([[-5.2343e-01,  9.9633e-01, -5.1836e-01,  6.4402e-01,  9.3081e-01,\n",
      "          7.9111e-01, -4.9137e-01, -9.9849e-01, -4.9404e-02,  2.6968e-01,\n",
      "         -9.9719e-01,  8.2082e-01, -9.8656e-01, -9.3588e-01, -9.7910e-01,\n",
      "          8.6507e-01,  6.6051e-01, -8.3997e-01, -5.1700e-01, -3.1183e-01,\n",
      "         -8.0014e-01,  7.4545e-01,  9.5745e-01,  8.3694e-01,  9.2873e-02,\n",
      "         -8.0556e-01,  3.3933e-01,  7.8950e-01, -5.8535e-01, -5.4122e-01,\n",
      "         -4.6080e-01, -3.1137e-01,  1.3735e-01, -9.8284e-01,  1.6217e-01,\n",
      "          6.0568e-01, -6.8383e-01, -1.0000e-01, -7.9208e-01, -9.7389e-01,\n",
      "          9.9515e-01, -4.3441e-01, -6.4260e-01,  3.6555e-01, -6.5714e-01,\n",
      "         -9.6989e-01, -1.3115e-02,  9.2584e-02,  9.4057e-01, -4.4816e-01,\n",
      "         -3.5038e-01,  2.2354e-01,  5.7295e-01, -6.3738e-01, -9.1979e-01,\n",
      "         -2.7047e-01,  3.9801e-01, -4.8707e-01,  1.8592e-02, -6.9465e-01,\n",
      "         -9.8727e-01, -4.4425e-01,  7.2622e-01,  9.8914e-01,  7.8501e-01,\n",
      "          4.3803e-01,  7.1933e-01, -2.3492e-01,  7.3955e-01, -9.9903e-01,\n",
      "         -9.0384e-01,  9.4630e-01,  9.5007e-02,  2.7558e-01, -6.6458e-02,\n",
      "         -7.9043e-01,  7.3623e-01,  6.8669e-01, -4.7558e-01,  9.8708e-01,\n",
      "         -4.9679e-01,  9.9788e-01, -1.3746e-01, -8.3286e-01, -7.7190e-01,\n",
      "         -3.0994e-01, -4.8298e-01, -5.0751e-01, -7.0768e-01, -3.1079e-03,\n",
      "         -7.8706e-01, -9.8708e-01, -5.7822e-01,  6.3586e-01, -9.0949e-01,\n",
      "          7.4709e-01,  1.1096e-01, -7.9232e-01, -9.3518e-01, -9.9584e-01,\n",
      "          6.6894e-01, -5.2256e-01,  8.9665e-02,  9.9677e-01, -9.2212e-01,\n",
      "         -6.9766e-01, -7.6348e-01,  6.4168e-01,  7.8059e-01, -9.8490e-01,\n",
      "         -5.0653e-01,  1.1290e-01, -7.5792e-01, -9.8263e-01,  6.1461e-03,\n",
      "         -2.0493e-01,  7.3101e-01,  6.0584e-01, -9.9402e-01, -9.7304e-01,\n",
      "          8.5958e-01, -9.5941e-01,  5.0145e-01,  8.9221e-01, -7.7334e-01,\n",
      "          8.3456e-01,  6.2220e-01, -6.7506e-01,  8.1167e-01,  5.0133e-01,\n",
      "         -9.8559e-01,  5.9967e-01, -1.4026e-01,  7.5832e-01, -9.7680e-01,\n",
      "         -8.7953e-01,  3.5914e-01, -9.1312e-01,  9.5351e-01,  8.4461e-01,\n",
      "         -4.1710e-01, -2.5920e-01,  8.1635e-01,  4.1956e-01,  2.4503e-01,\n",
      "          7.2455e-01,  9.5336e-01, -1.8210e-01, -8.8433e-01,  1.0961e-01,\n",
      "          3.9141e-01, -9.1073e-01, -7.0225e-01,  3.0648e-02, -3.9825e-01,\n",
      "         -7.7895e-01,  1.5144e-02,  9.7928e-01,  2.7564e-01,  7.8752e-01,\n",
      "          3.5877e-01, -8.8691e-01, -9.5942e-01,  8.1736e-01, -6.6440e-01,\n",
      "          9.3737e-01, -5.4447e-02, -4.4749e-01,  1.5916e-01,  8.2290e-01,\n",
      "          9.2680e-01,  9.6527e-01, -7.3300e-01, -5.3310e-01,  8.3344e-01,\n",
      "          3.6962e-02,  5.8535e-01, -9.9368e-01, -4.9696e-01,  9.4258e-01,\n",
      "          7.2954e-01,  7.1288e-01,  1.5842e-01, -8.5989e-01,  9.7715e-01,\n",
      "          3.6943e-02,  8.6121e-01,  9.3785e-01, -2.0410e-01, -7.2656e-01,\n",
      "         -1.9830e-01, -7.4641e-01,  9.9098e-01,  8.4592e-01, -2.4594e-01,\n",
      "         -1.1213e-01,  8.9056e-01,  7.7334e-01, -9.3480e-01, -6.6529e-01,\n",
      "          2.5404e-01,  5.3318e-01,  4.3365e-01, -9.2667e-02, -4.3202e-02,\n",
      "         -3.5008e-01, -5.6782e-01, -6.0517e-01, -9.8659e-01, -3.7626e-01,\n",
      "          9.7325e-01, -9.7357e-01, -2.1427e-01, -6.3976e-02, -5.3406e-01,\n",
      "         -1.0516e-02,  9.8095e-01, -2.8597e-02, -4.5738e-01,  9.9806e-01,\n",
      "          4.9036e-01,  6.5067e-01,  9.8291e-01,  9.8351e-01,  6.4468e-01,\n",
      "          4.2133e-01,  1.5318e-01, -8.2400e-01, -6.9661e-01,  9.8845e-01,\n",
      "          3.2693e-01, -7.0160e-01,  7.9192e-01, -9.9023e-01, -5.2303e-01,\n",
      "          2.3366e-01, -3.8856e-01, -1.6109e-01,  8.6715e-01,  9.9352e-01,\n",
      "          9.9669e-01, -8.9435e-01, -5.4480e-01, -9.9477e-01,  1.2119e-01,\n",
      "         -5.0084e-01, -8.8774e-01, -2.6898e-01, -9.5801e-01, -9.8292e-01,\n",
      "          6.7183e-01,  5.4507e-01,  9.8368e-01,  9.7714e-01,  6.6813e-01,\n",
      "         -6.5856e-01, -7.9393e-02, -2.1142e-01, -9.0532e-01, -8.0780e-01,\n",
      "         -7.2907e-01,  7.3739e-01, -4.7270e-01, -9.7594e-01, -9.5495e-01,\n",
      "          9.6244e-01,  9.1962e-01, -9.8734e-01, -9.6201e-01, -6.8423e-01,\n",
      "         -6.7649e-01, -9.8332e-01,  5.5483e-01, -8.4991e-01, -9.8116e-01,\n",
      "          6.0532e-01, -7.7268e-01,  5.7704e-01,  2.5330e-01,  2.6669e-02,\n",
      "         -7.3051e-01,  8.1901e-01,  5.3058e-01,  5.2546e-01,  9.6430e-01,\n",
      "          4.4592e-01, -6.5772e-01,  4.3096e-01,  3.4031e-01,  2.1779e-01,\n",
      "          6.9833e-01, -8.2134e-01,  2.9554e-02, -9.8655e-01,  6.9820e-01,\n",
      "          4.9975e-01,  9.4513e-02, -9.9150e-01, -2.8702e-01, -7.3656e-01,\n",
      "         -4.2763e-01,  5.9192e-01,  7.0785e-01, -6.1457e-01, -9.4312e-01,\n",
      "          9.7511e-01, -9.3675e-01,  3.5997e-01, -9.9831e-01,  7.4196e-01,\n",
      "         -1.7183e-01, -4.8862e-01, -5.0772e-01,  8.8758e-01, -4.0263e-02,\n",
      "          8.3482e-01, -9.7333e-01, -8.2058e-01, -2.8973e-01, -4.7095e-01,\n",
      "         -9.8896e-01, -5.5822e-01,  1.0751e-01, -9.0388e-01, -9.7592e-01,\n",
      "         -9.6603e-01, -4.6431e-04,  6.7249e-01,  4.3109e-02, -6.8746e-01,\n",
      "          7.4472e-01,  2.7132e-02, -6.2071e-01, -2.0240e-01, -5.0055e-01,\n",
      "          4.0770e-01, -5.0161e-02,  8.7470e-01,  3.1964e-01,  8.5037e-03,\n",
      "          7.4736e-01,  9.4990e-01, -5.9195e-01, -7.9586e-01,  8.0194e-01,\n",
      "          8.1935e-01, -6.2301e-02,  6.5118e-01, -9.5388e-01, -1.0997e-01,\n",
      "         -9.9878e-01,  8.0310e-01,  9.9350e-01,  7.4620e-01, -1.2872e-01,\n",
      "          6.7066e-01,  4.8000e-01,  5.1769e-01, -6.7818e-01, -1.2028e-01,\n",
      "         -8.0262e-01,  1.2461e-01,  5.0475e-01, -9.8050e-01, -6.3276e-01,\n",
      "         -3.5554e-02, -8.2412e-01, -6.8331e-01,  7.0442e-01,  9.3239e-01,\n",
      "          2.4708e-01,  5.2353e-01, -6.6923e-01, -6.8431e-01, -4.1679e-01,\n",
      "         -7.6558e-01,  5.6368e-01,  7.6726e-01,  5.9029e-01, -8.0724e-01,\n",
      "          8.9646e-01, -1.3143e-01, -1.3441e-01,  5.1014e-01,  4.0192e-01,\n",
      "          9.2316e-02, -2.9614e-01,  7.5210e-02,  9.9361e-01, -1.4326e-01,\n",
      "         -7.0115e-01,  2.6862e-01, -2.4919e-02, -8.6407e-02, -3.1110e-02,\n",
      "         -9.3832e-01,  4.7572e-02,  1.8639e-01,  1.3618e-01,  7.0290e-01,\n",
      "         -4.7132e-01,  1.9242e-01, -4.4251e-01, -4.3895e-01,  6.2704e-01,\n",
      "         -8.5447e-02,  5.2882e-01,  6.7987e-01,  2.6260e-01, -6.6921e-01,\n",
      "         -1.1075e-01,  9.8405e-01,  7.7670e-01, -6.4767e-01, -2.8178e-01,\n",
      "          5.0215e-01,  6.0933e-01,  2.4213e-02, -4.7271e-01, -3.8421e-01,\n",
      "         -9.7693e-01,  9.9263e-01, -5.4396e-01, -5.9164e-02, -6.2684e-01,\n",
      "         -1.8340e-02,  6.6924e-01,  2.5006e-03, -8.3613e-01,  1.6479e-01,\n",
      "          9.2922e-01, -9.8933e-01, -6.0236e-01,  3.4786e-01, -9.4357e-01,\n",
      "          3.4028e-01,  9.2641e-01, -1.6837e-02, -9.5471e-01, -9.8731e-01,\n",
      "         -4.9731e-01,  3.5952e-01, -3.7906e-01, -9.2048e-01, -2.1302e-01,\n",
      "          1.3301e-01,  5.8536e-01, -2.6934e-01,  9.7609e-01,  2.1008e-01,\n",
      "         -5.9529e-01,  1.5705e-03,  8.6830e-01,  7.4886e-02, -2.0666e-01,\n",
      "         -5.5846e-01, -4.3759e-01,  2.2934e-01, -8.1963e-01,  9.2176e-01,\n",
      "         -8.4801e-01,  9.2510e-01, -2.1295e-01, -7.9556e-01, -5.0008e-01,\n",
      "          9.6981e-01, -5.4573e-01, -5.1053e-01, -9.2296e-01,  2.9592e-01,\n",
      "         -5.4276e-01,  4.8365e-01,  9.6401e-01,  4.7087e-01,  5.4157e-01,\n",
      "          9.4224e-01, -6.5805e-01, -7.3420e-01, -9.9131e-01, -5.7159e-01,\n",
      "          9.9356e-01, -4.8779e-01, -9.8198e-01,  8.0914e-01, -5.5102e-01,\n",
      "         -8.9241e-01, -8.0507e-01,  4.3756e-02,  1.0942e-02,  1.0289e-01,\n",
      "          9.0970e-01, -9.8953e-01, -4.4860e-01, -5.7797e-01,  9.5806e-01,\n",
      "         -4.3734e-01, -7.6350e-01,  6.3200e-01, -9.0620e-01, -6.5687e-01,\n",
      "         -8.2853e-01, -3.0440e-01,  8.7933e-01,  8.6093e-01,  2.0685e-01,\n",
      "          7.0202e-01,  9.5100e-01,  3.7496e-01,  3.4178e-01,  9.0228e-01,\n",
      "         -9.6835e-01,  5.3546e-01, -6.6754e-01,  7.4720e-01,  8.2388e-01,\n",
      "         -6.6620e-01, -9.3110e-01, -1.4244e-01,  7.2384e-01, -4.9760e-01,\n",
      "          7.1840e-01,  6.8176e-01,  2.2391e-01, -1.0357e-01, -8.8481e-01,\n",
      "         -1.7582e-01, -7.2237e-01, -8.0556e-01, -7.1194e-01, -6.3745e-01,\n",
      "          8.8327e-01,  8.7374e-01, -8.3239e-01,  8.1547e-01,  4.8119e-01,\n",
      "          5.0592e-01, -9.5337e-01,  3.1887e-02, -2.8192e-01,  4.7939e-01,\n",
      "          7.2237e-02,  9.2936e-01,  7.3387e-01,  5.2616e-01,  6.0608e-01,\n",
      "          9.3667e-01, -8.2244e-01,  8.4849e-01,  5.2205e-01, -7.0630e-01,\n",
      "          9.7948e-01, -4.9668e-01, -9.8706e-01,  7.4959e-01, -4.8537e-01,\n",
      "         -5.1444e-01, -9.4134e-01,  9.9446e-01, -8.4229e-02, -2.7893e-01,\n",
      "          2.0444e-01,  7.5811e-01, -9.0320e-01,  7.8168e-02,  4.6758e-01,\n",
      "          9.2966e-01,  8.1607e-01,  3.6385e-01,  3.4137e-02, -2.4033e-01,\n",
      "          9.5783e-01, -8.8903e-01,  9.6780e-01, -9.5232e-01, -4.5445e-01,\n",
      "         -4.7219e-01,  1.9394e-01,  7.4011e-01,  8.0533e-01, -9.1167e-01,\n",
      "         -5.0869e-01, -9.2964e-01, -9.8824e-01,  2.5929e-01,  9.6533e-01,\n",
      "         -8.7014e-01,  6.0811e-01,  8.7299e-01,  8.2985e-01,  4.7614e-01,\n",
      "          9.3243e-01,  8.7013e-01,  7.0473e-01, -3.9552e-01,  5.6002e-01,\n",
      "          7.5001e-01,  9.1428e-01,  7.0532e-01, -4.7976e-01, -4.9264e-01,\n",
      "         -3.1857e-01, -9.9691e-01,  4.3555e-01,  9.8918e-01, -7.3742e-01,\n",
      "         -5.2611e-01, -1.3536e-02, -8.1699e-01, -9.8752e-01,  5.5976e-02,\n",
      "          2.5689e-01, -9.9159e-01, -7.0149e-01,  9.7580e-01, -2.2788e-01,\n",
      "         -9.7247e-01,  9.9647e-01, -6.9489e-01,  8.2745e-01, -8.6422e-01,\n",
      "          7.6774e-01,  8.6401e-01,  2.8978e-01, -7.0278e-01,  9.6575e-01,\n",
      "          9.2253e-01, -6.2670e-01, -5.0147e-01,  5.2607e-01,  6.5495e-01,\n",
      "          6.4618e-01,  7.2554e-01, -1.9550e-01, -5.1984e-01, -9.6999e-01,\n",
      "          2.9689e-01, -9.4536e-01, -8.1686e-01,  6.3149e-01,  2.6699e-01,\n",
      "          1.9891e-01,  8.2737e-01,  5.9905e-01, -4.7301e-01,  6.5242e-01,\n",
      "          6.5920e-01, -3.0405e-01,  4.6985e-01,  4.8359e-01, -1.0032e-01,\n",
      "         -9.5101e-01, -6.3368e-01, -3.3293e-02, -9.8226e-01,  7.9572e-01,\n",
      "         -2.3431e-01, -9.9699e-01, -4.1648e-01,  4.7613e-01, -6.7335e-01,\n",
      "          9.3508e-01,  5.6498e-01,  2.6159e-01,  6.7750e-01, -4.7318e-01,\n",
      "         -3.2485e-01,  7.9221e-01, -4.9239e-01, -3.4132e-01, -9.3145e-01,\n",
      "         -9.1924e-01,  9.8792e-01, -1.9545e-02,  2.8416e-01, -8.4030e-01,\n",
      "         -9.9474e-01, -9.5419e-01,  2.7423e-01,  3.8807e-01,  9.0787e-01,\n",
      "         -2.2763e-01,  3.8173e-02, -8.7891e-01,  7.6088e-01, -9.8842e-01,\n",
      "          2.0422e-01,  6.2561e-01,  5.9802e-01,  4.5542e-02,  5.9938e-02,\n",
      "         -8.7194e-01,  5.1692e-01,  4.0332e-01, -7.3097e-01, -9.3194e-04,\n",
      "         -6.3886e-01, -2.9002e-02,  6.4738e-01,  9.2560e-01, -8.2393e-01,\n",
      "          1.1107e-01,  6.8518e-01, -4.9937e-01,  5.7029e-01,  2.0562e-01,\n",
      "          7.5180e-02,  5.5131e-01,  1.5039e-01,  2.1509e-01, -5.4633e-01,\n",
      "         -4.5688e-01,  1.1479e-01,  4.5874e-01, -1.4683e-01,  3.0188e-02,\n",
      "          5.6022e-02,  2.1042e-01, -6.9678e-01,  2.5526e-01, -7.5268e-01,\n",
      "          8.4637e-01,  4.8764e-02,  4.9220e-01, -5.8370e-01,  6.6432e-01,\n",
      "          1.4453e-02, -9.9895e-02, -9.7226e-01,  1.2803e-01,  9.2890e-01,\n",
      "          5.5295e-01,  3.6650e-01, -7.5403e-01,  9.1552e-01,  7.5448e-01,\n",
      "          8.5899e-01, -6.3385e-01,  1.5180e-01, -9.6452e-01, -2.8306e-01,\n",
      "         -2.5677e-01,  6.2422e-01, -9.1621e-01, -9.1757e-01,  6.6670e-01,\n",
      "          4.4019e-01, -4.6841e-01,  9.0127e-01, -4.1798e-01, -4.1380e-01,\n",
      "         -8.7464e-01, -9.6244e-01,  8.0683e-01, -9.6272e-01, -4.4380e-01,\n",
      "         -7.9892e-01, -8.0555e-01, -6.2053e-01,  2.8099e-01,  6.9889e-01,\n",
      "         -6.7496e-02, -8.0736e-01,  4.9869e-01,  6.6122e-01,  7.0563e-02,\n",
      "          7.6341e-01,  3.4772e-01, -8.0573e-02]], device='cuda:0'), 'raw_cls_feats': tensor([[ 3.6141e-01,  1.8783e-01, -2.5118e-01, -2.1372e-01, -2.0064e-01,\n",
      "          2.2511e-01,  4.9391e-01, -1.8006e-01, -1.7816e-01,  1.7227e-01,\n",
      "         -1.0366e+00,  1.8195e-01,  7.5035e-01, -8.3817e-01, -9.1426e-02,\n",
      "         -3.7827e-01, -2.0228e-01, -1.4029e-01, -2.6218e-01, -1.0299e+00,\n",
      "          2.3659e-01,  1.5225e+00, -4.2063e-02, -1.3936e-01, -2.8206e-01,\n",
      "          8.1367e-01,  1.3670e-01,  1.4476e-01,  1.0514e-01,  5.3516e-01,\n",
      "         -3.5975e-01,  1.2692e-01,  3.1651e-01, -9.9555e-02, -9.6212e-01,\n",
      "         -1.8202e-02, -1.0860e-01,  3.1515e-01, -1.8154e-01,  9.0375e-01,\n",
      "         -4.4720e-01,  1.9494e-01,  1.8012e+00,  2.0789e-01,  3.1376e-01,\n",
      "         -1.2277e-02, -8.5278e-01, -1.3594e-02, -2.8682e-01,  3.2175e-01,\n",
      "          1.6123e+00,  1.8164e-01,  9.2958e-02, -1.1438e-02, -3.4389e-01,\n",
      "          8.4560e-01, -6.1685e-01, -1.2044e+00, -5.0754e-01,  2.7275e-01,\n",
      "         -2.7564e-01, -1.1272e-01,  5.3443e-01, -1.5125e-01,  5.6747e-01,\n",
      "         -6.8758e-01,  2.7512e-01, -1.1831e+00, -4.9383e-01,  3.0679e-01,\n",
      "          4.7814e-01, -7.7972e-01,  1.7903e-02,  4.7300e-01, -9.0445e-01,\n",
      "         -5.0180e-01, -7.0474e-01,  1.9097e-01,  6.8179e-01,  2.9668e-01,\n",
      "         -3.4728e-01, -9.7269e-02,  4.0982e-01,  1.3458e-01, -2.7922e-02,\n",
      "         -1.3426e-01, -3.5676e-01,  1.3542e-01,  3.3235e-01,  1.3566e-01,\n",
      "         -1.7860e-01,  7.8745e-01, -6.3247e-01,  9.9996e-02, -2.4067e-01,\n",
      "          1.2761e-01,  1.3643e-01, -2.2845e-01, -5.2688e-02,  1.9491e-01,\n",
      "         -2.5006e-01, -6.6345e-01,  1.3490e+00,  5.6771e-01,  1.0902e+00,\n",
      "          2.4159e-01,  5.1233e-01,  5.0241e-01, -1.7637e-01,  1.4951e-01,\n",
      "         -3.0246e-01,  8.1355e-01, -4.2599e-01,  1.9376e-01,  6.6600e-02,\n",
      "          3.1021e-01, -1.9679e+00,  7.5624e-01, -1.5580e+00,  1.4198e+00,\n",
      "          8.0889e-02, -4.7138e-01,  8.3884e-01, -2.8818e-01,  3.2342e-01,\n",
      "         -8.1441e-02,  5.4173e-02,  2.9429e-01, -7.8723e-02,  4.4672e-02,\n",
      "         -2.0853e-01,  1.3940e-01,  3.2705e-01, -4.0429e-01, -6.4130e-01,\n",
      "         -1.2582e-01,  1.0631e+00, -1.2624e+00, -3.8735e-01, -1.4381e+00,\n",
      "          2.9748e-01,  1.9450e-01,  1.8913e-01,  5.1301e-02, -4.7790e-01,\n",
      "         -8.2352e-01,  6.9919e-01, -2.2287e-01, -4.3648e-01,  1.5148e-01,\n",
      "          3.0398e-01,  4.8202e-01, -6.0599e-02,  1.8565e-01, -8.9838e-02,\n",
      "         -3.6070e-01, -3.1795e-01, -1.1437e-01, -2.9838e-02, -2.4669e-01,\n",
      "         -1.5472e-01,  9.9204e-02,  7.5056e-01, -1.2459e-01, -2.9928e-01,\n",
      "          2.8351e-01,  1.0541e-01, -4.8948e-01, -6.2255e-01, -4.5492e-01,\n",
      "          1.3628e-01, -1.3800e-01, -5.2081e-01, -1.6475e-01,  7.1306e-01,\n",
      "          6.7791e-02, -5.9091e-01,  2.3329e-01,  6.5180e-01, -4.2753e-02,\n",
      "          4.2395e-01, -6.1271e-01, -3.4893e-02,  2.7484e+00,  3.0263e-01,\n",
      "          1.2910e-02,  5.4291e-02,  5.5344e-01, -1.8447e-01, -1.1562e+00,\n",
      "         -1.0232e+00,  1.3854e-01, -3.6121e-01,  4.1101e-01, -3.0472e-01,\n",
      "         -3.0795e-01, -2.5360e+00, -1.7292e-01,  3.9385e-01,  1.6317e-01,\n",
      "          4.9976e-02, -4.9729e-02, -7.0128e-01, -2.6239e-01,  1.3530e-01,\n",
      "          2.8515e-01,  1.0923e+00, -1.0287e+00, -1.6339e-01, -5.1318e-01,\n",
      "         -7.5237e-01, -1.8696e-01, -3.0894e-02, -7.9202e-01,  1.3931e-01,\n",
      "          1.7963e-01, -1.9760e-01,  1.5253e+00,  1.0185e+00, -2.8782e-01,\n",
      "         -2.2469e-01,  3.1202e-01, -3.6777e-01,  3.9526e-01,  9.6423e-03,\n",
      "         -3.4280e-01,  1.6735e+00, -9.8565e-01,  4.7171e-01,  7.0436e-01,\n",
      "          4.4518e-01,  1.0640e-01,  2.4685e-01,  3.2912e-01,  6.1504e-02,\n",
      "          1.2171e-01,  1.2241e+00,  2.7514e-01,  3.0776e-01, -5.5756e-01,\n",
      "         -3.6855e-01,  1.2199e-02,  2.1865e-01,  4.4385e-02, -3.8125e-02,\n",
      "          1.0691e-01, -1.0914e+00,  2.0344e-01, -8.9704e-01, -5.7838e-01,\n",
      "         -7.1739e-01, -2.6323e-01,  1.2784e+00, -2.2725e-01, -8.7587e-01,\n",
      "          7.0854e-01,  1.0101e-02, -6.0122e-01, -6.4441e-01, -6.5333e-02,\n",
      "         -1.2896e-01,  1.0322e+00,  2.7711e-01,  4.0304e-01, -5.9419e-01,\n",
      "          1.3105e-01, -4.9334e-01, -1.6156e-01, -2.3407e-01,  5.3276e-01,\n",
      "         -3.1175e-01,  9.9868e-01, -8.3771e-01, -3.5210e-01,  2.8047e-01,\n",
      "         -6.5955e-02,  5.3440e-01,  3.0302e-02,  2.4380e-01,  5.6613e-01,\n",
      "         -1.4243e+00, -4.1872e-01,  4.1091e-01, -5.7796e-02, -7.9466e-02,\n",
      "         -2.8463e-02, -1.5350e+00,  1.0740e+00,  1.9164e-01, -1.4932e+00,\n",
      "          3.0814e-01,  5.5493e-01,  4.7860e-01, -1.1166e-01,  7.6016e-01,\n",
      "          2.2744e-01, -4.7271e-01,  4.8701e-02,  6.4194e-02, -1.0392e-02,\n",
      "          6.9148e-01,  1.7180e-01,  7.7798e-01,  1.9327e-01, -8.0282e-02,\n",
      "          1.3083e+00, -3.8224e-01, -2.1326e+00,  2.7248e-01, -2.2107e-01,\n",
      "         -7.1411e-01,  3.4170e-02,  7.6398e-01,  5.5461e-01,  1.6145e-01,\n",
      "         -4.9207e-01, -1.9328e-01, -3.5925e-01, -1.9313e-01,  8.4558e-02,\n",
      "         -2.1956e-01,  6.2709e-02,  3.8056e-01, -1.1715e+00,  1.2507e+00,\n",
      "          7.5341e-01,  4.7601e-03,  1.2108e-01,  4.2858e-02, -1.4963e-01,\n",
      "          6.9744e-02, -3.3031e-02,  5.5824e-01, -1.4313e-01,  2.2888e-01,\n",
      "         -1.7835e+00,  2.9494e-02,  7.4150e-01, -1.5285e+00,  6.6385e-02,\n",
      "         -1.2942e-01, -8.1099e-02,  3.7888e-01, -1.2779e+00, -8.2192e-03,\n",
      "          1.2207e-01,  1.1682e-01, -6.5582e-02,  7.9604e-01,  4.2965e-02,\n",
      "         -5.2719e-01, -9.0650e-02,  3.8344e-01,  1.5755e-01, -1.4409e-01,\n",
      "         -1.4299e-01, -4.4631e-02,  1.1547e+00,  8.4257e-02, -7.3913e-02,\n",
      "          3.7420e-02,  1.9368e-02, -9.1159e-01, -1.0381e-01, -1.2790e-01,\n",
      "          6.8796e-02, -8.3030e-01,  1.8294e+00,  7.5514e-02,  1.5400e-01,\n",
      "          4.7335e-02, -4.6910e-02, -5.2099e-01, -1.3934e-02,  3.3685e-01,\n",
      "         -6.2170e-02,  6.4318e-01, -2.1332e-01,  1.2560e-01, -1.7763e+00,\n",
      "         -1.6257e-01,  1.4458e+00,  8.3854e-01, -2.9601e-01, -9.0302e-01,\n",
      "          5.1080e-01,  4.9115e-01, -5.6607e-01, -1.9074e-01,  1.6628e-01,\n",
      "          6.3428e-01, -2.7575e-01,  1.4047e-01, -1.3659e-02, -6.4137e-01,\n",
      "          8.8691e-02, -4.8521e-01, -1.7768e-01, -3.3242e-01,  3.1005e-01,\n",
      "          1.5338e+00,  1.3934e-01,  1.4667e+00, -1.4961e-01, -1.8071e-01,\n",
      "         -3.3447e-01, -3.3197e-01, -8.5642e-02, -3.9016e-01,  1.8604e-02,\n",
      "          1.3910e-01,  1.0303e+00, -4.4773e-01,  1.4105e+00,  2.5487e-04,\n",
      "         -1.6540e-01, -1.4809e-01, -8.0690e-01, -2.9987e-01,  1.0153e-01,\n",
      "          7.1024e-01, -2.2234e+00, -2.1919e-01,  4.8566e-01,  3.4131e-01,\n",
      "         -4.5895e-01,  7.1482e-03,  1.5712e+00,  3.6831e-01, -1.6472e-01,\n",
      "          1.1023e+00, -5.0193e-02,  5.5119e-01,  6.6225e-01, -1.7613e-01,\n",
      "         -7.8425e-01, -7.2546e-02,  2.5477e-03,  1.2285e+00, -5.4523e-01,\n",
      "         -2.2095e-01, -1.6251e-01,  3.9068e-02,  8.1254e-02, -1.6907e-01,\n",
      "         -1.0706e-01,  7.4865e-01, -4.2230e-01,  3.7757e-02, -3.2343e-01,\n",
      "          3.9717e-01, -5.1432e-01, -7.5875e-01, -3.5605e-01,  1.5851e-01,\n",
      "          3.5527e+00,  8.0533e-02,  5.1695e-01,  4.4302e-01, -1.2075e+00,\n",
      "          1.3579e-01, -3.9402e-01, -2.7582e-01, -1.5794e+00, -2.3858e-01,\n",
      "          4.7786e-01,  6.2589e-01, -2.5873e-01,  3.4153e-01, -1.1612e-01,\n",
      "          6.0556e-01,  1.3539e+00,  2.6564e-01,  7.2777e-01,  6.5187e-01,\n",
      "         -1.3997e-01, -1.2468e+00, -2.8860e-01,  2.5193e-01,  6.2410e-01,\n",
      "         -6.0291e-01,  9.3986e-01, -3.8622e-02,  2.2620e+00, -9.9658e-01,\n",
      "         -5.9927e-02,  1.0738e-01, -4.6963e-01, -1.0800e-01,  2.3645e-01,\n",
      "          2.2922e-01,  4.8996e-01,  5.3180e-03, -4.2303e-01,  4.2152e-01,\n",
      "          2.4483e-01, -1.0446e-01, -9.0235e-03,  5.5988e-02, -5.4361e-01,\n",
      "         -9.4726e-02,  1.3711e-01,  1.3261e-01, -8.3704e-01,  3.2028e-02,\n",
      "          6.4740e-02,  5.8703e-01, -4.5175e-01, -2.4937e-01, -2.1753e-01,\n",
      "          4.1036e-01, -3.0445e-01,  2.6378e-01,  5.4252e-02,  1.4708e-01,\n",
      "          6.8799e-02,  1.7101e+00, -1.7207e-01,  1.2823e-01,  1.0606e-02,\n",
      "          2.5837e-01, -9.1240e-01,  7.5754e-01,  2.1670e-01,  5.4462e-01,\n",
      "         -7.3954e-01,  1.0807e-01,  2.5826e-01, -3.6903e-01,  7.4907e-02,\n",
      "         -1.5663e+00,  2.8731e-01, -2.7757e-01, -1.1086e+00, -2.9698e-02,\n",
      "          1.1031e+00, -8.2232e-02,  4.0823e-01,  1.3436e-01,  3.6211e-01,\n",
      "         -1.1789e-01,  5.4855e-01, -7.9354e-02, -2.5202e-01,  3.5308e-01,\n",
      "         -1.0268e+00, -2.2930e+00, -6.3424e-01, -4.8592e-01, -1.3931e-01,\n",
      "         -7.7932e-01,  2.1263e-01,  3.3939e-01,  1.8741e-01,  1.2362e+00,\n",
      "         -1.5468e-01,  1.2159e-01, -3.4168e-01, -1.0146e+00,  9.2046e-02,\n",
      "         -7.8857e-01,  1.5237e+00, -1.6068e-01, -1.2770e+00, -2.6015e-01,\n",
      "         -5.1607e-01, -4.1691e-01, -9.3378e-02, -2.7196e-01, -4.1529e-02,\n",
      "         -3.6846e-01, -3.9113e-01, -1.1271e-01, -1.0781e+00, -9.1762e-01,\n",
      "          3.6116e-02,  2.7318e-01,  8.0323e-01,  1.0957e+00,  5.2680e-01,\n",
      "         -5.9688e-01,  6.5722e-01, -4.3400e-03, -4.0275e-01,  2.0063e-01,\n",
      "          1.1793e+00, -1.8831e-01,  2.9897e-01, -4.5800e-01,  4.2527e-01,\n",
      "         -1.1238e-01,  4.8622e-01, -4.4368e-02,  2.0022e-01,  8.5428e-01,\n",
      "         -1.9050e-01, -7.1300e-01, -5.4713e-01, -1.4193e+00, -4.5831e-01,\n",
      "         -3.9267e-01, -2.6223e-01,  3.2148e-01,  2.6584e-01, -1.8345e-01,\n",
      "          2.2002e-01, -5.5194e-02,  1.8837e-02, -3.4867e-01, -3.8827e-01,\n",
      "          5.5706e-01,  1.1729e-01,  3.4947e-02, -4.6280e-02, -1.5734e-01,\n",
      "         -3.6808e-01,  3.5252e-01, -6.6831e-01, -2.2464e-01, -1.0933e-01,\n",
      "          1.0385e-01,  1.6952e+00, -1.1173e-02, -5.9923e-01,  2.9967e-01,\n",
      "         -1.5008e+00, -5.3448e-01, -3.1220e-01,  5.2456e-01, -1.8693e-02,\n",
      "         -7.8182e-01, -1.3794e-01, -7.3384e-03,  1.3896e+00,  1.4557e-01,\n",
      "          1.8207e-01, -3.1368e-01, -4.6805e-01,  9.9373e-01,  1.9465e-02,\n",
      "          4.6107e-01, -3.5058e-01, -6.6206e-01,  1.1131e-01, -5.7408e-02,\n",
      "          9.4779e-03,  1.1369e+00, -4.1586e-01, -2.0638e-01,  9.4523e-01,\n",
      "         -3.3693e-01,  5.5346e-01, -5.8792e-01, -2.3113e-01, -1.6025e+00,\n",
      "         -1.1285e+00, -1.4524e-01, -5.3540e-01, -1.1117e-01, -7.3863e-01,\n",
      "         -6.7735e-01,  2.8283e-02, -2.6253e-01,  6.1929e-01,  5.4047e-02,\n",
      "         -6.7219e-01, -2.8554e-01, -4.1939e-01,  3.1495e-01, -1.8739e-01,\n",
      "         -4.1693e-02, -4.5979e-01,  4.5192e-01, -4.8012e-01, -3.3711e-02,\n",
      "          4.1479e-01, -6.5328e-02,  5.2425e-01,  1.9785e-01, -5.6609e-01,\n",
      "         -3.2467e-01, -5.2471e-02,  1.2086e-01,  1.4986e+00,  1.3603e-01,\n",
      "          1.7344e-01,  1.2870e-01, -1.6262e-01,  8.0659e-01, -2.4519e-01,\n",
      "          2.3715e-01,  1.1510e-01, -5.6863e-02, -1.2018e-01,  2.3909e-01,\n",
      "          1.2114e-01,  6.3079e-01,  6.2645e-01,  4.6555e-01, -5.4708e-02,\n",
      "         -4.6541e-02,  4.0027e-01,  6.9259e-01,  8.7214e-02,  2.0612e-01,\n",
      "         -5.3998e-02,  4.1471e-01, -7.9228e-02,  5.7908e-02,  1.1615e+00,\n",
      "          2.0102e-01,  9.8402e-02, -1.2653e-01,  7.4995e-01,  4.7595e-01,\n",
      "          6.7151e-02,  1.7791e+00, -1.0141e-01,  1.0157e+00,  3.4430e-01,\n",
      "          7.3884e-01,  1.6394e+00,  3.2678e-01,  6.6538e-02,  5.3459e-01,\n",
      "          9.8108e-01, -9.4314e-02,  5.3482e-01, -4.9282e-01, -4.2414e-01,\n",
      "         -2.8435e-01, -6.8044e-01,  4.2793e-02,  3.3622e-02,  3.6986e-02,\n",
      "         -2.8776e-01, -4.5757e-01, -1.2858e-01, -2.0392e-01, -8.0276e-01,\n",
      "         -2.6076e-01, -3.6907e-02,  6.0854e-01,  3.2036e-02, -1.5283e+00,\n",
      "          3.3677e-01, -1.5704e+00, -2.9618e-02,  1.4755e-02, -9.8264e-01,\n",
      "          3.1663e-01,  7.6537e-01,  5.3900e-01,  2.4820e-01, -2.4555e+00,\n",
      "         -5.7393e-01, -1.5145e+00,  9.4313e-01,  6.8171e-01, -1.1194e+00,\n",
      "         -3.3067e-01, -9.0128e-01, -1.2980e-01,  2.4624e-01, -3.1765e-01,\n",
      "          1.2456e-01, -1.0228e-01, -6.5110e-01]], device='cuda:0'), 'cls_output': tensor([[0.7303]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2814811/3499233738.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sensor =  torch.tensor(sensor).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 3])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sensor_feats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb Cell 53\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(sensor)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m sensor \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mtensor(sensor)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39m# torch.Size([1, 1, 3])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m out \u001b[39m=\u001b[39m infer(examples[\u001b[39m0\u001b[39;49m],sensor)\n",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb Cell 53\u001b[0m in \u001b[0;36minfer\u001b[0;34m(img_filename, sensor)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     infer \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mprint\u001b[39m(infer)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     sensor_emb, img_emb \u001b[39m=\u001b[39m infer[\u001b[39m\"\u001b[39;49m\u001b[39msensor_feats\u001b[39;49m\u001b[39m\"\u001b[39;49m], infer[\u001b[39m\"\u001b[39m\u001b[39mimage_feats\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m# torch.Size([1, 23, 768]) torch.Size([1, 217, 768])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     cls_output \u001b[39m=\u001b[39m infer[\u001b[39m'\u001b[39m\u001b[39mcls_output\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [cls_output]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sensor_feats'"
     ]
    }
   ],
   "source": [
    "\n",
    "examples=[\n",
    "            \"/home/junsheng/data/xiangguan/pic/xiangguanD4-2021-05-24-10-00-25.jpeg\", #0\n",
    "            \n",
    "            \"/home/junsheng/data/xiangguan/pic/xiangguanD4-2021-07-18-04-22-30-preset-18.jpeg\", # 3\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "n = 1\n",
    "sensor = torch.rand(config.senser_input_num)\n",
    "# sensor = torch.ones(config.senser_input_num)\n",
    "print(sensor)\n",
    "sensor =  torch.tensor(sensor).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 3])\n",
    "out = infer(examples[0],sensor)\n",
    "# print(\"out:\",out,\"000\\n\")\n",
    "# print(\"out0.shape:\",out[0].shape)\n",
    "# cv2.imwrite('output.png',out[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.8166]], device='cuda:0')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8166\n"
     ]
    }
   ],
   "source": [
    "print(out[0].cpu().numpy()[0][0])\n",
    "#0.00031266143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test by valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择三组生长期不同的数据去验证训练的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.query(\"fold==0\").reset_index(drop=True)\n",
    "df_test.to_csv(\"test_by_valid.csv\",index=False)\n",
    "sensor_test_list = df_test.sensor.tolist()\n",
    "image_test_list = df_test.image_path.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: torch.Size([1, 3, 352, 608])\n",
      "{'sensor_feats': tensor([[[ 2.7024e-01,  8.4886e-01,  3.5035e-01,  5.3281e-02,  5.2474e-02,\n",
      "          -1.7046e-01,  7.3329e-02,  3.0590e-02,  6.7037e-02, -3.7755e-01,\n",
      "          -8.7652e-01,  1.3844e-01,  2.5090e-01, -3.3451e-01, -1.6991e-01,\n",
      "          -2.3502e-02, -6.9722e-02, -1.1445e-01, -1.7391e-01,  3.5070e-01,\n",
      "          -1.2979e+00,  2.7135e-01, -6.4320e-02, -9.8884e-01,  3.2600e-02,\n",
      "          -4.4981e-01,  1.7270e-01,  3.7485e-01, -8.4396e-01, -6.4098e-02,\n",
      "           1.6703e-01,  3.6598e-01, -4.2784e-02, -1.1087e-01,  1.1336e-02,\n",
      "          -2.0030e+00, -7.8494e-01, -9.4766e-02, -1.2019e-01,  1.6362e-01,\n",
      "          -1.2572e-01,  2.2219e-01, -3.8874e-02,  6.9456e-01, -6.6659e-01,\n",
      "          -7.5572e-02, -6.5935e-02, -2.7468e-02,  1.0221e+00, -2.5591e-01,\n",
      "           1.8912e-01, -5.2756e-01,  4.2142e-02,  1.3391e+00,  6.7435e-02,\n",
      "           9.3807e-01,  1.4467e+00,  4.8933e-01,  2.6360e-01, -6.8080e-02,\n",
      "           1.7264e-01,  7.1070e-02,  3.0559e-01,  1.0487e+00, -1.0531e-01,\n",
      "           1.4899e-01, -1.4601e-01,  7.0311e-02, -6.1047e-01,  3.2517e-01,\n",
      "           9.6615e-02, -4.9635e-01,  3.9653e-01, -8.1497e-01,  4.3536e-01,\n",
      "          -1.7965e-01, -1.8054e-02, -7.7346e-02,  3.7056e-01, -1.1527e-01,\n",
      "          -5.1328e-02,  2.2571e-01, -1.4052e-01,  3.9916e-01, -1.5368e+00,\n",
      "          -2.2687e-01,  6.8785e-01,  4.7555e-03,  4.0235e-01, -3.9818e-01,\n",
      "           4.5255e-01,  1.8249e-01,  2.4254e-02,  5.4363e-01,  3.1668e-01,\n",
      "           1.4741e-01, -1.2045e+00,  5.6026e-01,  1.8129e-02, -5.2342e-01,\n",
      "          -2.5647e-01, -5.9585e-01,  1.6685e-01, -2.0819e-01, -2.7393e-01,\n",
      "          -5.4547e-02,  8.3671e-01,  1.0122e+00,  3.0082e-01, -4.0947e-01,\n",
      "          -3.5765e-01, -8.6501e-04,  1.6294e-01, -4.0080e-01, -8.3902e-01,\n",
      "           2.2061e-01, -4.1820e-02, -4.1544e-01, -2.5201e+00, -9.8932e-02,\n",
      "          -5.8175e-01, -7.2491e-02, -8.2113e-01, -1.3048e-01, -4.9790e-01,\n",
      "          -2.5302e-01,  9.9828e-02,  3.8401e-01, -1.0704e-01, -1.3460e-01,\n",
      "          -5.2490e-01,  1.6422e-01, -7.2538e-02,  3.1729e-01, -1.8784e-01,\n",
      "           8.4847e-01,  2.7782e-01,  3.9456e-01,  7.3581e-01, -4.6038e-01,\n",
      "          -1.2405e-01,  3.6507e-01,  1.0595e+00, -3.3720e-01, -1.7847e-01,\n",
      "           6.9445e-02,  5.5660e-02,  6.6612e-01, -1.5342e-01, -1.0245e-01,\n",
      "          -4.1698e-01, -4.7990e-01, -4.3741e-02,  7.5446e-01, -8.5839e-01,\n",
      "          -2.9759e-01,  7.4105e-02,  3.6936e-01,  2.2517e-01,  2.0445e-01,\n",
      "          -2.2520e-01, -7.0262e-01,  1.7491e+00,  1.5410e-01,  2.4333e-01,\n",
      "           1.1808e-01,  2.0031e-01, -4.1765e-01, -4.4570e-02, -7.5414e-02,\n",
      "          -1.7943e-01,  2.9114e-01, -5.1989e-01,  5.7214e-02,  3.4968e-03,\n",
      "          -5.4809e-02,  9.5891e-02, -1.0574e-01,  1.3325e-01,  6.3144e-01,\n",
      "           5.8261e-02, -5.3787e-01,  4.9443e-01,  8.5900e-01,  3.4082e-02,\n",
      "           8.8916e-04, -2.6900e-02,  2.4115e-01,  3.4658e-01, -6.3444e-02,\n",
      "           1.6090e-01,  6.9500e-01, -3.7949e-01,  1.2788e-01,  1.5003e-01,\n",
      "          -4.2237e-02, -2.5673e-01, -3.3161e-01, -2.3348e-01,  5.5662e-01,\n",
      "          -4.5105e-01,  1.1752e-01,  5.5362e-01,  1.0310e+00,  5.0748e-03,\n",
      "          -1.2152e+00, -4.7172e-01,  1.2711e-01,  6.1709e-02,  4.8978e-01,\n",
      "           2.5862e-01, -1.6091e-01, -2.9285e-01, -2.4275e-01,  3.7013e-01,\n",
      "          -6.4637e-01,  4.7067e-01, -1.3941e-01,  8.2075e-02, -4.9278e-02,\n",
      "          -2.3442e-01,  2.8614e-01, -2.1160e-01, -1.1124e+00,  9.2892e-01,\n",
      "           3.1191e-01,  8.5168e-02,  1.1483e-01,  8.2778e-01,  3.2094e-01,\n",
      "          -4.2826e-01, -4.3217e-01,  9.0470e-02,  1.4781e-01,  6.4168e-01,\n",
      "          -4.0168e-01, -3.3907e-01,  1.7142e-01, -1.4673e-01,  8.6523e-02,\n",
      "          -4.7792e-03, -1.9192e-01, -3.2239e-01, -2.2403e-01, -2.6295e-02,\n",
      "          -1.5122e-01,  6.5477e-02,  1.5560e-01,  1.1998e-01,  1.4690e-01,\n",
      "           5.6724e-01, -9.5334e-01,  1.0883e-01, -4.6437e-01, -2.8476e-01,\n",
      "          -2.8313e-01,  5.9793e-01, -1.3925e+00,  5.2537e-02,  1.7755e-01,\n",
      "           4.5361e-02,  1.0916e-01, -1.9150e-01, -1.3015e-01, -5.1746e-01,\n",
      "          -5.5892e-01, -1.6779e-01,  9.6007e-01,  1.4014e+00, -3.8179e-01,\n",
      "          -2.3898e-01,  9.5665e-02,  5.4185e-01,  7.8480e-02, -7.4198e-01,\n",
      "           3.7485e-02, -1.1244e-01,  5.6840e-01, -1.5983e-01,  3.1847e-01,\n",
      "          -2.8043e-01,  1.3540e-01, -9.7404e-02, -7.2468e-01,  9.9290e-01,\n",
      "           6.1460e-01,  3.0556e-01, -9.4487e-01,  1.0193e+00, -1.0106e-01,\n",
      "          -1.5386e+00,  3.4158e-01,  4.2114e-01, -3.2881e-01, -1.3621e-02,\n",
      "          -2.3702e-01, -5.9156e-01, -6.2746e-02, -9.9363e-01, -3.5500e-03,\n",
      "          -1.1910e-02, -1.5673e-01, -1.3858e-01, -1.2728e-01,  3.2764e-01,\n",
      "           1.5330e-01,  3.4395e-01, -1.7346e+00,  4.2143e-01,  2.9009e-01,\n",
      "          -2.0314e-01, -1.6999e-01, -5.6043e-01,  1.5592e+00,  9.0695e-01,\n",
      "          -2.3074e-01,  2.6335e-01,  1.0063e-02,  3.3536e-01, -1.0068e+00,\n",
      "           3.3994e-01,  3.1071e-01,  5.5808e-04, -1.8070e-01,  3.1451e-01,\n",
      "           3.3578e-01, -2.1316e-02,  1.2061e-01, -2.9430e-01,  1.0108e-01,\n",
      "           3.9898e-02,  3.1339e-01,  4.6233e-01, -6.2455e-02, -4.8597e-01,\n",
      "          -1.1414e-01, -2.3682e-01,  3.2588e-01,  2.1854e-01,  2.1128e-01,\n",
      "          -6.2360e-01, -1.0117e-01,  4.4842e-01, -7.2232e-01,  8.1424e-02,\n",
      "          -1.1417e-01, -1.5510e-01,  1.9553e+00,  1.4658e-01,  8.1736e-01,\n",
      "          -1.5598e-01, -1.1353e-01,  7.0220e-01,  3.5282e-03, -2.4982e-01,\n",
      "          -2.7995e+00, -1.3884e+00,  9.2986e-01, -3.0575e-01,  4.1183e-01,\n",
      "          -5.4223e-01, -2.7192e-01,  3.2496e-01, -2.3899e-01, -3.1130e-02,\n",
      "          -1.0525e+00,  2.2014e+00, -7.1531e-01,  3.3892e-02, -3.3486e-01,\n",
      "           6.7763e-01,  2.0083e-01, -1.8894e-01, -1.0283e+00, -9.1044e-02,\n",
      "           4.8329e-03, -1.0640e-01,  4.0725e-01, -2.3403e-01,  6.0655e-01,\n",
      "           3.4804e-01, -3.5779e-01, -1.3233e-02, -1.0694e-01,  6.3256e-01,\n",
      "           1.0990e-01,  2.3830e-02,  3.6173e-01,  5.7738e-01, -1.9464e-01,\n",
      "           4.8241e-01, -2.5946e-02, -1.9019e-01, -7.8480e-01,  6.8758e-02,\n",
      "          -4.7497e-02, -1.3609e+00,  6.1587e-01,  5.8165e-02, -1.9913e-01,\n",
      "           9.7329e-01,  1.0289e-02,  1.6345e-01, -1.8136e-01, -2.1239e-01,\n",
      "          -7.4947e-02,  3.7483e-01, -1.4315e+00,  9.2524e-01,  5.4806e-02,\n",
      "           4.1944e-01,  2.0483e-02,  7.2994e-01,  2.1012e+00, -1.2746e+00,\n",
      "          -2.7914e-01, -4.1034e-01,  1.5823e-01, -1.2046e-01,  2.5009e-01,\n",
      "          -2.6848e-01,  9.3349e-03, -6.9723e-01, -1.1454e+00,  2.8049e-01,\n",
      "           1.7298e-01,  1.3442e-02, -3.6490e-01,  2.7565e-01, -5.0091e-01,\n",
      "           5.6422e-01, -4.3578e-01,  1.3744e+00,  2.6284e-01, -3.6305e-01,\n",
      "           1.8917e-01,  6.6354e-01, -6.3040e-01, -7.2850e-01, -8.3665e-02,\n",
      "          -2.6176e-01,  7.0304e-02,  1.4631e-01, -5.3198e-01,  6.2124e-01,\n",
      "           4.9013e-01,  7.6268e-02,  3.4316e-02, -1.7787e-01, -1.4833e-01,\n",
      "           1.1812e+00,  1.1317e+00, -4.8711e-01, -1.6038e-01,  2.3041e-01,\n",
      "           1.3259e+00,  9.8977e-02,  8.9631e-02,  1.8019e-01,  3.3693e-01,\n",
      "          -3.6393e-02,  1.1927e-01, -2.7777e-01, -9.0305e-02, -5.1156e-02,\n",
      "          -2.2291e-01, -8.1878e-01,  7.2951e-01,  2.9266e-01,  2.8071e+00,\n",
      "           2.3238e-01,  1.9978e-01,  4.6962e-01, -6.9338e-01,  2.1595e-02,\n",
      "           5.8179e-01, -8.0825e-03,  4.0437e-02,  4.6131e-01, -8.8928e-02,\n",
      "           1.0060e+00, -3.3248e-01, -4.9280e-01,  7.4792e-01,  1.4398e+00,\n",
      "          -1.4240e-01,  5.4036e-01,  3.3272e-01, -1.4869e-01, -3.5158e-01,\n",
      "          -2.0619e+00, -1.1094e-01, -3.5929e-01, -9.2581e-03, -6.2078e-01,\n",
      "          -3.0006e-01,  1.2676e-01, -3.4668e-01,  4.0886e-01, -1.8963e-01,\n",
      "          -3.1097e-01,  3.9580e-01, -8.1414e-02,  1.1727e-01, -1.0543e-01,\n",
      "          -1.1591e-01,  9.5239e-02,  1.2715e+00,  9.5719e-01, -1.0286e+00,\n",
      "          -1.2770e+00,  8.1440e-02, -1.8329e+00,  1.0241e-01, -3.5173e-01,\n",
      "          -5.2059e-01, -2.3979e-03, -1.6086e-01,  5.2218e-01,  1.0047e+00,\n",
      "           8.4269e-01,  7.7826e-02,  1.0640e-01, -3.7783e-02, -1.3345e+00,\n",
      "           5.3439e-01,  9.4980e-02,  1.7555e+00, -1.7011e-01,  6.6691e-02,\n",
      "           6.1246e-02,  5.6022e-01,  1.3658e-01, -1.5076e+00,  1.5500e-01,\n",
      "          -2.7122e-01, -2.7139e-01,  1.8960e-01, -1.3290e-01, -8.1194e-02,\n",
      "           2.3106e-02, -6.0200e-01,  2.4592e-01,  9.4521e-02, -3.6338e-01,\n",
      "           4.7547e-01, -1.4175e+00, -3.1754e-01,  2.4655e-02,  1.7531e+00,\n",
      "           2.2224e-01, -6.8889e-02,  1.7817e-01, -2.8154e-01,  1.2842e-01,\n",
      "          -1.1765e-01, -2.4398e-01,  6.9239e-01,  4.9469e-03, -1.0554e-01,\n",
      "          -2.1135e-01, -8.2615e-01, -1.2064e+00, -9.0425e-02, -3.6638e-01,\n",
      "          -1.1402e-01,  3.5683e-01, -4.8989e-01, -3.2952e-01, -1.4446e-01,\n",
      "           1.1521e-01,  5.4473e-01,  4.6421e-01, -4.7061e-01,  4.1033e-02,\n",
      "           3.0311e-02,  3.8718e-01,  3.9273e-02, -4.2830e-02, -2.2708e-02,\n",
      "           1.9289e+00,  2.8577e-02,  3.5952e-01,  4.2292e-02, -1.2712e+00,\n",
      "           4.9575e-01, -1.7472e-01,  6.2497e-01,  7.0061e-01,  1.0168e+00,\n",
      "           2.0898e-01,  2.9583e-01,  2.6145e+00,  7.3840e-01, -4.0931e-02,\n",
      "           1.6071e-01, -1.3981e+00, -6.6715e-02, -1.3173e-01, -1.1371e-01,\n",
      "           3.8258e-01,  1.4547e-01, -1.7297e-01,  3.8544e-02, -3.1107e-01,\n",
      "          -1.8706e+00, -2.0439e-01, -1.0771e-01,  3.1944e-01,  4.9499e-02,\n",
      "          -1.0994e-01,  1.5210e-01, -1.4176e+00,  5.2413e-02, -8.5459e-01,\n",
      "          -9.9805e-01,  1.9167e+00, -6.7263e-03,  2.3618e+00, -2.4710e-01,\n",
      "          -1.2896e-01,  3.7116e-01,  8.9034e-01, -6.4879e-02,  4.0245e-01,\n",
      "           3.8369e-01, -3.5353e-01,  5.1265e-01, -3.5775e-01,  6.3312e-02,\n",
      "          -1.3479e+00, -1.6700e-01, -2.2919e-01, -1.7324e-01, -3.7457e-01,\n",
      "          -1.0357e-01, -1.8559e-01, -5.9229e-01, -1.9978e-01,  4.4437e-01,\n",
      "          -8.8195e-01,  6.1009e-01,  5.7204e-01, -1.4240e+00, -3.9134e-01,\n",
      "           4.3413e-01,  5.6744e-01, -5.3973e-01,  1.3536e-01, -1.7571e-02,\n",
      "           4.3265e-01, -2.3575e+00, -2.0904e-01, -2.3189e+00, -6.9198e-01,\n",
      "           4.8116e-02,  4.4486e-01, -8.9616e-02, -3.0280e-01, -2.8890e-02,\n",
      "           1.9719e-01, -1.6125e+00, -1.0723e-02, -1.2308e+00,  2.7813e-02,\n",
      "           7.9382e-01, -3.8642e-01,  1.1324e-02,  3.2542e-02,  3.3886e-02,\n",
      "           8.7939e-02,  3.2446e-02, -4.3876e-01, -5.7848e-01,  2.2803e-01,\n",
      "          -5.0407e-02,  6.0831e-01, -1.8474e-01,  2.5290e+00,  4.7034e-01,\n",
      "          -7.4563e-01,  1.8814e-01,  5.8178e-02,  1.7588e-01, -2.3231e-01,\n",
      "          -2.6213e-01, -3.2092e-01,  3.5052e-01,  2.3856e-02, -9.3220e-02,\n",
      "          -1.4070e+00,  8.7897e-01, -1.7089e-01,  1.5757e-01,  6.0234e-01,\n",
      "           1.0688e-01, -5.8827e-02,  4.0119e-01, -8.5685e-02, -2.9215e-01,\n",
      "           3.3505e-02,  5.2877e-01,  8.5433e-02, -1.3682e-01,  5.6899e-02,\n",
      "           3.0420e-02, -1.6028e+00,  1.9255e-01,  1.2622e-01, -9.5260e-01,\n",
      "           2.0320e-01,  2.3399e-01,  2.6022e-01, -4.4882e-02, -3.5379e-01,\n",
      "          -4.8428e-01,  7.3951e-01,  3.5998e-01, -3.1704e-02,  6.6309e-01,\n",
      "           1.2429e-01,  1.0664e-01, -4.8499e-01, -1.4012e+00,  6.6858e-01,\n",
      "          -5.0829e-01,  3.4053e-02, -7.1859e-02,  2.4280e-01,  1.2617e-01,\n",
      "           3.1691e-01,  5.0482e-01, -1.4471e-01,  5.6196e-01, -1.0742e+00,\n",
      "          -3.1774e+00, -5.2434e-01, -7.6493e-01, -3.8002e-01, -7.4135e-02,\n",
      "          -1.2321e-01, -4.9928e-01,  3.1236e-01,  4.7799e-01,  9.0799e-01,\n",
      "          -6.3907e-02, -3.8825e-01,  1.3708e-01, -1.9597e-01, -6.9311e-01,\n",
      "          -2.2167e-01,  8.6342e-02,  5.5120e-03,  1.1685e+00, -1.1648e-01,\n",
      "           2.3934e-01,  1.8242e+00, -2.1611e-01, -2.9277e-01,  2.9649e-01,\n",
      "          -2.1038e-01, -2.2648e-01, -7.3345e-02,  1.4272e+00, -1.9541e-01,\n",
      "          -7.2778e-02,  5.3655e-01,  8.1853e-02]]], device='cuda:0'), 'image_feats': tensor([[[ 0.2431,  0.8703,  0.4091,  ..., -0.1364,  0.5865, -0.0774],\n",
      "         [ 0.1377,  1.0587,  0.3401,  ..., -0.0132,  0.5184,  1.2675],\n",
      "         [ 1.2541,  0.5216,  0.6157,  ...,  0.0277,  0.6304,  0.1008],\n",
      "         ...,\n",
      "         [-0.1858,  1.0811,  0.0942,  ..., -0.1176,  0.2101,  1.4752],\n",
      "         [ 0.2074,  0.9274,  0.3214,  ..., -0.2068,  0.5712, -0.3430],\n",
      "         [ 0.9357,  0.9592,  0.3450,  ..., -0.1386,  0.4405,  0.8156]]],\n",
      "       device='cuda:0'), 'cls_feats': tensor([[ 0.6861,  0.9635,  0.9189, -0.6999, -0.9506, -0.9428,  0.8898, -0.9481,\n",
      "         -0.4192, -0.7655, -0.9380, -0.7018, -0.8167,  0.9557, -0.9731,  0.9530,\n",
      "         -0.0454,  0.6914,  0.7266, -0.0052, -0.9271,  0.6346,  0.9023,  0.9638,\n",
      "         -0.3695,  0.9387, -0.8322,  0.9430, -0.2531,  0.8075, -0.6678, -0.6310,\n",
      "          0.7473,  0.9280, -0.0177,  0.3133, -0.8889,  0.1552, -0.9467, -0.9320,\n",
      "         -0.6951, -0.8687,  0.1766,  0.3877, -0.9530, -0.9646,  0.7337, -0.5759,\n",
      "          0.9306,  0.4362, -0.6669, -0.9406,  0.8098, -0.8067, -0.6465,  0.8948,\n",
      "          0.6083, -0.0344, -0.3722, -0.6427, -0.9051,  0.0540, -0.9654, -0.5094,\n",
      "          0.9314, -0.4041,  0.9361,  0.7168,  0.9392, -0.9849, -0.6538,  0.9099,\n",
      "         -0.8167, -0.6269, -0.8203, -0.8790, -0.9354,  0.9654,  0.9002,  0.8086,\n",
      "          0.6134,  0.8996,  0.4390, -0.9166,  0.7954,  0.4243,  0.5765, -0.4910,\n",
      "         -0.0837, -0.7827, -0.9418, -0.9364,  0.8557,  0.8651,  0.8614,  0.9193,\n",
      "          0.8506,  0.6370, -0.7113, -0.9676, -0.6871, -0.2314,  0.7330,  0.9065,\n",
      "         -0.9324,  0.3956,  0.7447, -0.8064,  0.9067,  0.8631,  0.4799,  0.6384,\n",
      "          0.8402, -0.8473, -0.8665,  0.1329,  0.9430,  0.9106, -0.9522, -0.8534,\n",
      "          0.8711,  0.2717, -0.5412,  0.7744, -0.9263,  0.0793,  0.4515, -0.9735,\n",
      "         -0.0066,  0.7723, -0.9771, -0.5410, -0.8353, -0.3052, -0.9695,  0.8457,\n",
      "          0.4923, -0.8924,  0.6764, -0.9508,  0.0490,  0.8915,  0.9543,  0.9395,\n",
      "          0.8224,  0.2361, -0.9094, -0.7523,  0.9566, -0.4121, -0.7178, -0.8682,\n",
      "         -0.9594, -0.5169,  0.9100, -0.0268, -0.2220,  0.8911,  0.8748, -0.5452,\n",
      "          0.9679, -0.0137, -0.6876,  0.9694,  0.2526, -0.8979,  0.1786, -0.8641,\n",
      "         -0.5407,  0.9638,  0.5739, -0.3002, -0.9697, -0.8552,  0.4265, -0.8314,\n",
      "          0.1260, -0.7668,  0.9569,  0.8464,  0.8809, -0.8522, -0.4863, -0.9610,\n",
      "          0.9031, -0.2059,  0.9832,  0.6457, -0.8745, -0.8451,  0.7987, -0.9393,\n",
      "         -0.9211,  0.3932, -0.8454, -0.7477,  0.9450,  0.9613,  0.8656,  0.0195,\n",
      "          0.6211, -0.4546,  0.9077,  0.5471,  0.5030,  0.9209,  0.6497, -0.8848,\n",
      "          0.4744,  0.2030, -0.9027, -0.8507, -0.2835, -0.0010,  0.9581, -0.9146,\n",
      "          0.9396, -0.2140, -0.4562,  0.8399, -0.3735,  0.5367, -0.6889,  0.8266,\n",
      "          0.8667,  0.6894, -0.0769,  0.1583, -0.0120,  0.7468, -0.4944, -0.9677,\n",
      "          0.8974,  0.9041, -0.7135,  0.7476,  0.8049, -0.7467,  0.8361, -0.1140,\n",
      "         -0.9609, -0.9281, -0.8294, -0.8841,  0.7275, -0.8979, -0.7762, -0.7321,\n",
      "         -0.7858, -0.7055,  0.9645, -0.9546,  0.8950,  0.9380, -0.4398, -0.9443,\n",
      "         -0.7640, -0.8377, -0.9044, -0.7822,  0.5797,  0.6652,  0.8443, -0.7218,\n",
      "         -0.9397, -0.7241, -0.9334, -0.7932, -0.9124, -0.9315, -0.9212,  0.9657,\n",
      "         -0.9403, -0.9138, -0.9086, -0.2287, -0.9148, -0.7972, -0.4978, -0.9206,\n",
      "         -0.9397, -0.3000, -0.8109, -0.9089,  0.8219, -0.9187, -0.9375,  0.1631,\n",
      "          0.9176, -0.4643,  0.0486,  0.8334,  0.9211, -0.9416, -0.4710, -0.8741,\n",
      "          0.4695, -0.8994,  0.0282,  0.8080, -0.6750, -0.8064,  0.9439, -0.3361,\n",
      "         -0.8883,  0.9143, -0.7095, -0.0080, -0.9304, -0.0989,  0.8746, -0.9472,\n",
      "         -0.9569, -0.5521,  0.1029,  0.9448,  0.9725, -0.9444, -0.8032,  0.6849,\n",
      "         -0.8741, -0.8476, -0.8543, -0.8867,  0.3841, -0.9577,  0.9002,  0.8944,\n",
      "          0.8741,  0.9605,  0.9298,  0.7942,  0.0601,  0.0177,  0.8477, -0.7911,\n",
      "         -0.7208,  0.6451, -0.7525,  0.9019,  0.9625, -0.6047, -0.4711, -0.7241,\n",
      "         -0.8680, -0.0926,  0.9080,  0.9230, -0.8913, -0.7550, -0.9705,  0.9343,\n",
      "          0.9556, -0.3745,  0.0613,  0.0245,  0.8374, -0.8194,  0.4525,  0.1838,\n",
      "         -0.1391, -0.8964, -0.9057, -0.9511, -0.8785, -0.9473, -0.9584, -0.9404,\n",
      "         -0.9258, -0.9336, -0.4731, -0.6960, -0.0861, -0.4606,  0.8067, -0.9468,\n",
      "          0.8689,  0.9710,  0.9321, -0.9172, -0.5130, -0.9465, -0.3851,  0.0096,\n",
      "         -0.8701,  0.7197,  0.1344, -0.2644,  0.8965,  0.0093, -0.8958, -0.1762,\n",
      "         -0.7720,  0.9036,  0.7997,  0.5176,  0.7928, -0.4390,  0.0357, -0.4593,\n",
      "         -0.1821,  0.7816, -0.4445, -0.6764,  0.9206, -0.5247, -0.8472,  0.6751,\n",
      "         -0.4740,  0.5442,  0.5204, -0.9465, -0.5485, -0.5013,  0.4493, -0.7130,\n",
      "         -0.9599, -0.0396, -0.8417, -0.8242, -0.8399, -0.9091, -0.9375,  0.3721,\n",
      "         -0.9502, -0.9258,  0.9106,  0.7854, -0.9354, -0.5029,  0.7846, -0.8933,\n",
      "          0.8479, -0.7099, -0.9312, -0.4060,  0.9086,  0.4037, -0.9608, -0.9267,\n",
      "          0.0818,  0.8091, -0.9481, -0.9064, -0.6212,  0.6837, -0.6029, -0.0268,\n",
      "         -0.1795,  0.8621, -0.4785,  0.1611, -0.9613,  0.6329, -0.8598, -0.8511,\n",
      "         -0.9122, -0.7216, -0.7042,  0.9457,  0.3143,  0.7789,  0.2101,  0.8547,\n",
      "          0.7129,  0.5477, -0.4509,  0.8447, -0.8087,  0.0530, -0.8974, -0.6889,\n",
      "          0.9161,  0.8877, -0.8584,  0.8737,  0.8873, -0.9335, -0.6944,  0.9046,\n",
      "          0.2264,  0.2252,  0.4507,  0.9608, -0.4124,  0.7434, -0.9581, -0.8339,\n",
      "          0.0081,  0.7294,  0.9500,  0.8169, -0.7480,  0.8812,  0.0795, -0.7554,\n",
      "         -0.9528, -0.5903, -0.8181, -0.6516, -0.9364, -0.7622,  0.7517,  0.8241,\n",
      "          0.6484, -0.7409, -0.8043,  0.8486, -0.3270,  0.7394, -0.9655, -0.8375,\n",
      "         -0.4116, -0.0213, -0.4419, -0.9021, -0.8633,  0.6484,  0.8442, -0.0075,\n",
      "          0.9237, -0.8946, -0.9126, -0.7234,  0.9336, -0.0032, -0.8876,  0.5668,\n",
      "          0.7643, -0.9399,  0.9520,  0.8163, -0.9074,  0.8824, -0.0571, -0.8952,\n",
      "         -0.9411,  0.9370, -0.9421,  0.5225,  0.3039,  0.9505,  0.8541,  0.9092,\n",
      "         -0.8648,  0.8545, -0.7344,  0.8958,  0.9592,  0.6203,  0.9080,  0.0415,\n",
      "         -0.9120,  0.2949,  0.9180, -0.9235, -0.8646, -0.1513,  0.3003, -0.7236,\n",
      "          0.1011,  0.9349, -0.7686, -0.8321,  0.8599, -0.8982, -0.9394,  0.9132,\n",
      "          0.4026,  0.5501,  0.9313, -0.9104,  0.8664, -0.0157,  0.9230, -0.9348,\n",
      "         -0.6024,  0.3617,  0.7102,  0.3783,  0.9083,  0.9204,  0.9442, -0.7189,\n",
      "          0.9407,  0.4892,  0.9174, -0.5663, -0.6324, -0.7260,  0.6909,  0.9679,\n",
      "          0.9625, -0.5346, -0.8391,  0.9468,  0.7944,  0.5043, -0.1009, -0.9703,\n",
      "          0.9267, -0.0780,  0.3834,  0.6234, -0.9261,  0.8249, -0.9312, -0.6229,\n",
      "         -0.8443,  0.8005, -0.3518,  0.9231,  0.9207,  0.9443,  0.8111, -0.9530,\n",
      "          0.9275,  0.0298, -0.8262, -0.6245,  0.9380,  0.6245, -0.5522,  0.6369,\n",
      "          0.9122,  0.9521, -0.6275,  0.5342,  0.0438,  0.6407,  0.5023,  0.9227,\n",
      "          0.4988,  0.3001,  0.9290,  0.7555, -0.8777, -0.9615,  0.7393,  0.7521,\n",
      "          0.4154,  0.9627, -0.7893,  0.8038,  0.9428, -0.4511, -0.0362, -0.2598,\n",
      "          0.0159,  0.1406,  0.4937,  0.4351,  0.5316, -0.9096, -0.9051,  0.0515,\n",
      "         -0.8954, -0.9084, -0.3198,  0.8460,  0.8972,  0.8789,  0.0014,  0.9582,\n",
      "         -0.9012, -0.8863,  0.9037,  0.1938,  0.8355, -0.6972,  0.8905,  0.9534,\n",
      "          0.2107,  0.5049, -0.9387, -0.7600, -0.9061, -0.9502, -0.0081, -0.9196,\n",
      "         -0.8195,  0.0489,  0.3990,  0.7317, -0.8240, -0.5181, -0.0454,  0.0215,\n",
      "          0.8402, -0.6998,  0.8516,  0.2863, -0.8246, -0.9624,  0.0259,  0.4900,\n",
      "         -0.6030, -0.8088, -0.9358, -0.6502, -0.7431, -0.5907, -0.5223, -0.1334,\n",
      "          0.8094, -0.6562,  0.8715, -0.4621, -0.8301,  0.3937, -0.8643,  0.5434,\n",
      "          0.3503, -0.7083,  0.5814,  0.7330, -0.4296, -0.9077, -0.9078, -0.9718,\n",
      "          0.9640,  0.3906,  0.8785,  0.6919, -0.9295,  0.0940,  0.4989, -0.8747,\n",
      "          0.7955,  0.7242,  0.8476, -0.9083,  0.6682,  0.9036,  0.0162, -0.5133,\n",
      "         -0.9446, -0.8102,  0.9813,  0.5234,  0.6895,  0.8091, -0.8560, -0.9017,\n",
      "          0.1673,  0.8996,  0.0289, -0.4581, -0.9003,  0.4672,  0.9173, -0.8879,\n",
      "         -0.7248, -0.9403,  0.3426,  0.2516, -0.9224, -0.9453,  0.9738,  0.5616,\n",
      "          0.9058, -0.8701,  0.9186,  0.7613,  0.3678,  0.2124, -0.5984,  0.3086]],\n",
      "       device='cuda:0'), 'raw_cls_feats': tensor([[ 2.7024e-01,  8.4886e-01,  3.5035e-01,  5.3281e-02,  5.2474e-02,\n",
      "         -1.7046e-01,  7.3329e-02,  3.0590e-02,  6.7037e-02, -3.7755e-01,\n",
      "         -8.7652e-01,  1.3844e-01,  2.5090e-01, -3.3451e-01, -1.6991e-01,\n",
      "         -2.3502e-02, -6.9722e-02, -1.1445e-01, -1.7391e-01,  3.5070e-01,\n",
      "         -1.2979e+00,  2.7135e-01, -6.4320e-02, -9.8884e-01,  3.2600e-02,\n",
      "         -4.4981e-01,  1.7270e-01,  3.7485e-01, -8.4396e-01, -6.4098e-02,\n",
      "          1.6703e-01,  3.6598e-01, -4.2784e-02, -1.1087e-01,  1.1336e-02,\n",
      "         -2.0030e+00, -7.8494e-01, -9.4766e-02, -1.2019e-01,  1.6362e-01,\n",
      "         -1.2572e-01,  2.2219e-01, -3.8874e-02,  6.9456e-01, -6.6659e-01,\n",
      "         -7.5572e-02, -6.5935e-02, -2.7468e-02,  1.0221e+00, -2.5591e-01,\n",
      "          1.8912e-01, -5.2756e-01,  4.2142e-02,  1.3391e+00,  6.7435e-02,\n",
      "          9.3807e-01,  1.4467e+00,  4.8933e-01,  2.6360e-01, -6.8080e-02,\n",
      "          1.7264e-01,  7.1070e-02,  3.0559e-01,  1.0487e+00, -1.0531e-01,\n",
      "          1.4899e-01, -1.4601e-01,  7.0311e-02, -6.1047e-01,  3.2517e-01,\n",
      "          9.6615e-02, -4.9635e-01,  3.9653e-01, -8.1497e-01,  4.3536e-01,\n",
      "         -1.7965e-01, -1.8054e-02, -7.7346e-02,  3.7056e-01, -1.1527e-01,\n",
      "         -5.1328e-02,  2.2571e-01, -1.4052e-01,  3.9916e-01, -1.5368e+00,\n",
      "         -2.2687e-01,  6.8785e-01,  4.7555e-03,  4.0235e-01, -3.9818e-01,\n",
      "          4.5255e-01,  1.8249e-01,  2.4254e-02,  5.4363e-01,  3.1668e-01,\n",
      "          1.4741e-01, -1.2045e+00,  5.6026e-01,  1.8129e-02, -5.2342e-01,\n",
      "         -2.5647e-01, -5.9585e-01,  1.6685e-01, -2.0819e-01, -2.7393e-01,\n",
      "         -5.4547e-02,  8.3671e-01,  1.0122e+00,  3.0082e-01, -4.0947e-01,\n",
      "         -3.5765e-01, -8.6501e-04,  1.6294e-01, -4.0080e-01, -8.3902e-01,\n",
      "          2.2061e-01, -4.1820e-02, -4.1544e-01, -2.5201e+00, -9.8932e-02,\n",
      "         -5.8175e-01, -7.2491e-02, -8.2113e-01, -1.3048e-01, -4.9790e-01,\n",
      "         -2.5302e-01,  9.9828e-02,  3.8401e-01, -1.0704e-01, -1.3460e-01,\n",
      "         -5.2490e-01,  1.6422e-01, -7.2538e-02,  3.1729e-01, -1.8784e-01,\n",
      "          8.4847e-01,  2.7782e-01,  3.9456e-01,  7.3581e-01, -4.6038e-01,\n",
      "         -1.2405e-01,  3.6507e-01,  1.0595e+00, -3.3720e-01, -1.7847e-01,\n",
      "          6.9445e-02,  5.5660e-02,  6.6612e-01, -1.5342e-01, -1.0245e-01,\n",
      "         -4.1698e-01, -4.7990e-01, -4.3741e-02,  7.5446e-01, -8.5839e-01,\n",
      "         -2.9759e-01,  7.4105e-02,  3.6936e-01,  2.2517e-01,  2.0445e-01,\n",
      "         -2.2520e-01, -7.0262e-01,  1.7491e+00,  1.5410e-01,  2.4333e-01,\n",
      "          1.1808e-01,  2.0031e-01, -4.1765e-01, -4.4570e-02, -7.5414e-02,\n",
      "         -1.7943e-01,  2.9114e-01, -5.1989e-01,  5.7214e-02,  3.4968e-03,\n",
      "         -5.4809e-02,  9.5891e-02, -1.0574e-01,  1.3325e-01,  6.3144e-01,\n",
      "          5.8261e-02, -5.3787e-01,  4.9443e-01,  8.5900e-01,  3.4082e-02,\n",
      "          8.8916e-04, -2.6900e-02,  2.4115e-01,  3.4658e-01, -6.3444e-02,\n",
      "          1.6090e-01,  6.9500e-01, -3.7949e-01,  1.2788e-01,  1.5003e-01,\n",
      "         -4.2237e-02, -2.5673e-01, -3.3161e-01, -2.3348e-01,  5.5662e-01,\n",
      "         -4.5105e-01,  1.1752e-01,  5.5362e-01,  1.0310e+00,  5.0748e-03,\n",
      "         -1.2152e+00, -4.7172e-01,  1.2711e-01,  6.1709e-02,  4.8978e-01,\n",
      "          2.5862e-01, -1.6091e-01, -2.9285e-01, -2.4275e-01,  3.7013e-01,\n",
      "         -6.4637e-01,  4.7067e-01, -1.3941e-01,  8.2075e-02, -4.9278e-02,\n",
      "         -2.3442e-01,  2.8614e-01, -2.1160e-01, -1.1124e+00,  9.2892e-01,\n",
      "          3.1191e-01,  8.5168e-02,  1.1483e-01,  8.2778e-01,  3.2094e-01,\n",
      "         -4.2826e-01, -4.3217e-01,  9.0470e-02,  1.4781e-01,  6.4168e-01,\n",
      "         -4.0168e-01, -3.3907e-01,  1.7142e-01, -1.4673e-01,  8.6523e-02,\n",
      "         -4.7792e-03, -1.9192e-01, -3.2239e-01, -2.2403e-01, -2.6295e-02,\n",
      "         -1.5122e-01,  6.5477e-02,  1.5560e-01,  1.1998e-01,  1.4690e-01,\n",
      "          5.6724e-01, -9.5334e-01,  1.0883e-01, -4.6437e-01, -2.8476e-01,\n",
      "         -2.8313e-01,  5.9793e-01, -1.3925e+00,  5.2537e-02,  1.7755e-01,\n",
      "          4.5361e-02,  1.0916e-01, -1.9150e-01, -1.3015e-01, -5.1746e-01,\n",
      "         -5.5892e-01, -1.6779e-01,  9.6007e-01,  1.4014e+00, -3.8179e-01,\n",
      "         -2.3898e-01,  9.5665e-02,  5.4185e-01,  7.8480e-02, -7.4198e-01,\n",
      "          3.7485e-02, -1.1244e-01,  5.6840e-01, -1.5983e-01,  3.1847e-01,\n",
      "         -2.8043e-01,  1.3540e-01, -9.7404e-02, -7.2468e-01,  9.9290e-01,\n",
      "          6.1460e-01,  3.0556e-01, -9.4487e-01,  1.0193e+00, -1.0106e-01,\n",
      "         -1.5386e+00,  3.4158e-01,  4.2114e-01, -3.2881e-01, -1.3621e-02,\n",
      "         -2.3702e-01, -5.9156e-01, -6.2746e-02, -9.9363e-01, -3.5500e-03,\n",
      "         -1.1910e-02, -1.5673e-01, -1.3858e-01, -1.2728e-01,  3.2764e-01,\n",
      "          1.5330e-01,  3.4395e-01, -1.7346e+00,  4.2143e-01,  2.9009e-01,\n",
      "         -2.0314e-01, -1.6999e-01, -5.6043e-01,  1.5592e+00,  9.0695e-01,\n",
      "         -2.3074e-01,  2.6335e-01,  1.0063e-02,  3.3536e-01, -1.0068e+00,\n",
      "          3.3994e-01,  3.1071e-01,  5.5808e-04, -1.8070e-01,  3.1451e-01,\n",
      "          3.3578e-01, -2.1316e-02,  1.2061e-01, -2.9430e-01,  1.0108e-01,\n",
      "          3.9898e-02,  3.1339e-01,  4.6233e-01, -6.2455e-02, -4.8597e-01,\n",
      "         -1.1414e-01, -2.3682e-01,  3.2588e-01,  2.1854e-01,  2.1128e-01,\n",
      "         -6.2360e-01, -1.0117e-01,  4.4842e-01, -7.2232e-01,  8.1424e-02,\n",
      "         -1.1417e-01, -1.5510e-01,  1.9553e+00,  1.4658e-01,  8.1736e-01,\n",
      "         -1.5598e-01, -1.1353e-01,  7.0220e-01,  3.5282e-03, -2.4982e-01,\n",
      "         -2.7995e+00, -1.3884e+00,  9.2986e-01, -3.0575e-01,  4.1183e-01,\n",
      "         -5.4223e-01, -2.7192e-01,  3.2496e-01, -2.3899e-01, -3.1130e-02,\n",
      "         -1.0525e+00,  2.2014e+00, -7.1531e-01,  3.3892e-02, -3.3486e-01,\n",
      "          6.7763e-01,  2.0083e-01, -1.8894e-01, -1.0283e+00, -9.1044e-02,\n",
      "          4.8329e-03, -1.0640e-01,  4.0725e-01, -2.3403e-01,  6.0655e-01,\n",
      "          3.4804e-01, -3.5779e-01, -1.3233e-02, -1.0694e-01,  6.3256e-01,\n",
      "          1.0990e-01,  2.3830e-02,  3.6173e-01,  5.7738e-01, -1.9464e-01,\n",
      "          4.8241e-01, -2.5946e-02, -1.9019e-01, -7.8480e-01,  6.8758e-02,\n",
      "         -4.7497e-02, -1.3609e+00,  6.1587e-01,  5.8165e-02, -1.9913e-01,\n",
      "          9.7329e-01,  1.0289e-02,  1.6345e-01, -1.8136e-01, -2.1239e-01,\n",
      "         -7.4947e-02,  3.7483e-01, -1.4315e+00,  9.2524e-01,  5.4806e-02,\n",
      "          4.1944e-01,  2.0483e-02,  7.2994e-01,  2.1012e+00, -1.2746e+00,\n",
      "         -2.7914e-01, -4.1034e-01,  1.5823e-01, -1.2046e-01,  2.5009e-01,\n",
      "         -2.6848e-01,  9.3349e-03, -6.9723e-01, -1.1454e+00,  2.8049e-01,\n",
      "          1.7298e-01,  1.3442e-02, -3.6490e-01,  2.7565e-01, -5.0091e-01,\n",
      "          5.6422e-01, -4.3578e-01,  1.3744e+00,  2.6284e-01, -3.6305e-01,\n",
      "          1.8917e-01,  6.6354e-01, -6.3040e-01, -7.2850e-01, -8.3665e-02,\n",
      "         -2.6176e-01,  7.0304e-02,  1.4631e-01, -5.3198e-01,  6.2124e-01,\n",
      "          4.9013e-01,  7.6268e-02,  3.4316e-02, -1.7787e-01, -1.4833e-01,\n",
      "          1.1812e+00,  1.1317e+00, -4.8711e-01, -1.6038e-01,  2.3041e-01,\n",
      "          1.3259e+00,  9.8977e-02,  8.9631e-02,  1.8019e-01,  3.3693e-01,\n",
      "         -3.6393e-02,  1.1927e-01, -2.7777e-01, -9.0305e-02, -5.1156e-02,\n",
      "         -2.2291e-01, -8.1878e-01,  7.2951e-01,  2.9266e-01,  2.8071e+00,\n",
      "          2.3238e-01,  1.9978e-01,  4.6962e-01, -6.9338e-01,  2.1595e-02,\n",
      "          5.8179e-01, -8.0825e-03,  4.0437e-02,  4.6131e-01, -8.8928e-02,\n",
      "          1.0060e+00, -3.3248e-01, -4.9280e-01,  7.4792e-01,  1.4398e+00,\n",
      "         -1.4240e-01,  5.4036e-01,  3.3272e-01, -1.4869e-01, -3.5158e-01,\n",
      "         -2.0619e+00, -1.1094e-01, -3.5929e-01, -9.2581e-03, -6.2078e-01,\n",
      "         -3.0006e-01,  1.2676e-01, -3.4668e-01,  4.0886e-01, -1.8963e-01,\n",
      "         -3.1097e-01,  3.9580e-01, -8.1414e-02,  1.1727e-01, -1.0543e-01,\n",
      "         -1.1591e-01,  9.5239e-02,  1.2715e+00,  9.5719e-01, -1.0286e+00,\n",
      "         -1.2770e+00,  8.1440e-02, -1.8329e+00,  1.0241e-01, -3.5173e-01,\n",
      "         -5.2059e-01, -2.3979e-03, -1.6086e-01,  5.2218e-01,  1.0047e+00,\n",
      "          8.4269e-01,  7.7826e-02,  1.0640e-01, -3.7783e-02, -1.3345e+00,\n",
      "          5.3439e-01,  9.4980e-02,  1.7555e+00, -1.7011e-01,  6.6691e-02,\n",
      "          6.1246e-02,  5.6022e-01,  1.3658e-01, -1.5076e+00,  1.5500e-01,\n",
      "         -2.7122e-01, -2.7139e-01,  1.8960e-01, -1.3290e-01, -8.1194e-02,\n",
      "          2.3106e-02, -6.0200e-01,  2.4592e-01,  9.4521e-02, -3.6338e-01,\n",
      "          4.7547e-01, -1.4175e+00, -3.1754e-01,  2.4655e-02,  1.7531e+00,\n",
      "          2.2224e-01, -6.8889e-02,  1.7817e-01, -2.8154e-01,  1.2842e-01,\n",
      "         -1.1765e-01, -2.4398e-01,  6.9239e-01,  4.9469e-03, -1.0554e-01,\n",
      "         -2.1135e-01, -8.2615e-01, -1.2064e+00, -9.0425e-02, -3.6638e-01,\n",
      "         -1.1402e-01,  3.5683e-01, -4.8989e-01, -3.2952e-01, -1.4446e-01,\n",
      "          1.1521e-01,  5.4473e-01,  4.6421e-01, -4.7061e-01,  4.1033e-02,\n",
      "          3.0311e-02,  3.8718e-01,  3.9273e-02, -4.2830e-02, -2.2708e-02,\n",
      "          1.9289e+00,  2.8577e-02,  3.5952e-01,  4.2292e-02, -1.2712e+00,\n",
      "          4.9575e-01, -1.7472e-01,  6.2497e-01,  7.0061e-01,  1.0168e+00,\n",
      "          2.0898e-01,  2.9583e-01,  2.6145e+00,  7.3840e-01, -4.0931e-02,\n",
      "          1.6071e-01, -1.3981e+00, -6.6715e-02, -1.3173e-01, -1.1371e-01,\n",
      "          3.8258e-01,  1.4547e-01, -1.7297e-01,  3.8544e-02, -3.1107e-01,\n",
      "         -1.8706e+00, -2.0439e-01, -1.0771e-01,  3.1944e-01,  4.9499e-02,\n",
      "         -1.0994e-01,  1.5210e-01, -1.4176e+00,  5.2413e-02, -8.5459e-01,\n",
      "         -9.9805e-01,  1.9167e+00, -6.7263e-03,  2.3618e+00, -2.4710e-01,\n",
      "         -1.2896e-01,  3.7116e-01,  8.9034e-01, -6.4879e-02,  4.0245e-01,\n",
      "          3.8369e-01, -3.5353e-01,  5.1265e-01, -3.5775e-01,  6.3312e-02,\n",
      "         -1.3479e+00, -1.6700e-01, -2.2919e-01, -1.7324e-01, -3.7457e-01,\n",
      "         -1.0357e-01, -1.8559e-01, -5.9229e-01, -1.9978e-01,  4.4437e-01,\n",
      "         -8.8195e-01,  6.1009e-01,  5.7204e-01, -1.4240e+00, -3.9134e-01,\n",
      "          4.3413e-01,  5.6744e-01, -5.3973e-01,  1.3536e-01, -1.7571e-02,\n",
      "          4.3265e-01, -2.3575e+00, -2.0904e-01, -2.3189e+00, -6.9198e-01,\n",
      "          4.8116e-02,  4.4486e-01, -8.9616e-02, -3.0280e-01, -2.8890e-02,\n",
      "          1.9719e-01, -1.6125e+00, -1.0723e-02, -1.2308e+00,  2.7813e-02,\n",
      "          7.9382e-01, -3.8642e-01,  1.1324e-02,  3.2542e-02,  3.3886e-02,\n",
      "          8.7939e-02,  3.2446e-02, -4.3876e-01, -5.7848e-01,  2.2803e-01,\n",
      "         -5.0407e-02,  6.0831e-01, -1.8474e-01,  2.5290e+00,  4.7034e-01,\n",
      "         -7.4563e-01,  1.8814e-01,  5.8178e-02,  1.7588e-01, -2.3231e-01,\n",
      "         -2.6213e-01, -3.2092e-01,  3.5052e-01,  2.3856e-02, -9.3220e-02,\n",
      "         -1.4070e+00,  8.7897e-01, -1.7089e-01,  1.5757e-01,  6.0234e-01,\n",
      "          1.0688e-01, -5.8827e-02,  4.0119e-01, -8.5685e-02, -2.9215e-01,\n",
      "          3.3505e-02,  5.2877e-01,  8.5433e-02, -1.3682e-01,  5.6899e-02,\n",
      "          3.0420e-02, -1.6028e+00,  1.9255e-01,  1.2622e-01, -9.5260e-01,\n",
      "          2.0320e-01,  2.3399e-01,  2.6022e-01, -4.4882e-02, -3.5379e-01,\n",
      "         -4.8428e-01,  7.3951e-01,  3.5998e-01, -3.1704e-02,  6.6309e-01,\n",
      "          1.2429e-01,  1.0664e-01, -4.8499e-01, -1.4012e+00,  6.6858e-01,\n",
      "         -5.0829e-01,  3.4053e-02, -7.1859e-02,  2.4280e-01,  1.2617e-01,\n",
      "          3.1691e-01,  5.0482e-01, -1.4471e-01,  5.6196e-01, -1.0742e+00,\n",
      "         -3.1774e+00, -5.2434e-01, -7.6493e-01, -3.8002e-01, -7.4135e-02,\n",
      "         -1.2321e-01, -4.9928e-01,  3.1236e-01,  4.7799e-01,  9.0799e-01,\n",
      "         -6.3907e-02, -3.8825e-01,  1.3708e-01, -1.9597e-01, -6.9311e-01,\n",
      "         -2.2167e-01,  8.6342e-02,  5.5120e-03,  1.1685e+00, -1.1648e-01,\n",
      "          2.3934e-01,  1.8242e+00, -2.1611e-01, -2.9277e-01,  2.9649e-01,\n",
      "         -2.1038e-01, -2.2648e-01, -7.3345e-02,  1.4272e+00, -1.9541e-01,\n",
      "         -7.2778e-02,  5.3655e-01,  8.1853e-02]], device='cuda:0'), 'image_labels': None, 'image_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0'), 'patch_index': (tensor([[[ 1,  8],\n",
      "         [ 2, 14],\n",
      "         [ 9,  8],\n",
      "         [ 3,  9],\n",
      "         [ 9,  3],\n",
      "         [ 7,  9],\n",
      "         [ 8,  1],\n",
      "         [ 4, 14],\n",
      "         [ 0,  5],\n",
      "         [ 6,  5],\n",
      "         [ 1, 14],\n",
      "         [ 2, 17],\n",
      "         [ 9, 10],\n",
      "         [10,  8],\n",
      "         [ 9, 13],\n",
      "         [ 9, 14],\n",
      "         [ 7, 15],\n",
      "         [ 7, 14],\n",
      "         [ 9,  0],\n",
      "         [ 9,  5],\n",
      "         [ 3,  8],\n",
      "         [ 5, 14],\n",
      "         [ 1,  5],\n",
      "         [10,  7],\n",
      "         [ 5, 15],\n",
      "         [10,  6],\n",
      "         [ 4,  8],\n",
      "         [ 4,  2],\n",
      "         [ 9, 12],\n",
      "         [ 8,  2],\n",
      "         [ 0,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  0],\n",
      "         [ 0,  3],\n",
      "         [ 5, 11],\n",
      "         [ 9,  6],\n",
      "         [ 6,  0],\n",
      "         [10, 14],\n",
      "         [ 2, 11],\n",
      "         [ 8, 18],\n",
      "         [ 6,  1],\n",
      "         [ 2, 16],\n",
      "         [ 0, 15],\n",
      "         [ 5, 17],\n",
      "         [ 6,  9],\n",
      "         [10,  9],\n",
      "         [ 9, 11],\n",
      "         [ 1, 13],\n",
      "         [ 3, 11],\n",
      "         [ 6,  7],\n",
      "         [ 3, 16],\n",
      "         [ 4, 17],\n",
      "         [ 4, 13],\n",
      "         [ 1, 17],\n",
      "         [ 7,  0],\n",
      "         [ 9, 18],\n",
      "         [ 3,  7],\n",
      "         [ 0, 17],\n",
      "         [ 3, 12],\n",
      "         [ 2, 10],\n",
      "         [ 0,  8],\n",
      "         [ 8, 10],\n",
      "         [ 8, 12],\n",
      "         [ 4,  3],\n",
      "         [ 6,  6],\n",
      "         [ 7, 10],\n",
      "         [ 5,  3],\n",
      "         [ 5,  0],\n",
      "         [10,  1],\n",
      "         [ 9,  4],\n",
      "         [ 2,  6],\n",
      "         [ 3,  0],\n",
      "         [ 0, 14],\n",
      "         [ 8, 14],\n",
      "         [ 6, 17],\n",
      "         [ 6, 14],\n",
      "         [ 5,  6],\n",
      "         [10, 17],\n",
      "         [ 9,  2],\n",
      "         [ 4,  9],\n",
      "         [ 2,  1],\n",
      "         [ 5,  9],\n",
      "         [ 7, 11],\n",
      "         [ 1,  4],\n",
      "         [ 3, 10],\n",
      "         [ 3, 15],\n",
      "         [ 4, 18],\n",
      "         [ 1,  7],\n",
      "         [ 4,  6],\n",
      "         [ 5, 12],\n",
      "         [ 6,  3],\n",
      "         [ 7,  2],\n",
      "         [ 0,  4],\n",
      "         [ 8, 13],\n",
      "         [ 2,  7],\n",
      "         [ 4,  7],\n",
      "         [ 6, 11],\n",
      "         [ 7, 13],\n",
      "         [ 4, 16],\n",
      "         [ 7,  1],\n",
      "         [ 8, 15],\n",
      "         [ 4,  4],\n",
      "         [ 3, 17],\n",
      "         [ 1,  0],\n",
      "         [ 8,  0],\n",
      "         [ 5, 18],\n",
      "         [ 8,  8],\n",
      "         [ 1,  1],\n",
      "         [ 0, 10],\n",
      "         [ 8,  5],\n",
      "         [ 0, 18],\n",
      "         [ 3,  4],\n",
      "         [ 9,  7],\n",
      "         [ 2,  0],\n",
      "         [10, 16],\n",
      "         [ 8, 17],\n",
      "         [10,  4],\n",
      "         [ 1, 10],\n",
      "         [ 3,  2],\n",
      "         [ 5, 16],\n",
      "         [ 3,  6],\n",
      "         [ 6, 10],\n",
      "         [ 2,  2],\n",
      "         [ 3, 18],\n",
      "         [10,  0],\n",
      "         [10, 10],\n",
      "         [ 7,  8],\n",
      "         [ 1,  2],\n",
      "         [ 8,  4],\n",
      "         [ 9,  1],\n",
      "         [ 5,  4],\n",
      "         [ 7, 12],\n",
      "         [ 0,  1],\n",
      "         [ 5,  8],\n",
      "         [ 3, 13],\n",
      "         [ 0,  7],\n",
      "         [ 7, 18],\n",
      "         [ 2,  3],\n",
      "         [ 2,  5],\n",
      "         [ 5,  5],\n",
      "         [ 7,  3],\n",
      "         [ 6, 18],\n",
      "         [ 8, 16],\n",
      "         [ 0, 16],\n",
      "         [ 6,  8],\n",
      "         [ 4, 11],\n",
      "         [ 2,  4],\n",
      "         [ 2, 15],\n",
      "         [ 8,  9],\n",
      "         [ 5, 13],\n",
      "         [ 3, 14],\n",
      "         [ 2, 12],\n",
      "         [ 4, 10],\n",
      "         [ 2, 18],\n",
      "         [ 9, 15],\n",
      "         [ 1, 16],\n",
      "         [ 7,  7],\n",
      "         [ 4,  5],\n",
      "         [ 7,  4],\n",
      "         [ 7,  6],\n",
      "         [ 7, 17],\n",
      "         [ 6, 15],\n",
      "         [ 6, 16],\n",
      "         [ 1,  3],\n",
      "         [ 4,  1],\n",
      "         [ 8,  6],\n",
      "         [ 1,  6],\n",
      "         [ 9, 16],\n",
      "         [ 8,  3],\n",
      "         [ 0, 12],\n",
      "         [ 0,  0],\n",
      "         [ 4, 15],\n",
      "         [ 5,  7],\n",
      "         [ 3,  5],\n",
      "         [ 1,  9],\n",
      "         [ 9, 17],\n",
      "         [ 5, 10],\n",
      "         [ 6, 13],\n",
      "         [ 8, 11],\n",
      "         [ 5,  2],\n",
      "         [ 1, 11],\n",
      "         [ 0,  9],\n",
      "         [10,  2],\n",
      "         [ 3,  1],\n",
      "         [ 2,  8],\n",
      "         [ 6,  2],\n",
      "         [10, 12],\n",
      "         [ 4, 12],\n",
      "         [ 1, 12],\n",
      "         [10,  3],\n",
      "         [10, 18],\n",
      "         [10,  5],\n",
      "         [10, 15],\n",
      "         [ 2, 13],\n",
      "         [ 0, 13],\n",
      "         [ 9,  9],\n",
      "         [ 2,  9],\n",
      "         [ 0, 11],\n",
      "         [ 7, 16],\n",
      "         [ 7,  5],\n",
      "         [ 8,  7],\n",
      "         [ 1, 15],\n",
      "         [ 6,  4],\n",
      "         [ 0,  6],\n",
      "         [ 1, 18],\n",
      "         [10, 13],\n",
      "         [10, 11],\n",
      "         [ 6, 12],\n",
      "         [ 5,  1]]]), (11, 19)), 'cls_output': tensor([[0.3804]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2814811/3734256495.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img)\n"
     ]
    }
   ],
   "source": [
    "idx = 64\n",
    "sensor =  torch.tensor(sensor_test_list[idx]).unsqueeze(0).unsqueeze(0)\n",
    "out = infer(image_test_list[idx],sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb Cell 60\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m876\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m sensor \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mtensor(sensor_test_list[idx])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m out \u001b[39m=\u001b[39m infer(image_test_list[idx],sensor)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "idx = 876\n",
    "sensor =  torch.tensor(sensor_test_list[idx]).unsqueeze(0).unsqueeze(0)\n",
    "out = infer(image_test_list[idx],sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1817\n",
    "sensor =  torch.tensor(sensor_test_list[idx]).unsqueeze(0).unsqueeze(0)\n",
    "out = infer(image_test_list[idx],sensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch_junsheng_39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29fd19f11c6b89e267402bb3227bc1208f7e2c9719aa03eba13baf7684fe5867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
