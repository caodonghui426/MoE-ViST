{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from vilt.modules import heads, objectives\n",
    "import vilt.modules.vision_transformer as vit\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from typing import OrderedDict\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vilt.transforms import pixelbert_transform\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class config:\n",
    "    debug = False\n",
    "    exp_name = \"vilt\"\n",
    "    seed = 101\n",
    "    batch_size = 4096  # this is a desired batch size; pl trainer will accumulate gradients when per step batch is smaller.\n",
    "    train_batch_size = 32\n",
    "    valid_batch_size = 4\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_fold = 5\n",
    "\n",
    "    model_name = \"sensorViLOnlyTransformerSS\"\n",
    "    # wandb \n",
    "    wandb_name = \"vilt|大豆|290仅图片\"\n",
    "    \n",
    "\n",
    "    # Image setting\n",
    "    train_transform_keys = [\"pixelbert\"]\n",
    "    val_transform_keys = [\"pixelbert\"]\n",
    "    img_size = 384\n",
    "    max_image_len = -1\n",
    "    patch_size = 32\n",
    "    draw_false_image = 1\n",
    "    image_only = False\n",
    "\n",
    "    # Sensor\n",
    "    # senser_input_num = 11 # 翔冠的传感器参数\n",
    "    senser_input_num = 19 # 天航的传感器参数\n",
    "    \n",
    "    # Text Setting\n",
    "    vqav2_label_size = 3129\n",
    "    max_text_len = 40\n",
    "    tokenizer = \"bert-base-uncased\"\n",
    "    vocab_size = 30522 # vocabulary词汇数量\n",
    "    whole_word_masking = False\n",
    "    mlm_prob = 0.15\n",
    "    draw_false_text = 0\n",
    "\n",
    "    # Transformer Setting\n",
    "    vit = \"vit_base_patch32_384\"\n",
    "    hidden_size = 768  # 嵌入向量大小\n",
    "    num_heads = 12\n",
    "    num_layers = 12\n",
    "    mlp_ratio = 4\n",
    "    drop_rate = 0.1\n",
    "\n",
    "    # Optimizer Setting\n",
    "    optim_type = \"adamw\"\n",
    "    learning_rate = 1e-3 #0.0015#2e-3 #\n",
    "    weight_decay = 1e-4 # 0.01 ->1e-4\n",
    "    decay_power = 1\n",
    "    max_epoch = 50\n",
    "    max_steps = 25000\n",
    "    warmup_steps = 2500\n",
    "    end_lr = 0\n",
    "    lr_mult = 1  # multiply lr for downstream heads\n",
    "    # T_max = 8000/train_batch_size*max_epoch \n",
    "    T_max = 1000/train_batch_size*max_epoch \n",
    "\n",
    "    # Downstream Setting\n",
    "    get_recall_metric = False\n",
    "\n",
    "\n",
    "    # below params varies with the environment\n",
    "    data_root = \"\"\n",
    "    log_dir = \"result\"\n",
    "    per_gpu_batchsize = 0  # you should define this manually with per_gpu_batch_size=#\n",
    "    num_gpus = 1\n",
    "    num_nodes = 1\n",
    "    load_path = \"weights/vilt_200k_mlm_itm.ckpt\"\n",
    "    # load_path = \"save_model_dict.pt\"\n",
    "    num_workers = 1\n",
    "    precision = 16\n",
    "\n",
    "# config = vars(config)\n",
    "# config = dict(config)\n",
    "config\n",
    "\n",
    "if config.debug:\n",
    "    config.max_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "\n",
    "    torch.manual_seed(seed)  # 为CPU设置随机种子\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.manual_seed(seed)  # 为当前GPU设置随机种子\n",
    "    torch.cuda.manual_seed_all(seed)  # 为所有GPU设置随机种子\n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "setup_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_MODE\"] = 'dryrun' # 离线模式\n",
    "try:\n",
    "    # wandb.log(key=\"*******\") # if debug\n",
    "    wandb.login() # storage in ~/.netrc file\n",
    "    anonymous = None\n",
    "except:\n",
    "    anonymous = \"must\"\n",
    "    print('\\nGet your W&B access token from here: https://wandb.ai/authorize\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2658, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pic_key</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date</th>\n",
       "      <th>co2</th>\n",
       "      <th>stemp</th>\n",
       "      <th>stemp2</th>\n",
       "      <th>stemp3</th>\n",
       "      <th>stemp4</th>\n",
       "      <th>stemp5</th>\n",
       "      <th>...</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm25</th>\n",
       "      <th>press</th>\n",
       "      <th>solar</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind_d</th>\n",
       "      <th>wind_sp</th>\n",
       "      <th>LAI</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>/794/1655497027_1655496664_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022/6/18</td>\n",
       "      <td>419.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>991.1</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.26</td>\n",
       "      <td>274.3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>/home/junsheng/data/tianhang_soybean/165549702...</td>\n",
       "      <td>1.3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>/794/1655497027_1655496664_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022/6/18</td>\n",
       "      <td>419.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>991.2</td>\n",
       "      <td>5.93</td>\n",
       "      <td>17.18</td>\n",
       "      <td>268.7</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>/home/junsheng/data/tianhang_soybean/165549702...</td>\n",
       "      <td>1.3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>/794/1655497027_1655496664_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022/6/18</td>\n",
       "      <td>418.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>991.1</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.26</td>\n",
       "      <td>274.3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>/home/junsheng/data/tianhang_soybean/165549702...</td>\n",
       "      <td>1.3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>/794/1655497027_1655496664_4.jpg</td>\n",
       "      <td>2022-06-18 04</td>\n",
       "      <td>2022/6/18</td>\n",
       "      <td>418.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>991.2</td>\n",
       "      <td>5.93</td>\n",
       "      <td>17.18</td>\n",
       "      <td>268.7</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>/home/junsheng/data/tianhang_soybean/165549702...</td>\n",
       "      <td>1.3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>/794/1655504185_1655503864_4.jpg</td>\n",
       "      <td>2022-06-18 06</td>\n",
       "      <td>2022/6/18</td>\n",
       "      <td>419.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>991.9</td>\n",
       "      <td>8.84</td>\n",
       "      <td>17.75</td>\n",
       "      <td>248.6</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>/home/junsheng/data/tianhang_soybean/165550418...</td>\n",
       "      <td>1.3175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                           pic_key      date_hour       date    co2  \\\n",
       "0     32  /794/1655497027_1655496664_4.jpg  2022-06-18 04  2022/6/18  419.0   \n",
       "1     33  /794/1655497027_1655496664_4.jpg  2022-06-18 04  2022/6/18  419.0   \n",
       "2     34  /794/1655497027_1655496664_4.jpg  2022-06-18 04  2022/6/18  418.0   \n",
       "3     35  /794/1655497027_1655496664_4.jpg  2022-06-18 04  2022/6/18  418.0   \n",
       "4     36  /794/1655504185_1655503864_4.jpg  2022-06-18 06  2022/6/18  419.0   \n",
       "\n",
       "   stemp  stemp2  stemp3  stemp4  stemp5  ...  pm10  pm25  press  solar  \\\n",
       "0   19.2    19.3    19.1    18.8    18.4  ...   6.0   6.0  991.1   2.52   \n",
       "1   19.2    19.3    19.1    18.8    18.4  ...   7.0   7.0  991.2   5.93   \n",
       "2   19.1    19.2    19.1    18.8    18.4  ...   6.0   6.0  991.1   2.52   \n",
       "3   19.1    19.2    19.1    18.8    18.4  ...   7.0   7.0  991.2   5.93   \n",
       "4   18.8    19.0    18.9    18.7    18.3  ...   5.0   5.0  991.9   8.84   \n",
       "\n",
       "    temp wind_d wind_sp     LAI  \\\n",
       "0  17.26  274.3    3.75  1.3175   \n",
       "1  17.18  268.7    2.67  1.3175   \n",
       "2  17.26  274.3    3.75  1.3175   \n",
       "3  17.18  268.7    2.67  1.3175   \n",
       "4  17.75  248.6    2.07  1.3175   \n",
       "\n",
       "                                          image_path   label  \n",
       "0  /home/junsheng/data/tianhang_soybean/165549702...  1.3175  \n",
       "1  /home/junsheng/data/tianhang_soybean/165549702...  1.3175  \n",
       "2  /home/junsheng/data/tianhang_soybean/165549702...  1.3175  \n",
       "3  /home/junsheng/data/tianhang_soybean/165549702...  1.3175  \n",
       "4  /home/junsheng/data/tianhang_soybean/165550418...  1.3175  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tianhang = pd.read_csv(\"/home/junsheng/ViLT/data/290-tianhang-soybean.csv\")\n",
    "df_tianhang['image_path'] = df_tianhang['pic_key'].map(lambda x:os.path.join('/home/junsheng/data/tianhang_soybean',x.split('/')[-1]))\n",
    "df_tianhang['label'] = df_tianhang['LAI']\n",
    "df_tianhang = df_tianhang.dropna()\n",
    "df_tianhang = df_tianhang.reset_index()\n",
    "print(df_tianhang.shape)\n",
    "df_tianhang.to_csv(\"test.csv\",index=False)\n",
    "df_tianhang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n",
      "811\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "# 检查图片下载的全不全\n",
    "pic = df_tianhang.image_path.map(lambda x:x.split('/')[-1]).unique()\n",
    "print(len(pic))\n",
    "file_ls = os.listdir(\"/home/junsheng/data/tianhang_soybean\")\n",
    "print(len(file_ls))\n",
    "ret = list(set(pic) ^ set(file_ls))\n",
    "print(len(ret)) #差集\n",
    "# assert len(pic)==len(file_ls),\"请检查下载的图片，缺了{}个\".format(len(pic)-len(file_ls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化非object列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'pic_key',\n",
       " 'date_hour',\n",
       " 'date',\n",
       " 'co2',\n",
       " 'stemp',\n",
       " 'stemp2',\n",
       " 'stemp3',\n",
       " 'stemp4',\n",
       " 'stemp5',\n",
       " 'shumi',\n",
       " 'shumi2',\n",
       " 'shumi3',\n",
       " 'shumi4',\n",
       " 'shumi5',\n",
       " 'ts',\n",
       " 'insert_time',\n",
       " 'humi',\n",
       " 'pm10',\n",
       " 'pm25',\n",
       " 'press',\n",
       " 'solar',\n",
       " 'temp',\n",
       " 'wind_d',\n",
       " 'wind_sp',\n",
       " 'LAI',\n",
       " 'image_path',\n",
       " 'label']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_tianhang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'co2', 'stemp', 'stemp2', 'stemp3', 'stemp4', 'stemp5', 'shumi', 'shumi2', 'shumi3', 'shumi4', 'shumi5', 'humi', 'pm10', 'pm25', 'press', 'solar', 'temp', 'wind_d', 'wind_sp', 'LAI', 'label']\n",
      "{'index': (32, 3161), 'co2': (341.0, 751.0), 'stemp': (14.0, 29.0), 'stemp2': (14.8, 27.5), 'stemp3': (15.5, 25.7), 'stemp4': (15.6, 24.6), 'stemp5': (16.0, 24.3), 'shumi': (44.6, 75.7), 'shumi2': (36.5, 71.3), 'shumi3': (38.9, 71.7), 'shumi4': (43.6, 75.0), 'shumi5': (61.6, 80.0), 'humi': (31.0, 100.0), 'pm10': (0.0, 1333.0), 'pm25': (0.0, 1333.0), 'press': (981.1, 1014.8), 'solar': (0.0, 200.0), 'temp': (7.25, 32.0), 'wind_d': (0.0, 359.8), 'wind_sp': (0.0, 10.27), 'LAI': (1.3175, 2.23), 'label': (1.3175, 2.23)}\n"
     ]
    }
   ],
   "source": [
    "number_title = []\n",
    "recorder = {}\n",
    "for title in df_tianhang:\n",
    "    # print(df_xiangguan[title].head())\n",
    "    if title == 'raw_label':\n",
    "        continue\n",
    "    if df_tianhang[title].dtype != \"object\":\n",
    "        \n",
    "        number_title.append(title)\n",
    "        x_min = df_tianhang[title].min()\n",
    "        x_max = df_tianhang[title].max()\n",
    "        # print(x_min,x_max)\n",
    "        recorder[title] = (x_min,x_max)\n",
    "        df_tianhang[title] = df_tianhang[title].map(lambda x:(x-x_min)/(x_max - x_min))\n",
    "print(number_title)\n",
    "print(recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tianhang['stemp4'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: 19\n"
     ]
    }
   ],
   "source": [
    "# xiangguan_sensor = ['temperature', 'humidity', 'illuminance', 'soil_temperature', 'soil_humidity', 'pressure', 'wind_speed', 'photosynthetic', 'sun_exposure_time', 'COz', 'soil_ph']\n",
    "tianhang_sensor = ['co2', 'stemp', 'stemp2', 'stemp3', 'stemp4', 'stemp5', 'shumi', 'shumi2', 'shumi3', 'shumi4', 'shumi5', 'humi', 'pm10', 'pm25', 'press', 'solar', 'temp', 'wind_d', 'wind_sp']\n",
    "# tianhang_sensor = ['co2', 'stemp', 'stemp2', 'stemp3', 'stemp5', 'shumi', 'shumi2', 'shumi3', 'shumi5', 'humi', 'pm10', 'pm25', 'press', 'solar', 'temp', 'wind_d', 'wind_sp']\n",
    "\n",
    "df_tianhang['sensor'] = df_tianhang[tianhang_sensor].values.tolist()\n",
    "print(\"input dim:\",len(tianhang_sensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2658, 29)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_tianhang\n",
    "if config.debug:\n",
    "    df = df[:100]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tianhang.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0.0    532\n",
       "1.0    532\n",
       "2.0    532\n",
       "3.0    531\n",
       "4.0    531\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)  \n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df,df.date)):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "df.groupby(['fold'])['label'].count()# ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv(\"test_fold.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((config.img_size,config.img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    mean=[0.7136, 0.7118, 0.6788],\n",
    "    std=[0.3338, 0.3453, 0.3020],\n",
    "    \n",
    ")\n",
    "])\n",
    "\n",
    "def load_img(path):\n",
    "    img =  Image.open(path).convert('RGB')\n",
    "    img = myTransforms(img)\n",
    "    return img\n",
    "\n",
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, label=True, transforms=None):\n",
    "        self.df         = df\n",
    "        self.label      = label\n",
    "        self.sensors = df['sensor'].tolist()\n",
    "        self.img_paths  = df['image_path'].tolist()   \n",
    "        if self.label:\n",
    "            self.labels = df['label'].tolist()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        img = load_img(img_path)\n",
    "        sensor = self.sensors[index]\n",
    "        sensor = torch.tensor(sensor).unsqueeze(0) #[1,n]\n",
    "        if self.label:\n",
    "            label = self.labels[index]\n",
    "            return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n",
    "        else:\n",
    "            return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_dataloader(fold:int):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    print(\"train_df.shape:\",train_df.shape)\n",
    "    print(\"valid_df.shape:\",valid_df.shape)\n",
    "\n",
    "    train_data  = BuildDataset(df=train_df,label=True)\n",
    "    valid_data = BuildDataset(df=valid_df,label=True)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.train_batch_size,shuffle=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=config.valid_batch_size,shuffle=False)\n",
    "    # test_loader = DataLoader(test_data, batch_size=config.test_batch_size,shuffle=False)\n",
    "    return train_loader,valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape: (2126, 30)\n",
      "valid_df.shape: (532, 30)\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = BuildDataset(df=df)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=config.train_batch_size,shuffle=True)\n",
    "# valid_loader = DataLoader(train_dataset, batch_size=config.valid_batch_size,shuffle=True)\n",
    "train_loader,valid_loader = fetch_dataloader(fold=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_389858/355586058.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 384, 384])\n",
      "torch.Size([32, 1, 19])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "img,sensor,label = next(iter(train_loader))\n",
    "print(img.shape)\n",
    "print(sensor.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorViLOnlyTransformerSS-仅vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sensorViLOnlyTransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self, sensor_class_n, output_class_n):\n",
    "        super().__init__()\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "            pretrained=True, config=vars(config)\n",
    "        )\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "        self.classifier = nn.Linear(config.hidden_size, output_class_n)\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        mask_image=False,\n",
    "        image_token_type_idx=1,\n",
    "        image_embeds=None,\n",
    "        image_masks=None,\n",
    "    ):\n",
    "\n",
    "        if image_embeds is None and image_masks is None:\n",
    "            img = batch[\"image\"].to(config.device)\n",
    "\n",
    "            (\n",
    "                image_embeds,  # torch.Size([1, 217, 768])\n",
    "                image_masks,  # torch.Size([1, 217])\n",
    "                patch_index,\n",
    "                image_labels,\n",
    "            ) = self.transformer.visual_embed(\n",
    "                img,\n",
    "                max_image_len=config.max_image_len,\n",
    "                mask_it=mask_image,\n",
    "            )\n",
    "        else:\n",
    "            patch_index, image_labels = (\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        image_embeds = image_embeds + self.token_type_embeddings(\n",
    "            torch.full_like(image_masks, image_token_type_idx)\n",
    "        )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(batch_size, 1).to(config.device)  # 序列数量\n",
    "        image_masks = image_masks.to(config.device)\n",
    "        co_embeds = image_embeds\n",
    "        co_masks = image_masks\n",
    "\n",
    "        x = co_embeds.to(config.device)  # torch.Size([1, 145, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks):\n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks)  # co_masks = torch.Size([1, 211])\n",
    "\n",
    "        x = self.transformer.norm(x)  # torch.Size([1, 240, 768])\n",
    "        image_feats = x\n",
    "        cls_feats = self.pooler(x)  # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "\n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "\n",
    "        ret = {\n",
    "            \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats,  # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            \"image_labels\": image_labels,\n",
    "            \"image_masks\": image_masks,\n",
    "\n",
    "            \"patch_index\": patch_index,\n",
    "\n",
    "            \"cls_output\": cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "\n",
    "        ret.update(self.infer(batch))\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorViLTransformerSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorViLTransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config.hidden_size) \n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "                pretrained=True, config=vars(config)\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config.hidden_size,output_class_n)\n",
    "\n",
    "        hs = config.hidden_size\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        mask_image=False,\n",
    "        image_token_type_idx=1,\n",
    "        image_embeds=None,\n",
    "        image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config.device)\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        \n",
    "\n",
    "        if image_embeds is None and image_masks is None:\n",
    "            img = batch[\"image\"].to(config.device)\n",
    "       \n",
    "            (\n",
    "                image_embeds, # torch.Size([1, 217, 768])\n",
    "                image_masks, # torch.Size([1, 217])\n",
    "                patch_index,\n",
    "                image_labels,\n",
    "            ) = self.transformer.visual_embed(\n",
    "                img,\n",
    "                max_image_len=config.max_image_len,\n",
    "                mask_it=mask_image,\n",
    "            )\n",
    "        else:\n",
    "            patch_index, image_labels = (\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        image_embeds = image_embeds + self.token_type_embeddings(\n",
    "                torch.full_like(image_masks, image_token_type_idx)\n",
    "            )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(batch_size,1).to(config.device) # 序列数量\n",
    "        image_masks = image_masks.to(config.device)\n",
    "        co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "\n",
    "        x = co_embeds.to(config.device) # torch.Size([1, 211, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks): \n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks) # co_masks = torch.Size([1, 211])\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "            x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "            x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "        \n",
    "        ret = {\n",
    "           \"sensor_feats\":sensor_feats,\n",
    "            \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            \"image_labels\": image_labels,\n",
    "            \"image_masks\": image_masks,\n",
    "           \n",
    "            \"patch_index\": patch_index,\n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorOnlyViLTransformerSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorOnlyViLTransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config.hidden_size) \n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "                pretrained=True, config=vars(config)\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config.hidden_size,output_class_n)\n",
    "\n",
    "        hs = config.hidden_size\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        # mask_image=False,\n",
    "        # image_token_type_idx=1,\n",
    "        # image_embeds=None,\n",
    "        # image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config.device)\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        \n",
    "\n",
    "        # if image_embeds is None and image_masks is None:\n",
    "        #     img = batch[\"image\"].to(config.device)\n",
    "       \n",
    "        #     (\n",
    "        #         image_embeds, # torch.Size([1, 217, 768])\n",
    "        #         image_masks, # torch.Size([1, 217])\n",
    "        #         patch_index,\n",
    "        #         image_labels,\n",
    "        #     ) = self.transformer.visual_embed(\n",
    "        #         img,\n",
    "        #         max_image_len=config.max_image_len,\n",
    "        #         mask_it=mask_image,\n",
    "        #     )\n",
    "        # else:\n",
    "        #     patch_index, image_labels = (\n",
    "        #         None,\n",
    "        #         None,\n",
    "        #     )\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        # image_embeds = image_embeds + self.token_type_embeddings(\n",
    "        #         torch.full_like(image_masks, image_token_type_idx)\n",
    "        #     )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        # batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(sensor_embeds.shape[1],1).to(config.device) # 序列数量\n",
    "        # image_masks = image_masks.to(config.device)\n",
    "        # co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        # co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "        co_embeds = sensor_embeds\n",
    "        co_masks = sensor_masks\n",
    "\n",
    "        x = co_embeds.to(config.device) # torch.Size([1, 1, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks):\n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks)\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        # sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "        #     x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "        #     x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        # )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "        \n",
    "        ret = {\n",
    "        #    \"sensor_feats\":sensor_feats,\n",
    "            # \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            # \"image_labels\": image_labels,\n",
    "            # \"image_masks\": image_masks,\n",
    "           \n",
    "            # \"patch_index\": patch_index,\n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorResnet50TransformerSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorResnet50TransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config.hidden_size) \n",
    "        # resnet model\n",
    "        resnet_model = pretrainedmodels.__dict__[\"resnet50\"](\n",
    "    num_classes=1000, pretrained='imagenet')\n",
    "        features = list([resnet_model.conv1, resnet_model.bn1, resnet_model.relu, resnet_model.maxpool, resnet_model.layer1, resnet_model.layer2, resnet_model.layer3,resnet_model.layer4])\n",
    "        conv = nn.Conv2d(2048, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        bn = nn.BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "        self.resnet_features = nn.Sequential(*features,conv,bn,relu)\n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "                pretrained=True, config=vars(config)\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config.hidden_size,output_class_n)\n",
    "\n",
    "        hs = config.hidden_size\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        mask_image=False,\n",
    "        image_token_type_idx=1,\n",
    "        image_embeds=None,\n",
    "        image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config.device)\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        img = batch[\"image\"].to(config.device)\n",
    "        image_embeds = self.resnet_features(img) \n",
    "        image_embeds = image_embeds.flatten(2).transpose(1, 2)\n",
    "        image_masks = torch.ones(image_embeds.shape[0],image_embeds.shape[1],dtype=torch.int64).to(config.device)\n",
    "\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        image_embeds = image_embeds + self.token_type_embeddings(\n",
    "                torch.full_like(image_masks, image_token_type_idx)\n",
    "            )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(batch_size,1).to(config.device) # 序列数量\n",
    "        image_masks = image_masks.to(config.device)\n",
    "        co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "\n",
    "        x = co_embeds.to(config.device) # torch.Size([1, 211, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks): \n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks) # co_masks = torch.Size([1, 211])\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "            x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "            x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "        \n",
    "        ret = {\n",
    "           \"sensor_feats\":sensor_feats,\n",
    "            \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            \"image_masks\": image_masks,\n",
    "           \n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensorResnet101TransformerSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorResnet101TransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config.hidden_size) \n",
    "        # resnet model\n",
    "        resnet_model = pretrainedmodels.__dict__[\"resnet101\"](\n",
    "    num_classes=1000, pretrained='imagenet')\n",
    "        features = list([resnet_model.conv1, resnet_model.bn1, resnet_model.relu, resnet_model.maxpool, resnet_model.layer1, resnet_model.layer2, resnet_model.layer3,resnet_model.layer4])\n",
    "        conv = nn.Conv2d(2048, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        bn = nn.BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "        self.resnet_features = nn.Sequential(*features,conv,bn,relu)\n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config.hidden_size)\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        self.transformer = getattr(vit, config.vit)(\n",
    "                pretrained=True, config=vars(config)\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config.hidden_size)\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config.hidden_size,output_class_n)\n",
    "\n",
    "        hs = config.hidden_size\n",
    "\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        mask_image=False,\n",
    "        image_token_type_idx=1,\n",
    "        image_embeds=None,\n",
    "        image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config.device)\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        img = batch[\"image\"].to(config.device)\n",
    "        image_embeds = self.resnet_features(img) \n",
    "        image_embeds = image_embeds.flatten(2).transpose(1, 2)\n",
    "        image_masks = torch.ones(image_embeds.shape[0],image_embeds.shape[1],dtype=torch.int64).to(config.device)\n",
    "\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        image_embeds = image_embeds + self.token_type_embeddings(\n",
    "                torch.full_like(image_masks, image_token_type_idx)\n",
    "            )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(batch_size,1).to(config.device) # 序列数量\n",
    "        image_masks = image_masks.to(config.device)\n",
    "        co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "\n",
    "        x = co_embeds.to(config.device) # torch.Size([1, 211, 768])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks): \n",
    "            blk = blk.to(config.device)\n",
    "            x, _attn = blk(x, mask=co_masks) # co_masks = torch.Size([1, 211])\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "            x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "            x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        \n",
    "        m = nn.Sigmoid()\n",
    "        cls_output = m(cls_output)\n",
    "        \n",
    "        ret = {\n",
    "           \"sensor_feats\":sensor_feats,\n",
    "            \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            \"image_masks\": image_masks,\n",
    "           \n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No pretrained weights exist or were found for this model. Using random initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "0 sensorViLOnlyTransformerSS(\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (transformer): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      "  (pooler): Pooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n",
      "1 Embedding(2, 768)\n",
      "2 VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      ")\n",
      "3 PatchEmbed(\n",
      "  (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      ")\n",
      "4 Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "5 Dropout(p=0.1, inplace=False)\n",
      "6 ModuleList(\n",
      "  (0): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (2): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (3): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (4): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (5): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (6): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (7): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (8): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (9): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (10): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (11): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "8 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "9 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "10 Linear(in_features=768, out_features=2304, bias=True)\n",
      "11 Dropout(p=0.0, inplace=False)\n",
      "12 Linear(in_features=768, out_features=768, bias=True)\n",
      "13 Dropout(p=0.1, inplace=False)\n",
      "14 Identity()\n",
      "15 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "16 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "17 Linear(in_features=768, out_features=3072, bias=True)\n",
      "18 GELU(approximate=none)\n",
      "19 Linear(in_features=3072, out_features=768, bias=True)\n",
      "20 Dropout(p=0.1, inplace=False)\n",
      "21 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "22 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "23 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "24 Linear(in_features=768, out_features=2304, bias=True)\n",
      "25 Dropout(p=0.0, inplace=False)\n",
      "26 Linear(in_features=768, out_features=768, bias=True)\n",
      "27 Dropout(p=0.1, inplace=False)\n",
      "28 Identity()\n",
      "29 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "30 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "31 Linear(in_features=768, out_features=3072, bias=True)\n",
      "32 GELU(approximate=none)\n",
      "33 Linear(in_features=3072, out_features=768, bias=True)\n",
      "34 Dropout(p=0.1, inplace=False)\n",
      "35 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "36 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "37 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "38 Linear(in_features=768, out_features=2304, bias=True)\n",
      "39 Dropout(p=0.0, inplace=False)\n",
      "40 Linear(in_features=768, out_features=768, bias=True)\n",
      "41 Dropout(p=0.1, inplace=False)\n",
      "42 Identity()\n",
      "43 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "44 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "45 Linear(in_features=768, out_features=3072, bias=True)\n",
      "46 GELU(approximate=none)\n",
      "47 Linear(in_features=3072, out_features=768, bias=True)\n",
      "48 Dropout(p=0.1, inplace=False)\n",
      "49 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "50 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "51 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "52 Linear(in_features=768, out_features=2304, bias=True)\n",
      "53 Dropout(p=0.0, inplace=False)\n",
      "54 Linear(in_features=768, out_features=768, bias=True)\n",
      "55 Dropout(p=0.1, inplace=False)\n",
      "56 Identity()\n",
      "57 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "58 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "59 Linear(in_features=768, out_features=3072, bias=True)\n",
      "60 GELU(approximate=none)\n",
      "61 Linear(in_features=3072, out_features=768, bias=True)\n",
      "62 Dropout(p=0.1, inplace=False)\n",
      "63 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "64 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "65 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "66 Linear(in_features=768, out_features=2304, bias=True)\n",
      "67 Dropout(p=0.0, inplace=False)\n",
      "68 Linear(in_features=768, out_features=768, bias=True)\n",
      "69 Dropout(p=0.1, inplace=False)\n",
      "70 Identity()\n",
      "71 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "72 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "73 Linear(in_features=768, out_features=3072, bias=True)\n",
      "74 GELU(approximate=none)\n",
      "75 Linear(in_features=3072, out_features=768, bias=True)\n",
      "76 Dropout(p=0.1, inplace=False)\n",
      "77 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "78 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "79 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "80 Linear(in_features=768, out_features=2304, bias=True)\n",
      "81 Dropout(p=0.0, inplace=False)\n",
      "82 Linear(in_features=768, out_features=768, bias=True)\n",
      "83 Dropout(p=0.1, inplace=False)\n",
      "84 Identity()\n",
      "85 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "86 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "87 Linear(in_features=768, out_features=3072, bias=True)\n",
      "88 GELU(approximate=none)\n",
      "89 Linear(in_features=3072, out_features=768, bias=True)\n",
      "90 Dropout(p=0.1, inplace=False)\n",
      "91 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "92 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "93 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "94 Linear(in_features=768, out_features=2304, bias=True)\n",
      "95 Dropout(p=0.0, inplace=False)\n",
      "96 Linear(in_features=768, out_features=768, bias=True)\n",
      "97 Dropout(p=0.1, inplace=False)\n",
      "98 Identity()\n",
      "99 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "100 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "101 Linear(in_features=768, out_features=3072, bias=True)\n",
      "102 GELU(approximate=none)\n",
      "103 Linear(in_features=3072, out_features=768, bias=True)\n",
      "104 Dropout(p=0.1, inplace=False)\n",
      "105 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "106 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "107 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "108 Linear(in_features=768, out_features=2304, bias=True)\n",
      "109 Dropout(p=0.0, inplace=False)\n",
      "110 Linear(in_features=768, out_features=768, bias=True)\n",
      "111 Dropout(p=0.1, inplace=False)\n",
      "112 Identity()\n",
      "113 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "114 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "115 Linear(in_features=768, out_features=3072, bias=True)\n",
      "116 GELU(approximate=none)\n",
      "117 Linear(in_features=3072, out_features=768, bias=True)\n",
      "118 Dropout(p=0.1, inplace=False)\n",
      "119 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "120 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "121 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "122 Linear(in_features=768, out_features=2304, bias=True)\n",
      "123 Dropout(p=0.0, inplace=False)\n",
      "124 Linear(in_features=768, out_features=768, bias=True)\n",
      "125 Dropout(p=0.1, inplace=False)\n",
      "126 Identity()\n",
      "127 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "128 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "129 Linear(in_features=768, out_features=3072, bias=True)\n",
      "130 GELU(approximate=none)\n",
      "131 Linear(in_features=3072, out_features=768, bias=True)\n",
      "132 Dropout(p=0.1, inplace=False)\n",
      "133 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "134 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "135 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "136 Linear(in_features=768, out_features=2304, bias=True)\n",
      "137 Dropout(p=0.0, inplace=False)\n",
      "138 Linear(in_features=768, out_features=768, bias=True)\n",
      "139 Dropout(p=0.1, inplace=False)\n",
      "140 Identity()\n",
      "141 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "142 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "143 Linear(in_features=768, out_features=3072, bias=True)\n",
      "144 GELU(approximate=none)\n",
      "145 Linear(in_features=3072, out_features=768, bias=True)\n",
      "146 Dropout(p=0.1, inplace=False)\n",
      "147 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "148 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "149 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "150 Linear(in_features=768, out_features=2304, bias=True)\n",
      "151 Dropout(p=0.0, inplace=False)\n",
      "152 Linear(in_features=768, out_features=768, bias=True)\n",
      "153 Dropout(p=0.1, inplace=False)\n",
      "154 Identity()\n",
      "155 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "156 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "157 Linear(in_features=768, out_features=3072, bias=True)\n",
      "158 GELU(approximate=none)\n",
      "159 Linear(in_features=3072, out_features=768, bias=True)\n",
      "160 Dropout(p=0.1, inplace=False)\n",
      "161 Block(\n",
      "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "162 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "163 Attention(\n",
      "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (proj_drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "164 Linear(in_features=768, out_features=2304, bias=True)\n",
      "165 Dropout(p=0.0, inplace=False)\n",
      "166 Linear(in_features=768, out_features=768, bias=True)\n",
      "167 Dropout(p=0.1, inplace=False)\n",
      "168 Identity()\n",
      "169 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "170 Mlp(\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "171 Linear(in_features=768, out_features=3072, bias=True)\n",
      "172 GELU(approximate=none)\n",
      "173 Linear(in_features=3072, out_features=768, bias=True)\n",
      "174 Dropout(p=0.1, inplace=False)\n",
      "175 LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "176 Linear(in_features=768, out_features=768, bias=True)\n",
      "177 Tanh()\n",
      "178 Pooler(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n",
      "179 Linear(in_features=768, out_features=768, bias=True)\n",
      "180 Tanh()\n",
      "181 Linear(in_features=768, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import pretrainedmodels\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "def build_model(model_name: str,pre_train):\n",
    "    if model_name[:6] == \"resnet50\":\n",
    "        model = pretrainedmodels.__dict__[config.model_name](\n",
    "            num_classes=1000, pretrained='imagenet')\n",
    "        dim_feats = model.last_linear.in_features  # =2048\n",
    "        nb_classes = 1\n",
    "        model.last_linear = nn.Linear(dim_feats, nb_classes)\n",
    "        return model\n",
    "    if model_name == \"se_resnet50\":\n",
    "        model = pretrainedmodels.__dict__[config.model_name](\n",
    "            num_classes=1000, pretrained='imagenet')\n",
    "        model.last_linear = nn.Linear(204800, 1,bias=True)\n",
    "        return model\n",
    "    if model_name == \"efficientnet-b4\": # efficient net\n",
    "        # refer:https://github.com/lukemelas/EfficientNet-PyTorch#example-classification\n",
    "        nb_classes = 1\n",
    "        if pre_train:\n",
    "            model = EfficientNet.from_pretrained(config.model_name)# 'efficientnet-b4'\n",
    "        else:\n",
    "            model = EfficientNet.from_name(config.model_name)# 'efficientnet-b4'\n",
    "        model._fc = nn.Linear(1792, nb_classes)\n",
    "        return model\n",
    "\n",
    "    if model_name == \"sensorOnlyViLTransformerSS\": #仅传感器\n",
    "        model = sensorOnlyViLTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "        return model\n",
    "    if model_name == \"sensorViLOnlyTransformerSS\": # 仅vit图像\n",
    "        model = sensorViLOnlyTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "        return model\n",
    "        \n",
    "    if model_name == \"sensorResnet50TransformerSS\":\n",
    "        model = sensorResnet50TransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "        return model\n",
    "    if model_name == \"sensorResnet101TransformerSS\":\n",
    "        model = sensorResnet101TransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "        return model\n",
    "\n",
    "    if model_name == \"sensorViLTransformerSS\":\n",
    "        model = sensorViLTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1)\n",
    "        return model\n",
    "\n",
    "model = build_model(config.model_name,True)\n",
    "model.to(config.device)\n",
    "print(config.device)\n",
    "for i,m in enumerate(model.modules()):\n",
    "    print(i,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sensor = torch.rand(config.senser_input_num)\n",
    "# # sensor = torch.ones(config.senser_input_num)\n",
    "# print(sensor)\n",
    "# sensor =  torch.tensor(sensor).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 3])\n",
    "# batch = {}\n",
    "# batch['sensor'] = sensor\n",
    "# batch['image'] = \"/home/junsheng/data/xiangguan/pic/xiangguanD4-2021-05-24-10-00-25.jpeg\"\n",
    "# model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.mse_loss #均方误差损失函数\n",
    "# criterion = F.mae_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (img, sensor,label) in pbar:         \n",
    "        # img = img.to(device, dtype=torch.float)\n",
    "        # sensor  = sensor.to(device, dtype=torch.float)\n",
    "        # label  = label.to(device, dtype=torch.float)\n",
    "        batch_size = img.size(0)\n",
    "        \n",
    "        batch = {\"image\":img,\"sensor\":sensor}\n",
    "\n",
    "        y_pred = model(batch)\n",
    "        label = label.to(config.device).unsqueeze(1)\n",
    "        loss = criterion(y_pred['cls_output'], label)\n",
    "        \n",
    "        #一坨优化\n",
    "        optimizer.zero_grad()#每一次反向传播之前都要归零梯度\n",
    "        loss.backward()      #反向传播\n",
    "        optimizer.step()     #固定写法\n",
    "        scheduler.step()\n",
    "     \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, optimizer):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    val_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (img, sensor,label) in pbar:               \n",
    "        \n",
    "        \n",
    "        batch_size = img.size(0)\n",
    "        batch = {\"image\":img,\"sensor\":sensor}\n",
    "\n",
    "        y_pred  = model(batch)\n",
    "        label = label.to(config.device).unsqueeze(1)\n",
    "\n",
    "        loss = criterion(y_pred['cls_output'], label)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "     # init wandb\n",
    "    run = wandb.init(project=\"vilt\",\n",
    "                    config={k: v for k, v in dict(vars(config)).items() if '__' not in k},\n",
    "                    # config={k: v for k, v in dict(config).items() if '__' not in k},\n",
    "                    anonymous=anonymous,\n",
    "                    # name=f\"vilt|fold-{config.valid_fold}\",\n",
    "                    name=config.wandb_name,\n",
    "                    # group=config.wandb_group,\n",
    "                    )\n",
    "    wandb.watch(model, log_freq=100)\n",
    "\n",
    "    best_loss = 9999\n",
    "    best_valid_loss = 9999\n",
    "    history = defaultdict(list)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=device, epoch=epoch)\n",
    "        val_loss = valid_one_epoch(model,valid_loader,device=device,optimizer=optimizer)\n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "\n",
    "        wandb.log({\"Train Loss\": train_loss,\n",
    "                    \"Valid Loss\": val_loss,\n",
    "                \"lr\": scheduler.get_last_lr()[0]\n",
    "                })\n",
    "        if best_valid_loss > val_loss:\n",
    "            best_valid_loss = val_loss\n",
    "            # model_file_path = os.path.join(wandb.run.dir,\"epoch-{}-{}.bin\".format(epoch,wandb.run.id))\n",
    "            model_file_path = os.path.join(wandb.run.dir,\"epoch-best.bin\")\n",
    "            run.summary[\"Best Epoch\"] = epoch\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            print(\"model save to\", model_file_path)\n",
    "            \n",
    "    os.system(\"cp /home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb {}\".format(wandb.run.dir))\n",
    "    run.finish()\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=config.T_max, \n",
    "                                                   eta_min=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8hmf14eh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▆▆▃▄▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Valid Loss</td><td>█▆▆▅▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>████▇▇▇▆▆▅▅▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Epoch</td><td>26</td></tr><tr><td>Train Loss</td><td>0.01645</td></tr><tr><td>Valid Loss</td><td>0.01765</td></tr><tr><td>lr</td><td>4e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/junsheng/ViLT/wandb/offline-run-20221102_160705-8hmf14eh<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221102_160705-8hmf14eh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8hmf14eh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: NVIDIA GeForce RTX 3090\n",
      "\n",
      "Epoch 1/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/67 [00:00<?, ?it/s]/tmp/ipykernel_389858/355586058.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n",
      "/home/junsheng/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Train : 100%|██████████| 67/67 [02:34<00:00,  2.30s/it, gpu_mem=7.07 GB, lr=0.00100, train_loss=0.2876]\n",
      "Valid : 100%|██████████| 133/133 [00:38<00:00,  3.42it/s, gpu_memory=3.35 GB, lr=0.00100, valid_loss=0.2937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 2/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:32<00:00,  2.27s/it, gpu_mem=7.02 GB, lr=0.00098, train_loss=0.2933]\n",
      "Valid : 100%|██████████| 133/133 [00:38<00:00,  3.41it/s, gpu_memory=3.34 GB, lr=0.00098, valid_loss=0.2937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 3/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:32<00:00,  2.27s/it, gpu_mem=7.02 GB, lr=0.00096, train_loss=0.2933]\n",
      "Valid : 100%|██████████| 133/133 [00:39<00:00,  3.34it/s, gpu_memory=3.34 GB, lr=0.00096, valid_loss=0.2937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 4/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:33<00:00,  2.29s/it, gpu_mem=7.02 GB, lr=0.00093, train_loss=0.2933]\n",
      "Valid : 100%|██████████| 133/133 [00:39<00:00,  3.35it/s, gpu_memory=3.34 GB, lr=0.00093, valid_loss=0.2936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 5/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:31<00:00,  2.27s/it, gpu_mem=7.02 GB, lr=0.00089, train_loss=0.2059]\n",
      "Valid : 100%|██████████| 133/133 [00:39<00:00,  3.35it/s, gpu_memory=3.34 GB, lr=0.00089, valid_loss=0.0785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 6/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:34<00:00,  2.30s/it, gpu_mem=7.02 GB, lr=0.00085, train_loss=0.0812]\n",
      "Valid : 100%|██████████| 133/133 [00:38<00:00,  3.48it/s, gpu_memory=3.34 GB, lr=0.00085, valid_loss=0.0779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 7/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:32<00:00,  2.27s/it, gpu_mem=7.02 GB, lr=0.00080, train_loss=0.0806]\n",
      "Valid : 100%|██████████| 133/133 [00:39<00:00,  3.34it/s, gpu_memory=3.34 GB, lr=0.00080, valid_loss=0.0838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:30<00:00,  2.25s/it, gpu_mem=7.02 GB, lr=0.00074, train_loss=0.0811]\n",
      "Valid : 100%|██████████| 133/133 [00:40<00:00,  3.32it/s, gpu_memory=3.34 GB, lr=0.00074, valid_loss=0.0778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 9/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:32<00:00,  2.28s/it, gpu_mem=7.02 GB, lr=0.00068, train_loss=0.0804]\n",
      "Valid : 100%|██████████| 133/133 [00:38<00:00,  3.45it/s, gpu_memory=3.34 GB, lr=0.00068, valid_loss=0.0780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:33<00:00,  2.29s/it, gpu_mem=7.02 GB, lr=0.00061, train_loss=0.0795]\n",
      "Valid : 100%|██████████| 133/133 [00:40<00:00,  3.32it/s, gpu_memory=3.34 GB, lr=0.00061, valid_loss=0.0815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:33<00:00,  2.28s/it, gpu_mem=7.02 GB, lr=0.00055, train_loss=0.0796]\n",
      "Valid : 100%|██████████| 133/133 [00:39<00:00,  3.38it/s, gpu_memory=3.34 GB, lr=0.00055, valid_loss=0.0817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:32<00:00,  2.28s/it, gpu_mem=7.02 GB, lr=0.00048, train_loss=0.0790]\n",
      "Valid : 100%|██████████| 133/133 [00:38<00:00,  3.43it/s, gpu_memory=3.34 GB, lr=0.00048, valid_loss=0.0849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:31<00:00,  2.27s/it, gpu_mem=7.02 GB, lr=0.00042, train_loss=0.0788]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.56it/s, gpu_memory=3.34 GB, lr=0.00042, valid_loss=0.0775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 14/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:24<00:00,  2.16s/it, gpu_mem=7.02 GB, lr=0.00035, train_loss=0.0790]\n",
      "Valid : 100%|██████████| 133/133 [00:36<00:00,  3.68it/s, gpu_memory=3.34 GB, lr=0.00035, valid_loss=0.0781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:22<00:00,  2.13s/it, gpu_mem=7.02 GB, lr=0.00029, train_loss=0.0782]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.56it/s, gpu_memory=3.34 GB, lr=0.00029, valid_loss=0.0802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:24<00:00,  2.15s/it, gpu_mem=7.02 GB, lr=0.00023, train_loss=0.0788]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.58it/s, gpu_memory=3.34 GB, lr=0.00023, valid_loss=0.0761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 17/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:25<00:00,  2.18s/it, gpu_mem=7.02 GB, lr=0.00018, train_loss=0.0678]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.54it/s, gpu_memory=3.34 GB, lr=0.00018, valid_loss=0.0520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 18/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:25<00:00,  2.17s/it, gpu_mem=7.02 GB, lr=0.00013, train_loss=0.0343]\n",
      "Valid : 100%|██████████| 133/133 [00:36<00:00,  3.64it/s, gpu_memory=3.34 GB, lr=0.00013, valid_loss=0.0260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 19/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:25<00:00,  2.17s/it, gpu_mem=7.02 GB, lr=0.00009, train_loss=0.0249]\n",
      "Valid : 100%|██████████| 133/133 [00:36<00:00,  3.65it/s, gpu_memory=3.34 GB, lr=0.00009, valid_loss=0.0212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 20/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:21<00:00,  2.11s/it, gpu_mem=7.02 GB, lr=0.00006, train_loss=0.0182]\n",
      "Valid : 100%|██████████| 133/133 [00:34<00:00,  3.87it/s, gpu_memory=3.34 GB, lr=0.00006, valid_loss=0.0170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 21/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:20<00:00,  2.09s/it, gpu_mem=7.02 GB, lr=0.00003, train_loss=0.0151]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.58it/s, gpu_memory=3.34 GB, lr=0.00003, valid_loss=0.0136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 22/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:26<00:00,  2.18s/it, gpu_mem=7.02 GB, lr=0.00002, train_loss=0.0144]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.52it/s, gpu_memory=3.34 GB, lr=0.00002, valid_loss=0.0135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 23/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:25<00:00,  2.17s/it, gpu_mem=7.02 GB, lr=0.00001, train_loss=0.0142]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.58it/s, gpu_memory=3.34 GB, lr=0.00001, valid_loss=0.0134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 24/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:25<00:00,  2.16s/it, gpu_mem=7.02 GB, lr=0.00001, train_loss=0.0139]\n",
      "Valid : 100%|██████████| 133/133 [00:36<00:00,  3.63it/s, gpu_memory=3.34 GB, lr=0.00001, valid_loss=0.0130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 25/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:24<00:00,  2.16s/it, gpu_mem=7.02 GB, lr=0.00002, train_loss=0.0140]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.54it/s, gpu_memory=3.34 GB, lr=0.00002, valid_loss=0.0135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:26<00:00,  2.18s/it, gpu_mem=7.02 GB, lr=0.00004, train_loss=0.0142]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.57it/s, gpu_memory=3.34 GB, lr=0.00004, valid_loss=0.0169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:24<00:00,  2.16s/it, gpu_mem=7.02 GB, lr=0.00007, train_loss=0.0142]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.55it/s, gpu_memory=3.34 GB, lr=0.00007, valid_loss=0.0262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:25<00:00,  2.17s/it, gpu_mem=7.02 GB, lr=0.00011, train_loss=0.0144]\n",
      "Valid : 100%|██████████| 133/133 [00:36<00:00,  3.65it/s, gpu_memory=3.34 GB, lr=0.00011, valid_loss=0.0124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 29/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:24<00:00,  2.16s/it, gpu_mem=7.02 GB, lr=0.00015, train_loss=0.0135]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.57it/s, gpu_memory=3.34 GB, lr=0.00015, valid_loss=0.0109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 30/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:25<00:00,  2.17s/it, gpu_mem=7.02 GB, lr=0.00020, train_loss=0.0188]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.54it/s, gpu_memory=3.34 GB, lr=0.00020, valid_loss=0.0121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:26<00:00,  2.18s/it, gpu_mem=7.02 GB, lr=0.00025, train_loss=0.0115]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.53it/s, gpu_memory=3.34 GB, lr=0.00025, valid_loss=0.0072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 32/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:25<00:00,  2.18s/it, gpu_mem=7.02 GB, lr=0.00031, train_loss=0.0081]\n",
      "Valid : 100%|██████████| 133/133 [00:36<00:00,  3.64it/s, gpu_memory=3.34 GB, lr=0.00031, valid_loss=0.0122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:24<00:00,  2.15s/it, gpu_mem=7.02 GB, lr=0.00037, train_loss=0.0056]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.58it/s, gpu_memory=3.34 GB, lr=0.00037, valid_loss=0.0066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 34/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:23<00:00,  2.15s/it, gpu_mem=7.02 GB, lr=0.00044, train_loss=0.0093]\n",
      "Valid : 100%|██████████| 133/133 [00:37<00:00,  3.58it/s, gpu_memory=3.34 GB, lr=0.00044, valid_loss=0.0054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 35/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:24<00:00,  2.16s/it, gpu_mem=7.02 GB, lr=0.00051, train_loss=0.0051]\n",
      "Valid : 100%|██████████| 133/133 [00:36<00:00,  3.63it/s, gpu_memory=3.34 GB, lr=0.00051, valid_loss=0.0065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:15<00:00,  2.02s/it, gpu_mem=7.02 GB, lr=0.00057, train_loss=0.0088]\n",
      "Valid : 100%|██████████| 133/133 [00:34<00:00,  3.82it/s, gpu_memory=3.34 GB, lr=0.00057, valid_loss=0.0077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:17<00:00,  2.05s/it, gpu_mem=7.02 GB, lr=0.00064, train_loss=0.0038]\n",
      "Valid : 100%|██████████| 133/133 [00:33<00:00,  3.94it/s, gpu_memory=3.34 GB, lr=0.00064, valid_loss=0.0073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:16<00:00,  2.04s/it, gpu_mem=7.02 GB, lr=0.00070, train_loss=0.0101]\n",
      "Valid : 100%|██████████| 133/133 [00:33<00:00,  3.94it/s, gpu_memory=3.34 GB, lr=0.00070, valid_loss=0.0052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 39/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:15<00:00,  2.02s/it, gpu_mem=7.02 GB, lr=0.00076, train_loss=0.0044]\n",
      "Valid : 100%|██████████| 133/133 [00:33<00:00,  3.96it/s, gpu_memory=3.34 GB, lr=0.00076, valid_loss=0.0029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 40/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:15<00:00,  2.03s/it, gpu_mem=7.02 GB, lr=0.00081, train_loss=0.0051]\n",
      "Valid : 100%|██████████| 133/133 [00:33<00:00,  3.97it/s, gpu_memory=3.34 GB, lr=0.00081, valid_loss=0.0069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:15<00:00,  2.03s/it, gpu_mem=7.02 GB, lr=0.00086, train_loss=0.0150]\n",
      "Valid : 100%|██████████| 133/133 [00:33<00:00,  3.98it/s, gpu_memory=3.34 GB, lr=0.00086, valid_loss=0.0102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:15<00:00,  2.02s/it, gpu_mem=7.02 GB, lr=0.00091, train_loss=0.0063]\n",
      "Valid : 100%|██████████| 133/133 [00:34<00:00,  3.89it/s, gpu_memory=3.34 GB, lr=0.00091, valid_loss=0.0047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:14<00:00,  2.00s/it, gpu_mem=7.02 GB, lr=0.00094, train_loss=0.0043]\n",
      "Valid : 100%|██████████| 133/133 [00:34<00:00,  3.89it/s, gpu_memory=3.34 GB, lr=0.00094, valid_loss=0.0032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:16<00:00,  2.03s/it, gpu_mem=7.02 GB, lr=0.00097, train_loss=0.0036]\n",
      "Valid : 100%|██████████| 133/133 [00:34<00:00,  3.85it/s, gpu_memory=3.34 GB, lr=0.00097, valid_loss=0.0058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:12<00:00,  1.97s/it, gpu_mem=7.02 GB, lr=0.00099, train_loss=0.0047]\n",
      "Valid : 100%|██████████| 133/133 [00:33<00:00,  3.97it/s, gpu_memory=3.34 GB, lr=0.00099, valid_loss=0.0050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:15<00:00,  2.02s/it, gpu_mem=7.02 GB, lr=0.00100, train_loss=0.0057]\n",
      "Valid : 100%|██████████| 133/133 [00:34<00:00,  3.90it/s, gpu_memory=3.34 GB, lr=0.00100, valid_loss=0.0039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:16<00:00,  2.03s/it, gpu_mem=7.02 GB, lr=0.00100, train_loss=0.0051]\n",
      "Valid : 100%|██████████| 133/133 [00:33<00:00,  4.02it/s, gpu_memory=3.34 GB, lr=0.00100, valid_loss=0.0088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:16<00:00,  2.04s/it, gpu_mem=7.02 GB, lr=0.00099, train_loss=0.0055]\n",
      "Valid : 100%|██████████| 133/133 [00:33<00:00,  3.94it/s, gpu_memory=3.34 GB, lr=0.00099, valid_loss=0.0049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:13<00:00,  2.00s/it, gpu_mem=7.02 GB, lr=0.00098, train_loss=0.0043]\n",
      "Valid : 100%|██████████| 133/133 [00:33<00:00,  3.94it/s, gpu_memory=3.34 GB, lr=0.00098, valid_loss=0.0023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save to /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd/files/epoch-best.bin\n",
      "Epoch 50/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 67/67 [02:17<00:00,  2.05s/it, gpu_mem=7.02 GB, lr=0.00095, train_loss=0.0033]\n",
      "Valid : 100%|██████████| 133/133 [00:33<00:00,  3.98it/s, gpu_memory=3.34 GB, lr=0.00095, valid_loss=0.0028]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>████▃▃▃▃▃▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Valid Loss</td><td>████▃▃▃▃▃▃▃▃▃▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>████▇▇▆▆▅▄▄▃▃▂▂▂▁▁▁▁▁▁▂▂▃▃▄▄▅▅▆▆▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Epoch</td><td>49</td></tr><tr><td>Train Loss</td><td>0.00325</td></tr><tr><td>Valid Loss</td><td>0.00279</td></tr><tr><td>lr</td><td>0.00095</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/junsheng/ViLT/wandb/offline-run-20221102_172029-dlghdwkd<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221102_172029-dlghdwkd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model, history = run_training(model, optimizer, scheduler,device=config.device,num_epochs=config.max_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 384, 384]) torch.Size([4, 1, 19]) tensor([0., 0., 0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_389858/355586058.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n"
     ]
    }
   ],
   "source": [
    "for (img,sensor,label) in valid_loader:\n",
    "    print(img.shape,sensor.shape,label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'embedding_test_dict.pt')\n",
    "# print(model)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"/home/junsheng/ViLT/wandb/offline-run-20220811_120519-nzfb1xoz/files/epoch-best.bin\"))\n",
    "model.eval()\n",
    "device = config.device\n",
    "model.to(device)\n",
    "def infer(img_filename, sensor):\n",
    "    try:\n",
    "        img_path = os.path.join('pictures',img_filename)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        img = pixelbert_transform(size=384)(image) # 将图像数据归一化torch.Size([3, 384, 576])\n",
    "        img = torch.tensor(img)\n",
    "        img = torch.unsqueeze(img, 0) # torch.Size([1, 3, 384, 576])\n",
    "        img = img.to(device)\n",
    "        print(\"img.shape:\",img.shape)\n",
    "    except :\n",
    "        print(\"图片加载失败！\")\n",
    "        raise\n",
    "\n",
    "    batch = dict()\n",
    "    batch[\"image\"] = img\n",
    "\n",
    "    batch['sensor_masks'] = torch.ones(1,1).to(device)\n",
    "    with torch.no_grad():\n",
    "        batch['sensor'] = sensor.to(device)       \n",
    "        infer = model(batch)\n",
    "\n",
    "        print(infer)\n",
    "        sensor_emb, img_emb = infer[\"sensor_feats\"], infer[\"image_feats\"]# torch.Size([1, 23, 768]) torch.Size([1, 217, 768])\n",
    "        cls_output = infer['cls_output']\n",
    "        \n",
    "\n",
    "    return [cls_output]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2798, 0.3580, 0.3258, 0.9675, 0.3362, 0.1932, 0.6399, 0.4880, 0.2876,\n",
      "        0.2520, 0.2133, 0.5669, 0.0398, 0.7086, 0.0027, 0.2921, 0.3442, 0.8358,\n",
      "        0.7115])\n",
      "img.shape: torch.Size([1, 3, 352, 608])\n",
      "{'image_feats': tensor([[[-3.0109e+00, -8.9953e-03, -2.2351e-05,  ...,  4.6877e-02,\n",
      "          -2.8691e-03, -3.2883e-03],\n",
      "         [-1.2397e+00,  1.8484e-02, -3.1946e-02,  ..., -4.2533e-02,\n",
      "           7.0037e-03, -3.2790e-04],\n",
      "         [-1.6883e+00, -1.7783e-02,  2.9024e-03,  ...,  9.2604e-02,\n",
      "          -3.3002e-02, -7.4470e-02],\n",
      "         ...,\n",
      "         [-1.6554e+00, -1.3973e-02, -1.1536e-02,  ...,  1.7800e-02,\n",
      "           1.6437e-02,  1.9664e-02],\n",
      "         [-1.7469e+00, -1.9370e-02,  1.4804e-02,  ...,  2.5505e-02,\n",
      "          -3.4030e-02, -3.8892e-02],\n",
      "         [-2.3801e+00, -1.9123e-02,  1.1407e-02,  ...,  5.9326e-03,\n",
      "           9.1222e-03, -5.7441e-02]]], device='cuda:0'), 'cls_feats': tensor([[-9.4028e-01,  7.3397e-01,  6.6973e-01,  6.4067e-04, -4.8336e-01,\n",
      "         -8.6946e-01, -2.5885e-04, -7.5991e-01,  9.9263e-01,  2.5117e-01,\n",
      "         -6.1082e-01, -1.4695e-05,  4.8495e-03,  5.0195e-04,  5.4845e-01,\n",
      "         -4.1843e-03, -7.1915e-02,  2.0214e-04,  8.2382e-01, -2.2452e-03,\n",
      "         -4.5062e-05, -1.1496e-05, -9.7624e-01, -5.4864e-01, -5.7467e-03,\n",
      "         -5.6064e-01,  4.2476e-02,  1.1352e-08,  9.2664e-01,  9.2981e-01,\n",
      "         -1.6397e-02, -5.7589e-05, -2.5454e-04,  3.2206e-03, -2.4385e-06,\n",
      "          7.9906e-01,  6.4002e-01,  3.0797e-04, -1.0808e-03, -5.9004e-01,\n",
      "         -4.3191e-01, -5.7487e-01,  3.3328e-01,  6.8221e-03, -6.4921e-01,\n",
      "          9.8922e-01,  9.6900e-01, -3.5112e-03, -4.5073e-01, -9.5702e-01,\n",
      "         -3.2284e-04, -3.6805e-04, -1.5612e-04, -2.1355e-04, -1.2958e-03,\n",
      "         -1.2897e-03, -4.7466e-05,  2.5556e-01,  3.1241e-02,  6.7035e-01,\n",
      "          3.3714e-01,  1.2365e-06,  7.6992e-01,  3.1910e-04,  1.8830e-03,\n",
      "          9.3618e-01, -9.8736e-01,  8.9082e-02,  1.5610e-04, -1.0841e-03,\n",
      "          1.3664e-04,  7.8726e-01, -7.1546e-01,  7.2817e-01,  9.7177e-01,\n",
      "         -9.3964e-01,  2.6937e-01,  6.1860e-07, -4.8894e-01,  5.3022e-01,\n",
      "         -7.0473e-01,  3.5491e-01,  9.8293e-01, -5.1339e-01, -1.7059e-03,\n",
      "          5.3825e-02,  9.2817e-01,  6.4997e-02, -2.1389e-08, -1.4974e-03,\n",
      "          9.4608e-01,  9.9285e-01,  7.4964e-01, -4.7241e-01, -7.7959e-05,\n",
      "          3.0230e-05,  1.1993e-04, -9.2869e-01,  5.5595e-06, -9.7696e-01,\n",
      "          8.6617e-01, -9.4075e-01, -9.7245e-01,  5.1969e-01, -1.8297e-05,\n",
      "          9.5432e-01,  7.0894e-04, -1.4539e-05, -2.9680e-02,  7.9710e-01,\n",
      "         -1.1548e-06, -4.3518e-03,  7.3692e-01,  2.0416e-02, -4.0679e-07,\n",
      "          8.1619e-01, -9.8520e-01, -1.2393e-03,  1.3639e-08,  8.2540e-01,\n",
      "         -9.9550e-01,  9.3680e-05,  4.8755e-06,  1.4385e-05,  6.6885e-01,\n",
      "          4.3780e-05,  6.5003e-01,  9.7991e-02, -8.2869e-01,  2.0687e-02,\n",
      "         -8.1379e-01, -9.7779e-06,  2.7490e-01, -5.1892e-01, -9.2132e-01,\n",
      "         -4.4555e-02, -1.2965e-04, -9.6558e-01, -7.7246e-08,  5.5406e-01,\n",
      "          3.1832e-05,  6.3681e-01,  7.5263e-03, -9.5290e-01,  1.9459e-04,\n",
      "         -8.8335e-01,  6.1048e-01,  1.2822e-04,  9.2508e-03, -7.9333e-01,\n",
      "          8.2267e-01,  7.0252e-01, -1.6495e-03, -2.3794e-01, -7.3882e-06,\n",
      "          3.0554e-02, -5.8042e-04, -8.0537e-01,  1.8105e-03, -9.2734e-01,\n",
      "         -3.6030e-01,  1.0771e-05,  5.4130e-01, -7.9555e-01, -9.8420e-01,\n",
      "         -1.4669e-04,  7.8304e-01, -6.3092e-01, -6.8349e-01, -6.2287e-05,\n",
      "          8.5279e-08,  9.6277e-01,  2.3662e-06, -1.2732e-03, -8.1221e-01,\n",
      "          7.1133e-01,  2.7552e-03,  1.3299e-05, -2.2749e-04, -9.7666e-04,\n",
      "         -9.2047e-01, -3.4028e-01, -7.8675e-01, -1.4816e-02,  3.5860e-04,\n",
      "          9.5552e-01, -1.1031e-03, -3.7938e-06, -6.4817e-01,  9.6772e-01,\n",
      "          4.8179e-01, -8.4088e-01,  4.5677e-03,  9.6799e-01, -6.9065e-01,\n",
      "          3.7316e-04,  9.9748e-01,  7.3148e-01, -8.1992e-01,  3.0156e-03,\n",
      "         -9.0480e-05,  8.8108e-01,  7.6917e-01,  9.9007e-01,  9.5630e-01,\n",
      "          9.7287e-01,  5.8194e-02, -5.1548e-04, -2.2101e-06, -8.8100e-01,\n",
      "          2.0253e-01, -1.5385e-01, -4.8435e-01,  7.3884e-01, -7.3225e-01,\n",
      "          9.0784e-01, -9.1882e-01,  4.0458e-03,  9.8282e-01, -9.8196e-01,\n",
      "          2.2980e-06, -8.1899e-01,  7.3201e-01, -6.2684e-01, -9.8246e-01,\n",
      "         -2.5831e-02, -9.1541e-05, -7.2345e-01,  9.6678e-01, -4.7065e-01,\n",
      "         -7.6160e-05, -5.3946e-01, -1.0406e-04,  9.0681e-01,  9.9794e-05,\n",
      "          2.3491e-01, -7.7433e-01,  9.4331e-03,  2.6062e-05,  4.1039e-01,\n",
      "         -7.5002e-07, -5.8101e-04, -7.3807e-01,  1.4231e-03, -1.5273e-05,\n",
      "         -6.8893e-01,  9.4612e-01,  1.7819e-05,  3.7150e-04, -9.5383e-01,\n",
      "          1.5706e-04,  4.4372e-02, -6.1883e-01,  7.4925e-01,  1.9172e-05,\n",
      "          6.5359e-01,  5.8735e-06, -2.4698e-01, -7.7445e-01,  1.5435e-06,\n",
      "          6.4194e-06, -2.3236e-02, -4.1767e-01, -8.1464e-01,  9.8218e-01,\n",
      "          3.4489e-02,  3.7274e-03, -3.9714e-01, -2.7867e-06,  8.3137e-06,\n",
      "         -5.3923e-01, -9.7786e-01, -9.1515e-01, -8.0248e-01, -2.1320e-05,\n",
      "         -6.8173e-01,  6.8685e-01, -9.4362e-01,  6.3763e-01, -4.5449e-01,\n",
      "         -4.1207e-04, -8.4664e-02,  1.4563e-05,  5.5818e-01, -2.6677e-04,\n",
      "          9.4587e-05,  3.9663e-06,  9.7346e-03,  8.2423e-02,  9.5295e-01,\n",
      "          9.6680e-01, -2.2340e-02,  1.9715e-01, -9.5638e-01,  1.6198e-04,\n",
      "          5.1163e-05,  3.3228e-04,  7.8873e-01, -9.5695e-01, -5.4355e-04,\n",
      "         -5.5694e-03, -1.0469e-04, -8.5217e-05,  1.2664e-01,  1.5490e-02,\n",
      "          2.7731e-04, -9.0393e-01,  1.1974e-02,  7.4552e-05, -3.8089e-04,\n",
      "          2.0038e-03,  9.5730e-05, -8.2030e-01,  8.0864e-01,  3.1055e-02,\n",
      "          2.7683e-01, -9.9218e-01, -7.8599e-04, -8.8267e-01, -9.5040e-02,\n",
      "          6.6863e-03,  7.4513e-01,  9.7433e-01, -3.6394e-01, -6.6726e-01,\n",
      "         -5.5072e-01,  9.9526e-01,  8.2520e-01,  9.7980e-01,  1.0255e-04,\n",
      "         -4.4834e-04, -6.6313e-01,  9.1207e-03,  7.0842e-06,  7.5865e-04,\n",
      "         -1.4443e-03,  9.5891e-01,  7.5257e-04,  6.4959e-01,  4.6206e-04,\n",
      "          3.6615e-03,  2.2089e-05,  2.2646e-02, -3.8926e-04, -4.9038e-04,\n",
      "          3.8705e-01, -1.2485e-03, -3.1508e-04,  3.5292e-01,  8.1677e-05,\n",
      "          8.4399e-04, -3.4441e-01, -9.6275e-01,  1.4973e-04, -9.7222e-01,\n",
      "         -9.5791e-04,  4.8511e-01, -6.6014e-01,  7.4985e-01, -6.8622e-01,\n",
      "         -5.4150e-05,  7.3211e-01,  7.0975e-01, -1.4171e-04, -9.2817e-01,\n",
      "         -9.2801e-01,  2.7162e-02, -7.1067e-01,  1.9914e-04,  2.5354e-01,\n",
      "          4.0138e-01,  9.5722e-01, -2.7013e-01,  8.2653e-05, -3.4106e-04,\n",
      "         -2.0401e-01, -4.6788e-05,  9.8112e-01,  7.5023e-01, -3.5753e-04,\n",
      "          7.5081e-01,  9.1084e-01, -9.1941e-01, -7.0773e-01, -9.7563e-01,\n",
      "          7.7851e-01, -2.0995e-04, -5.4735e-01, -7.2832e-01,  9.6413e-01,\n",
      "         -1.1652e-02,  3.4063e-06,  4.1716e-05,  7.0217e-07,  3.6616e-02,\n",
      "         -6.2348e-09,  1.0315e-02, -1.2621e-05, -7.8973e-01,  6.7176e-07,\n",
      "          5.9166e-05, -6.7730e-04, -6.9656e-01, -2.4379e-04, -7.9662e-01,\n",
      "          5.4473e-05,  7.8903e-01, -2.6781e-04, -6.2203e-05,  2.0626e-01,\n",
      "          7.6477e-01,  7.0033e-03, -3.9287e-04, -2.0658e-04, -5.9221e-05,\n",
      "         -5.3384e-06, -5.9584e-02, -9.7684e-01,  5.8753e-01, -3.3951e-06,\n",
      "         -9.6957e-01, -2.4236e-03,  9.3913e-01, -1.4023e-01,  7.2839e-01,\n",
      "         -9.8575e-01, -9.6939e-01,  2.2100e-05, -9.0396e-01,  3.8181e-04,\n",
      "         -7.6033e-01,  2.5858e-05, -5.5915e-01, -4.2745e-02, -3.2858e-04,\n",
      "         -8.4416e-01,  8.4355e-02, -5.6790e-01,  7.5477e-01,  9.6012e-01,\n",
      "          9.2724e-01, -2.6307e-04, -8.4177e-01,  4.0373e-04, -9.6043e-04,\n",
      "          6.5702e-01, -8.0054e-01,  1.3471e-03,  6.4443e-03, -3.6556e-06,\n",
      "         -8.0112e-01,  1.3254e-01, -8.4722e-05,  9.7039e-01, -6.9838e-01,\n",
      "          1.0733e-01,  1.3547e-03, -3.0132e-04,  4.8966e-06, -9.0936e-01,\n",
      "          3.6608e-04,  1.3682e-04,  9.7603e-01, -1.4694e-02,  6.6745e-01,\n",
      "         -3.9772e-04, -7.8830e-01, -7.0239e-02, -6.3270e-04,  1.1532e-02,\n",
      "          1.3849e-04,  3.6269e-01, -1.0925e-03, -8.0403e-05, -2.2983e-01,\n",
      "          1.9133e-04, -5.3437e-02,  4.9370e-05, -5.7206e-01,  6.4578e-03,\n",
      "         -3.3336e-05,  8.2086e-05, -1.7067e-04,  7.9037e-01, -3.7590e-04,\n",
      "          3.0703e-05,  3.4611e-01, -1.0352e-02, -5.4964e-04, -9.2937e-01,\n",
      "         -9.0472e-01,  1.7672e-03, -1.7239e-04, -3.4855e-01, -1.0177e-05,\n",
      "          9.8388e-02,  1.5511e-02,  2.0679e-05, -4.8777e-04,  9.8958e-01,\n",
      "          9.8564e-01,  7.3928e-01, -6.7643e-01,  4.6759e-01, -5.5323e-01,\n",
      "          8.9643e-01, -5.7426e-04, -9.8433e-01,  1.1846e-05, -1.5612e-06,\n",
      "          3.2826e-04,  6.7265e-04,  3.3014e-03, -1.8969e-05, -9.2084e-01,\n",
      "          9.9516e-01, -6.4202e-04,  8.7654e-09, -1.3531e-02,  2.3315e-06,\n",
      "          6.3955e-01,  6.9861e-01,  9.7259e-01, -2.2654e-06, -2.6800e-03,\n",
      "         -4.3657e-05, -9.6159e-01,  2.0720e-08,  6.7035e-01,  7.6490e-01,\n",
      "         -8.2907e-01, -6.8139e-01,  9.4351e-01,  3.3684e-06, -1.2992e-05,\n",
      "         -9.4636e-04, -1.0113e-04, -7.5867e-01, -8.9044e-01,  6.8896e-01,\n",
      "         -9.7957e-01,  1.6393e-01, -1.8138e-01,  7.7681e-01,  5.6579e-05,\n",
      "         -1.7885e-05, -2.0360e-02,  9.8079e-01, -5.1463e-05, -4.9951e-01,\n",
      "          1.2103e-01, -2.3953e-06, -9.3070e-01,  8.4356e-01,  8.7658e-01,\n",
      "          3.4003e-05,  6.9458e-01, -9.1744e-01,  2.1022e-01,  7.6144e-01,\n",
      "          1.4439e-03,  1.4879e-03,  1.3611e-04,  5.9068e-04, -8.4586e-07,\n",
      "         -2.2029e-05, -7.7121e-01, -6.0082e-03,  8.0931e-01,  1.5536e-05,\n",
      "         -7.6252e-01, -1.1149e-04,  5.3758e-01,  3.8098e-05, -7.5009e-01,\n",
      "          1.6939e-06, -8.0134e-01,  4.3734e-02,  3.5199e-04,  7.4828e-01,\n",
      "          1.1907e-05, -1.0850e-03,  1.6146e-02,  9.9661e-01, -9.8475e-01,\n",
      "          7.7253e-01,  9.7862e-01,  9.9549e-01,  1.5101e-01, -5.6592e-04,\n",
      "         -9.6977e-03,  8.0883e-01,  9.1784e-05, -9.4251e-04,  3.8736e-06,\n",
      "          1.7666e-03, -9.7044e-01,  9.2644e-01,  7.0187e-01, -1.7954e-04,\n",
      "         -5.5661e-05,  3.9966e-02, -1.6989e-01, -6.6684e-09,  1.3881e-04,\n",
      "         -7.3771e-01, -7.4109e-05, -6.3312e-06,  8.1508e-01, -7.1693e-01,\n",
      "          6.6022e-01, -3.1538e-05, -9.9486e-01,  2.3850e-04, -7.5254e-01,\n",
      "          1.6988e-05, -9.4420e-01,  2.1519e-03, -7.1494e-03, -8.9732e-01,\n",
      "         -2.3748e-05,  8.2768e-04, -7.8198e-04, -5.7955e-01, -9.9212e-01,\n",
      "         -6.9152e-01,  1.4089e-05,  9.8891e-01,  1.7776e-02, -3.8406e-03,\n",
      "         -9.6604e-01, -5.2832e-04,  1.3994e-03,  6.2412e-01,  8.8506e-01,\n",
      "         -1.1928e-04,  4.0410e-05, -1.8016e-03, -1.1646e-05,  1.2773e-04,\n",
      "          4.2167e-01,  9.4080e-01,  2.0597e-05, -7.4587e-01,  4.0608e-04,\n",
      "         -9.6972e-01,  9.0101e-02, -8.2679e-01, -6.8286e-03, -9.7855e-01,\n",
      "          4.7422e-01, -6.9470e-01, -9.6731e-01, -2.7600e-05, -4.5050e-02,\n",
      "          9.3673e-01,  9.8242e-01,  7.7601e-05, -1.3466e-01, -9.7993e-01,\n",
      "          5.7788e-02, -5.5604e-01,  9.5573e-01, -1.2469e-01,  1.5967e-04,\n",
      "         -7.2069e-05,  7.4703e-01,  2.2228e-03, -7.7898e-01, -5.9103e-01,\n",
      "          9.7456e-01, -1.1787e-02, -9.6877e-01,  4.2858e-01,  8.1674e-01,\n",
      "         -7.2661e-01, -5.6280e-05,  6.8194e-01,  5.1082e-01,  6.9211e-01,\n",
      "          9.6290e-01,  7.7474e-01,  9.5821e-01,  1.0349e-06, -1.4359e-04,\n",
      "         -7.8047e-01, -8.1184e-05, -3.6115e-04, -8.1840e-03,  7.4909e-07,\n",
      "         -8.6940e-05, -6.8662e-01, -8.6074e-02,  7.6073e-01, -1.5116e-06,\n",
      "         -1.4550e-05, -7.3040e-01,  7.4608e-01,  8.1185e-01,  5.0770e-02,\n",
      "         -5.0688e-03, -8.5019e-04,  2.1553e-02,  7.7819e-01,  3.9907e-01,\n",
      "         -8.6675e-01,  9.7729e-01, -1.1066e-04, -5.0724e-04,  8.4976e-01,\n",
      "         -7.8324e-01,  8.8470e-01,  6.7362e-01,  9.9578e-04,  5.4447e-03,\n",
      "         -8.3872e-01,  6.6559e-02,  7.8752e-01, -7.4608e-01, -9.4938e-01,\n",
      "          3.0926e-06,  7.9679e-05,  2.8195e-04, -6.6665e-01, -5.9851e-01,\n",
      "          9.6855e-01, -9.5340e-01, -5.3880e-01, -3.0911e-04,  4.7133e-01,\n",
      "         -7.6544e-03,  2.9059e-06, -9.2713e-01,  5.7540e-01, -7.9185e-01,\n",
      "          1.3759e-04,  3.2486e-01,  1.8061e-03, -3.4310e-01, -1.1083e-05,\n",
      "         -2.7960e-04,  8.2740e-01, -1.1491e-02,  7.4928e-01, -1.9223e-03,\n",
      "          9.9555e-01, -8.5197e-02,  1.9422e-01, -4.7302e-03,  8.1581e-01,\n",
      "          1.9725e-03, -1.0175e-03, -5.8348e-04,  3.1840e-03, -7.6491e-04,\n",
      "          1.4826e-03, -7.1275e-01,  1.2445e-04, -1.7655e-01,  5.4605e-01,\n",
      "         -4.2728e-07,  1.7653e-05,  7.6342e-02, -3.2378e-03, -4.1011e-01,\n",
      "          7.2950e-01,  8.0809e-05,  4.8509e-03]], device='cuda:0'), 'raw_cls_feats': tensor([[-3.0109e+00, -8.9953e-03, -2.2351e-05, -1.1450e-02,  1.7442e-02,\n",
      "         -1.3375e-02,  1.7006e-01,  2.1830e-02, -4.6638e-03,  9.1832e-03,\n",
      "          3.4021e-04, -9.9972e-01, -2.6788e-04,  1.5159e+00,  8.8057e-03,\n",
      "         -1.6768e-04,  1.6825e-01,  8.2084e-02, -5.2070e-03,  1.4334e-02,\n",
      "         -1.3003e-02, -2.2540e-03, -8.3637e-04,  1.3267e-03,  1.8024e-01,\n",
      "          3.7079e-03, -4.2218e-01,  7.3853e-02,  4.8463e-03, -3.6079e-01,\n",
      "          1.6498e-03,  6.6759e-03,  1.5752e-01,  4.7754e-04,  4.2652e-03,\n",
      "         -2.7858e-04, -5.2703e-02, -4.6805e-01, -1.2118e-03, -7.9779e-04,\n",
      "          1.3571e-02, -3.5654e-03, -1.6005e-02,  1.2206e-03, -1.1747e-03,\n",
      "          1.2590e-02, -3.2586e-03, -1.6766e-04,  1.5050e+00,  1.2331e-02,\n",
      "          3.3995e-02, -5.8004e-02,  1.3539e-02, -4.0053e-01,  2.2011e-01,\n",
      "         -1.4664e-01,  1.0882e-03,  1.5737e-03, -1.0446e-03,  8.0135e-02,\n",
      "          3.2917e+00, -2.7886e-05, -2.4455e-03,  8.2408e-02,  1.1276e-01,\n",
      "          1.5057e-03, -4.3500e-03, -2.3755e-03, -1.7226e+00,  1.2582e-01,\n",
      "          2.3394e-03, -5.4569e-03,  7.3986e-05,  2.6633e-01, -2.3075e-01,\n",
      "          4.6003e-03,  1.1735e-03, -6.8097e-03, -1.0645e-01,  8.6231e-04,\n",
      "         -1.5714e-03,  4.4001e-02, -2.0541e-02,  2.1275e-03, -1.9836e+00,\n",
      "          9.0597e-04,  5.1301e-04,  7.0973e-03,  7.6132e-04,  2.1823e-04,\n",
      "          1.5172e-03, -5.2191e-02,  3.5308e-02,  4.3450e-03, -2.3879e-03,\n",
      "          7.3907e-02, -2.0179e-04,  1.6715e-03, -1.1293e+00, -4.9131e-03,\n",
      "         -4.6745e-03, -1.5016e-03,  5.9710e-02,  1.0971e-01, -4.5588e-04,\n",
      "         -4.3151e-03, -1.5685e+00,  5.7405e-02,  2.7721e+00, -8.9761e-05,\n",
      "          1.1022e-03,  1.0136e+00, -1.7432e-02, -1.9908e-01, -6.1203e-03,\n",
      "         -3.2452e-02,  4.4381e-04,  8.1242e-03,  3.2210e-03,  1.9793e-02,\n",
      "         -7.0614e-04,  1.0873e-04,  5.5867e-03,  6.5368e-01,  2.4404e-03,\n",
      "         -1.6664e-01,  2.0060e-04,  3.8241e-03, -1.4373e-03,  3.9833e-02,\n",
      "         -3.5981e-03, -2.7545e-03, -2.1694e-03,  1.2867e-02,  4.4100e-03,\n",
      "         -2.2297e-03, -8.0208e-04,  3.3737e+00, -2.5951e-03,  1.3670e-03,\n",
      "          9.6551e-02, -7.0511e-03,  1.3848e-01,  6.6705e-03,  6.5061e-04,\n",
      "          1.7787e-02, -1.5340e-01, -6.1371e+00,  1.6068e-02,  4.3451e-02,\n",
      "         -3.1946e-01,  9.7845e-04,  8.7607e-04, -3.6942e-01, -5.6860e-02,\n",
      "         -3.3728e-03,  6.1758e-02,  1.2593e-02,  4.2923e-01,  1.0896e-03,\n",
      "         -3.7351e-02, -1.7150e-06, -7.5885e-03, -3.1066e-03,  1.2498e-03,\n",
      "         -1.0476e-01, -3.8313e-02,  7.0855e-03, -1.0659e-01,  2.6528e-04,\n",
      "          1.4602e-01,  1.6658e-01,  1.0437e+00,  3.0464e-03, -1.4319e-03,\n",
      "         -3.4028e+00,  1.1532e-02, -4.2345e-03, -2.5126e-02,  5.0487e-02,\n",
      "         -3.1702e-04,  1.9771e-01,  1.9210e-03,  4.7998e-03,  1.7285e-02,\n",
      "          2.3742e-03, -3.7216e-02, -2.4242e-03,  4.7727e-02, -1.3025e-03,\n",
      "          2.6489e+00, -2.1808e-02,  6.8973e-02, -1.8827e-01, -1.4756e-01,\n",
      "         -1.2037e-02,  3.1828e-02, -3.2029e-02,  2.9317e-03,  4.1851e-02,\n",
      "          1.2137e-02, -1.5516e-03,  2.3239e-03, -6.9039e-04,  7.0504e-01,\n",
      "         -1.5382e-05, -9.3177e-03,  5.1598e-02, -1.7463e-02,  1.4088e-03,\n",
      "         -2.0046e-03,  3.0760e-03,  4.4703e-02,  7.9513e-03, -1.3620e-02,\n",
      "         -3.1028e-02, -2.6729e-02,  1.6368e-03, -2.2728e-03, -3.0712e-02,\n",
      "         -2.8875e-04, -2.5598e-03, -1.5270e-03,  5.2332e-02, -7.0361e-02,\n",
      "         -1.5720e-03,  3.8659e-02, -3.0554e-02,  5.6636e-04,  1.7310e-01,\n",
      "         -9.1705e-03, -5.7927e-03,  2.3654e-02,  2.4745e-03,  9.0386e-02,\n",
      "         -4.9442e-05, -1.7761e-04,  4.2664e-02,  4.0612e-03,  1.2882e-04,\n",
      "          2.2145e-02,  2.1935e-02,  2.5801e-01, -2.9681e-03, -2.0162e-03,\n",
      "          2.0145e-03, -5.2661e-03,  1.1714e-03, -9.9247e-03,  5.0535e-04,\n",
      "         -1.4360e-01,  4.1827e-03, -6.3747e-02,  5.4171e-03, -7.9031e-04,\n",
      "          5.8392e-01, -2.7796e-03,  2.9129e-03,  1.0877e-03, -3.2851e-02,\n",
      "          8.7012e-02,  2.9639e-04, -8.3625e-04, -9.0658e-04, -3.1434e-01,\n",
      "          4.8793e-01, -5.2567e-01, -5.2259e-02,  1.5269e-02, -4.7323e-04,\n",
      "          5.3477e-03,  2.4360e-02,  1.0119e-01,  5.9819e-04,  2.7478e-03,\n",
      "          4.8186e-03,  3.6549e-02, -2.8628e-03,  1.1317e-01, -3.8340e-03,\n",
      "         -2.4399e-02,  2.2925e-03,  4.9010e-01,  1.9861e-01,  3.9185e-01,\n",
      "          1.3942e-03,  1.6635e+00,  2.0715e-02, -1.0363e-04, -1.2284e-01,\n",
      "         -6.5254e-02, -8.4126e-03,  1.1570e-04, -3.6496e-01, -7.7903e-01,\n",
      "         -1.9582e+00,  4.6566e-02,  3.7214e-02,  9.9047e-03,  5.1057e-06,\n",
      "         -1.0263e-02,  6.3429e-02,  2.0565e-02, -4.0325e-02,  2.0419e-03,\n",
      "         -1.1167e-02,  1.7386e-03,  1.0800e-03,  3.5123e-03, -6.5098e-03,\n",
      "          2.5205e+00, -1.0787e-02, -5.2318e-03,  3.8639e-04,  1.1261e+00,\n",
      "         -8.5306e-03, -1.9158e-03, -2.7415e-03,  1.5324e-04, -5.3301e-03,\n",
      "          3.2673e-01, -2.9780e-03, -1.5666e-03,  8.1651e-02,  2.0135e-03,\n",
      "         -1.2715e-02,  1.1050e+00, -2.5392e-01, -3.1885e-04,  1.6313e-03,\n",
      "          5.0613e-03, -3.0815e-04,  1.3593e-03,  1.6716e-02, -4.1342e-02,\n",
      "         -2.6535e-03,  8.7301e-03, -4.5990e-02, -3.3433e-01, -1.8564e-03,\n",
      "          2.0868e-02,  1.5746e+00, -6.0151e-02,  1.8862e+00,  7.7008e-03,\n",
      "         -1.0826e-02,  6.2058e-03,  2.5223e-01, -2.6777e-03,  3.2033e-03,\n",
      "          7.5408e-03, -8.9416e-02, -3.7129e-02,  3.2369e-03,  1.4817e-03,\n",
      "         -6.3134e-05,  5.8678e-03,  1.2100e-01,  1.0100e+00,  1.1306e-01,\n",
      "         -6.7924e-02, -2.7483e-02,  1.0827e-01, -2.8542e-03, -1.7669e-01,\n",
      "         -1.5566e-02, -3.5369e-03, -5.3290e-03,  6.5237e-03, -4.7700e-03,\n",
      "         -3.0721e-02, -1.8966e-02, -4.0810e-04, -5.1925e-03, -1.0001e-02,\n",
      "          5.7661e-03,  1.1424e-04, -6.0956e-05,  1.1712e-02,  1.8653e-03,\n",
      "         -1.4709e-02, -6.6813e-02,  3.0640e-02, -1.8456e-04, -4.7056e-04,\n",
      "         -1.2058e-03, -3.6145e-01,  1.0174e-01,  2.7152e-03,  2.2691e-03,\n",
      "          8.0294e-04, -5.2907e-04, -3.5487e-04, -5.9340e-01, -7.0650e-03,\n",
      "         -5.2328e-04,  3.3726e-03, -1.1098e-03, -5.7102e-01, -2.2014e-03,\n",
      "         -6.5394e-04,  7.6700e-03, -1.5292e-02,  1.1418e-02, -1.8648e-03,\n",
      "         -3.5684e-03, -1.0364e-03, -6.8215e-02, -8.5016e-03,  3.0292e-03,\n",
      "         -1.2979e-02, -1.9753e-02, -5.6634e-02,  1.7365e-02,  1.8508e-04,\n",
      "         -4.3772e-03, -6.2213e-03,  4.5688e-03,  3.2824e-02, -7.2634e-01,\n",
      "         -1.2791e-01, -5.0431e-02,  4.7811e-03,  8.5610e-05,  8.5808e-03,\n",
      "         -1.7290e-03,  2.4328e-02,  3.9584e-02,  6.9032e-04,  1.1380e-02,\n",
      "         -4.0676e-04, -2.4171e-03,  1.3252e-01, -2.5778e-02,  6.9360e-02,\n",
      "         -8.5522e-04, -2.6247e+00, -6.7090e-01,  2.3442e-03, -1.4717e-04,\n",
      "          6.7160e-02,  7.7960e-02,  4.4421e-04, -2.5135e-02, -1.9991e-03,\n",
      "          2.0649e-02,  7.1433e-04,  4.2792e-04,  1.0194e-03,  2.2026e-02,\n",
      "         -5.0093e-03,  8.8966e-03, -1.2260e-01, -2.7647e-03,  4.0441e-04,\n",
      "          6.1359e-03, -4.3807e-03,  1.0895e-03, -5.0919e-03,  7.5980e-03,\n",
      "         -1.8750e-02,  8.6327e-03,  1.9685e-02, -3.2694e-04,  5.4851e-03,\n",
      "          7.1800e-03, -2.1997e-02,  4.2220e-01,  9.3665e-01,  5.9569e-03,\n",
      "          1.2029e-03,  1.0899e-05, -7.9744e-04, -7.9200e-04, -1.3077e-03,\n",
      "          5.7680e-03,  8.5932e-02, -9.5488e-03, -2.2373e-04, -1.1382e-01,\n",
      "         -7.0549e-03,  1.0015e-04, -1.4496e-01,  9.7872e-04, -2.8055e-03,\n",
      "          3.7057e-02,  3.1867e-01, -3.8721e-02,  4.7606e-01,  2.7009e-02,\n",
      "         -1.1700e-03, -9.5645e-04,  4.5048e-03, -1.5324e-02,  1.0799e-01,\n",
      "         -2.7520e-02,  2.2430e-03, -1.0701e-03,  1.3302e-02,  1.1657e-02,\n",
      "          3.0984e-04, -9.7469e-01, -1.1070e-03,  6.5832e-02, -1.3053e-01,\n",
      "         -3.0052e-02,  4.8989e-04, -3.4384e-03,  3.5660e-04, -4.2896e-01,\n",
      "         -1.1104e-01,  6.9590e-03, -8.5972e-03,  8.4741e-02,  7.4489e-03,\n",
      "          8.8161e-03,  1.5897e-03, -3.9305e-03, -6.0714e-03,  1.8147e-01,\n",
      "         -8.9436e-04, -6.9391e-02, -5.4912e-03,  8.7391e-04,  2.5837e-03,\n",
      "         -9.1899e-03,  9.9847e-03, -1.3463e-03,  3.8523e-04,  1.9353e-03,\n",
      "         -4.5288e-02, -2.2915e-03, -1.1312e+00, -1.7529e-02,  1.4622e-02,\n",
      "          2.2490e-02,  2.7346e-04, -3.6617e-01, -1.7777e-02, -1.3905e-02,\n",
      "          1.9215e-03,  3.8388e-02,  3.2472e-03, -3.2025e-03,  1.7336e-03,\n",
      "         -1.7920e-01, -2.5853e-01,  2.5596e-04, -7.5512e-03, -2.6324e-02,\n",
      "          9.9960e-04,  2.5230e-04,  6.3839e-03,  9.4724e-04,  9.0915e-01,\n",
      "         -6.4409e-04,  2.1346e-02, -5.0155e-03, -6.8880e-03, -3.8564e-01,\n",
      "         -3.1615e-03,  7.7354e-03, -3.5102e-02, -4.3670e-02, -2.0654e-01,\n",
      "          4.6999e-03, -8.7484e-04, -5.2157e-03, -3.7984e-02,  3.8436e-03,\n",
      "          1.6024e-02,  8.1106e-04, -1.8520e+00, -1.6300e-02,  2.7459e+00,\n",
      "          3.2638e-03,  6.4907e-03,  9.2871e-03,  3.5875e-02, -4.1667e-03,\n",
      "          2.3093e-04, -1.6576e-04, -1.5246e-02,  8.0909e-03, -2.2452e-03,\n",
      "         -1.0696e-03, -5.9520e-02, -5.3257e-04,  2.7177e-03, -2.4270e-02,\n",
      "          2.1677e-03, -1.3450e-02,  6.3649e-03, -1.1989e-03,  4.0153e-01,\n",
      "          1.4997e-03,  1.9392e-03, -1.4704e-03, -4.1706e-02, -2.6353e-01,\n",
      "          1.4691e-02,  4.3454e-03,  3.0187e-03, -3.7317e-03, -1.3557e-04,\n",
      "          4.1693e-03, -1.6112e-02, -2.3536e-04, -8.3370e-01,  4.1996e-02,\n",
      "         -1.5654e-03, -4.2973e-01, -1.1410e-02,  3.1387e-03, -2.2012e-02,\n",
      "          8.9572e-03,  1.1585e-01,  4.2299e-06, -2.0672e-03, -3.3357e-04,\n",
      "          4.4582e-02,  1.9351e-02, -1.4857e-03,  4.0452e-03,  2.9512e-01,\n",
      "          2.6719e-03, -4.9329e-03,  5.7307e-04,  2.6703e-04,  6.1451e-01,\n",
      "          3.6954e-01,  1.2819e-01,  7.9980e-02,  4.2989e-02, -2.1789e-01,\n",
      "          4.5188e-03,  5.2167e-03, -1.7324e+00, -8.9191e-03,  6.9120e-02,\n",
      "         -3.1858e-01,  2.2268e-01,  1.0997e+00, -8.8103e-04, -2.8255e-02,\n",
      "         -1.2758e-01,  3.5381e-02,  1.1391e-02,  2.0327e-03, -3.0958e-03,\n",
      "          1.7754e-02, -9.9925e-03, -7.9027e-03, -1.3805e-01,  3.3914e-02,\n",
      "          2.3301e-02, -1.8786e-02,  4.0544e-04, -7.3267e-03, -2.8005e-02,\n",
      "         -1.2129e-02,  3.4059e-03,  1.3163e-02,  5.2067e-04, -1.6014e-02,\n",
      "          1.7468e-03,  2.3850e-03,  3.7642e-02,  3.2561e-03, -1.2948e-02,\n",
      "         -1.5015e-03, -3.8516e-02, -1.6818e-01,  1.1983e-03, -3.6030e-03,\n",
      "         -2.3532e-03, -1.7455e-01, -3.0093e-02,  8.0215e-02,  1.7738e-03,\n",
      "          5.9665e-02, -2.2233e-01,  4.1062e-04, -4.3095e-02,  1.0200e-02,\n",
      "          9.9566e-04, -7.9157e-03, -2.0970e-02,  2.2900e+00, -5.7907e-04,\n",
      "          1.0234e-02, -2.1680e-03,  1.3802e-04,  1.0871e+00,  1.6410e-01,\n",
      "          1.5685e-03,  2.2397e-04, -5.1926e-02, -4.9278e-03, -3.4344e-01,\n",
      "          4.4304e-03,  1.6152e-03, -4.8358e-03,  1.2135e-03, -5.1316e-01,\n",
      "          2.4194e-03,  4.1370e-03,  1.0658e-01,  4.7698e-01,  3.6364e-02,\n",
      "         -3.6990e-02,  2.9570e-03,  2.2997e-01,  1.2404e-02, -5.1300e-03,\n",
      "         -7.2075e-04, -3.9982e-01, -9.6406e-02,  2.4532e-04, -7.4729e-02,\n",
      "         -6.5134e-03,  9.0688e-01,  5.2672e-02, -1.1369e+00, -1.1327e-02,\n",
      "         -1.2027e-02, -8.2927e-03, -7.8894e-04,  4.6843e-03, -9.6426e-04,\n",
      "         -1.4102e+00,  3.7344e-04, -2.8163e-03,  1.1606e-02, -2.6626e-04,\n",
      "         -1.8183e-02,  1.1804e-03,  4.6185e-03,  2.5544e-03, -4.1188e-02,\n",
      "         -1.9278e-04, -1.3695e-03, -4.3845e-03,  1.0229e-02,  4.0238e-01,\n",
      "          6.5167e-03,  1.1881e-02,  4.1376e-04,  4.2147e-03, -2.1801e-03,\n",
      "         -2.1741e-02, -2.2052e+00, -1.6529e-02,  9.4468e-03,  1.8932e-02,\n",
      "          3.2387e-04, -9.1743e-04, -7.2454e-01, -1.3841e+00,  3.5807e-04,\n",
      "         -3.3783e-02,  5.3466e-05,  1.7706e-02,  3.4934e-01,  1.4483e-03,\n",
      "          4.6877e-02, -2.8691e-03, -3.2883e-03]], device='cuda:0'), 'image_labels': None, 'image_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0'), 'patch_index': (tensor([[[ 9, 17],\n",
      "         [ 7,  1],\n",
      "         [ 5, 17],\n",
      "         [ 9,  6],\n",
      "         [10,  0],\n",
      "         [10, 15],\n",
      "         [ 6,  8],\n",
      "         [ 3,  5],\n",
      "         [ 3, 18],\n",
      "         [ 3,  2],\n",
      "         [ 2,  6],\n",
      "         [ 5,  6],\n",
      "         [ 2, 18],\n",
      "         [ 8,  2],\n",
      "         [ 0, 13],\n",
      "         [ 4,  6],\n",
      "         [ 7, 18],\n",
      "         [ 5,  4],\n",
      "         [ 7,  3],\n",
      "         [ 4, 14],\n",
      "         [ 0, 16],\n",
      "         [ 7,  8],\n",
      "         [ 8, 17],\n",
      "         [ 1,  5],\n",
      "         [ 7,  9],\n",
      "         [ 2,  0],\n",
      "         [ 2,  2],\n",
      "         [ 2,  1],\n",
      "         [ 1,  4],\n",
      "         [ 0, 10],\n",
      "         [10, 11],\n",
      "         [ 6,  3],\n",
      "         [ 0, 14],\n",
      "         [ 3,  3],\n",
      "         [ 2,  7],\n",
      "         [ 8,  9],\n",
      "         [ 7,  2],\n",
      "         [ 8, 18],\n",
      "         [10, 17],\n",
      "         [ 9, 14],\n",
      "         [ 6,  6],\n",
      "         [ 0,  3],\n",
      "         [ 4,  8],\n",
      "         [ 6, 18],\n",
      "         [ 7, 15],\n",
      "         [10,  9],\n",
      "         [ 2, 17],\n",
      "         [ 8, 14],\n",
      "         [ 3,  9],\n",
      "         [ 6,  1],\n",
      "         [ 0,  2],\n",
      "         [ 3, 17],\n",
      "         [ 6, 13],\n",
      "         [ 8, 16],\n",
      "         [ 4,  4],\n",
      "         [10, 14],\n",
      "         [ 1, 15],\n",
      "         [ 9, 16],\n",
      "         [10, 18],\n",
      "         [ 4, 10],\n",
      "         [ 2,  3],\n",
      "         [10, 12],\n",
      "         [ 0, 12],\n",
      "         [ 8, 10],\n",
      "         [ 8,  5],\n",
      "         [ 3, 11],\n",
      "         [ 2, 15],\n",
      "         [ 1, 17],\n",
      "         [ 9,  2],\n",
      "         [ 3,  1],\n",
      "         [ 6, 11],\n",
      "         [ 2,  5],\n",
      "         [ 5,  0],\n",
      "         [10,  2],\n",
      "         [ 1,  2],\n",
      "         [ 0,  4],\n",
      "         [ 4, 15],\n",
      "         [ 8,  6],\n",
      "         [ 3, 10],\n",
      "         [ 4, 18],\n",
      "         [ 5, 15],\n",
      "         [ 3,  6],\n",
      "         [ 5, 11],\n",
      "         [ 8, 11],\n",
      "         [ 0,  0],\n",
      "         [ 9,  0],\n",
      "         [ 4, 17],\n",
      "         [ 8,  8],\n",
      "         [ 7,  0],\n",
      "         [ 1, 11],\n",
      "         [ 4,  2],\n",
      "         [ 0, 18],\n",
      "         [ 5, 12],\n",
      "         [ 1,  0],\n",
      "         [ 6, 10],\n",
      "         [ 2, 10],\n",
      "         [ 0,  1],\n",
      "         [ 0, 17],\n",
      "         [ 0, 11],\n",
      "         [ 4, 13],\n",
      "         [ 8,  4],\n",
      "         [ 7, 10],\n",
      "         [ 3, 15],\n",
      "         [ 9, 10],\n",
      "         [ 6,  7],\n",
      "         [ 2, 16],\n",
      "         [ 8,  0],\n",
      "         [ 9,  8],\n",
      "         [ 3, 13],\n",
      "         [ 0,  7],\n",
      "         [ 0, 15],\n",
      "         [ 1, 18],\n",
      "         [ 4,  9],\n",
      "         [ 6,  0],\n",
      "         [ 1, 12],\n",
      "         [ 9,  5],\n",
      "         [ 8, 12],\n",
      "         [ 1,  3],\n",
      "         [ 6,  2],\n",
      "         [ 5, 10],\n",
      "         [ 9,  3],\n",
      "         [ 6,  9],\n",
      "         [ 3, 16],\n",
      "         [ 7,  4],\n",
      "         [10, 10],\n",
      "         [ 1, 14],\n",
      "         [ 0,  8],\n",
      "         [ 1,  7],\n",
      "         [ 7, 13],\n",
      "         [ 4,  3],\n",
      "         [ 6, 15],\n",
      "         [ 6, 16],\n",
      "         [ 0,  9],\n",
      "         [ 0,  5],\n",
      "         [ 2,  8],\n",
      "         [ 9, 12],\n",
      "         [ 3,  4],\n",
      "         [ 9, 15],\n",
      "         [ 5, 16],\n",
      "         [ 5,  9],\n",
      "         [10,  1],\n",
      "         [ 1,  8],\n",
      "         [ 1,  6],\n",
      "         [ 4, 16],\n",
      "         [ 2,  9],\n",
      "         [ 8, 13],\n",
      "         [ 7,  5],\n",
      "         [ 7, 11],\n",
      "         [ 2, 14],\n",
      "         [ 9,  7],\n",
      "         [ 6, 12],\n",
      "         [ 1,  9],\n",
      "         [ 5,  2],\n",
      "         [ 9,  4],\n",
      "         [ 8,  1],\n",
      "         [ 3,  7],\n",
      "         [10,  6],\n",
      "         [ 8, 15],\n",
      "         [ 3,  0],\n",
      "         [ 3,  8],\n",
      "         [10, 16],\n",
      "         [ 6, 14],\n",
      "         [ 5,  3],\n",
      "         [ 9, 11],\n",
      "         [10,  4],\n",
      "         [ 7,  7],\n",
      "         [ 4,  7],\n",
      "         [ 1,  1],\n",
      "         [ 4,  0],\n",
      "         [ 5, 18],\n",
      "         [ 3, 14],\n",
      "         [ 5, 14],\n",
      "         [ 2, 13],\n",
      "         [ 8,  3],\n",
      "         [ 5,  5],\n",
      "         [10,  8],\n",
      "         [ 4,  1],\n",
      "         [ 5,  1],\n",
      "         [ 1, 16],\n",
      "         [ 4,  5],\n",
      "         [ 5,  8],\n",
      "         [ 4, 11],\n",
      "         [ 6, 17],\n",
      "         [ 1, 13],\n",
      "         [ 2, 11],\n",
      "         [ 8,  7],\n",
      "         [ 9, 13],\n",
      "         [ 4, 12],\n",
      "         [ 2,  4],\n",
      "         [ 0,  6],\n",
      "         [10,  7],\n",
      "         [ 3, 12],\n",
      "         [ 1, 10],\n",
      "         [10,  5],\n",
      "         [ 6,  5],\n",
      "         [ 2, 12],\n",
      "         [10, 13],\n",
      "         [ 7, 16],\n",
      "         [ 5,  7],\n",
      "         [ 7, 12],\n",
      "         [ 9,  1],\n",
      "         [ 9,  9],\n",
      "         [ 7, 14],\n",
      "         [10,  3],\n",
      "         [ 9, 18],\n",
      "         [ 7,  6],\n",
      "         [ 5, 13],\n",
      "         [ 6,  4],\n",
      "         [ 7, 17]]]), (11, 19)), 'cls_output': tensor([[0.2354]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_389858/3499233738.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sensor =  torch.tensor(sensor).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 3])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sensor_feats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb Cell 59\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(sensor)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m sensor \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mtensor(sensor)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39m# torch.Size([1, 1, 3])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m out \u001b[39m=\u001b[39m infer(examples[\u001b[39m0\u001b[39;49m],sensor)\n",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb Cell 59\u001b[0m in \u001b[0;36minfer\u001b[0;34m(img_filename, sensor)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     infer \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mprint\u001b[39m(infer)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     sensor_emb, img_emb \u001b[39m=\u001b[39m infer[\u001b[39m\"\u001b[39;49m\u001b[39msensor_feats\u001b[39;49m\u001b[39m\"\u001b[39;49m], infer[\u001b[39m\"\u001b[39m\u001b[39mimage_feats\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m# torch.Size([1, 23, 768]) torch.Size([1, 217, 768])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     cls_output \u001b[39m=\u001b[39m infer[\u001b[39m'\u001b[39m\u001b[39mcls_output\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_soybean.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [cls_output]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sensor_feats'"
     ]
    }
   ],
   "source": [
    "\n",
    "examples=[\n",
    "            \"/home/junsheng/data/xiangguan/pic/xiangguanD4-2021-05-24-10-00-25.jpeg\", #0\n",
    "            \n",
    "            \"/home/junsheng/data/xiangguan/pic/xiangguanD4-2021-07-18-04-22-30-preset-18.jpeg\", # 3\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "n = 1\n",
    "sensor = torch.rand(config.senser_input_num)\n",
    "# sensor = torch.ones(config.senser_input_num)\n",
    "print(sensor)\n",
    "sensor =  torch.tensor(sensor).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 3])\n",
    "out = infer(examples[0],sensor)\n",
    "# print(\"out:\",out,\"000\\n\")\n",
    "# print(\"out0.shape:\",out[0].shape)\n",
    "# cv2.imwrite('output.png',out[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.8166]], device='cuda:0')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8166\n"
     ]
    }
   ],
   "source": [
    "print(out[0].cpu().numpy()[0][0])\n",
    "#0.00031266143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test by valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择三组生长期不同的数据去验证训练的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.query(\"fold==0\").reset_index(drop=True)\n",
    "df_test.to_csv(\"test_by_valid.csv\",index=False)\n",
    "sensor_test_list = df_test.sensor.tolist()\n",
    "image_test_list = df_test.image_path.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: torch.Size([1, 3, 352, 608])\n",
      "{'sensor_feats': tensor([[[ 2.7024e-01,  8.4886e-01,  3.5035e-01,  5.3281e-02,  5.2474e-02,\n",
      "          -1.7046e-01,  7.3329e-02,  3.0590e-02,  6.7037e-02, -3.7755e-01,\n",
      "          -8.7652e-01,  1.3844e-01,  2.5090e-01, -3.3451e-01, -1.6991e-01,\n",
      "          -2.3502e-02, -6.9722e-02, -1.1445e-01, -1.7391e-01,  3.5070e-01,\n",
      "          -1.2979e+00,  2.7135e-01, -6.4320e-02, -9.8884e-01,  3.2600e-02,\n",
      "          -4.4981e-01,  1.7270e-01,  3.7485e-01, -8.4396e-01, -6.4098e-02,\n",
      "           1.6703e-01,  3.6598e-01, -4.2784e-02, -1.1087e-01,  1.1336e-02,\n",
      "          -2.0030e+00, -7.8494e-01, -9.4766e-02, -1.2019e-01,  1.6362e-01,\n",
      "          -1.2572e-01,  2.2219e-01, -3.8874e-02,  6.9456e-01, -6.6659e-01,\n",
      "          -7.5572e-02, -6.5935e-02, -2.7468e-02,  1.0221e+00, -2.5591e-01,\n",
      "           1.8912e-01, -5.2756e-01,  4.2142e-02,  1.3391e+00,  6.7435e-02,\n",
      "           9.3807e-01,  1.4467e+00,  4.8933e-01,  2.6360e-01, -6.8080e-02,\n",
      "           1.7264e-01,  7.1070e-02,  3.0559e-01,  1.0487e+00, -1.0531e-01,\n",
      "           1.4899e-01, -1.4601e-01,  7.0311e-02, -6.1047e-01,  3.2517e-01,\n",
      "           9.6615e-02, -4.9635e-01,  3.9653e-01, -8.1497e-01,  4.3536e-01,\n",
      "          -1.7965e-01, -1.8054e-02, -7.7346e-02,  3.7056e-01, -1.1527e-01,\n",
      "          -5.1328e-02,  2.2571e-01, -1.4052e-01,  3.9916e-01, -1.5368e+00,\n",
      "          -2.2687e-01,  6.8785e-01,  4.7555e-03,  4.0235e-01, -3.9818e-01,\n",
      "           4.5255e-01,  1.8249e-01,  2.4254e-02,  5.4363e-01,  3.1668e-01,\n",
      "           1.4741e-01, -1.2045e+00,  5.6026e-01,  1.8129e-02, -5.2342e-01,\n",
      "          -2.5647e-01, -5.9585e-01,  1.6685e-01, -2.0819e-01, -2.7393e-01,\n",
      "          -5.4547e-02,  8.3671e-01,  1.0122e+00,  3.0082e-01, -4.0947e-01,\n",
      "          -3.5765e-01, -8.6501e-04,  1.6294e-01, -4.0080e-01, -8.3902e-01,\n",
      "           2.2061e-01, -4.1820e-02, -4.1544e-01, -2.5201e+00, -9.8932e-02,\n",
      "          -5.8175e-01, -7.2491e-02, -8.2113e-01, -1.3048e-01, -4.9790e-01,\n",
      "          -2.5302e-01,  9.9828e-02,  3.8401e-01, -1.0704e-01, -1.3460e-01,\n",
      "          -5.2490e-01,  1.6422e-01, -7.2538e-02,  3.1729e-01, -1.8784e-01,\n",
      "           8.4847e-01,  2.7782e-01,  3.9456e-01,  7.3581e-01, -4.6038e-01,\n",
      "          -1.2405e-01,  3.6507e-01,  1.0595e+00, -3.3720e-01, -1.7847e-01,\n",
      "           6.9445e-02,  5.5660e-02,  6.6612e-01, -1.5342e-01, -1.0245e-01,\n",
      "          -4.1698e-01, -4.7990e-01, -4.3741e-02,  7.5446e-01, -8.5839e-01,\n",
      "          -2.9759e-01,  7.4105e-02,  3.6936e-01,  2.2517e-01,  2.0445e-01,\n",
      "          -2.2520e-01, -7.0262e-01,  1.7491e+00,  1.5410e-01,  2.4333e-01,\n",
      "           1.1808e-01,  2.0031e-01, -4.1765e-01, -4.4570e-02, -7.5414e-02,\n",
      "          -1.7943e-01,  2.9114e-01, -5.1989e-01,  5.7214e-02,  3.4968e-03,\n",
      "          -5.4809e-02,  9.5891e-02, -1.0574e-01,  1.3325e-01,  6.3144e-01,\n",
      "           5.8261e-02, -5.3787e-01,  4.9443e-01,  8.5900e-01,  3.4082e-02,\n",
      "           8.8916e-04, -2.6900e-02,  2.4115e-01,  3.4658e-01, -6.3444e-02,\n",
      "           1.6090e-01,  6.9500e-01, -3.7949e-01,  1.2788e-01,  1.5003e-01,\n",
      "          -4.2237e-02, -2.5673e-01, -3.3161e-01, -2.3348e-01,  5.5662e-01,\n",
      "          -4.5105e-01,  1.1752e-01,  5.5362e-01,  1.0310e+00,  5.0748e-03,\n",
      "          -1.2152e+00, -4.7172e-01,  1.2711e-01,  6.1709e-02,  4.8978e-01,\n",
      "           2.5862e-01, -1.6091e-01, -2.9285e-01, -2.4275e-01,  3.7013e-01,\n",
      "          -6.4637e-01,  4.7067e-01, -1.3941e-01,  8.2075e-02, -4.9278e-02,\n",
      "          -2.3442e-01,  2.8614e-01, -2.1160e-01, -1.1124e+00,  9.2892e-01,\n",
      "           3.1191e-01,  8.5168e-02,  1.1483e-01,  8.2778e-01,  3.2094e-01,\n",
      "          -4.2826e-01, -4.3217e-01,  9.0470e-02,  1.4781e-01,  6.4168e-01,\n",
      "          -4.0168e-01, -3.3907e-01,  1.7142e-01, -1.4673e-01,  8.6523e-02,\n",
      "          -4.7792e-03, -1.9192e-01, -3.2239e-01, -2.2403e-01, -2.6295e-02,\n",
      "          -1.5122e-01,  6.5477e-02,  1.5560e-01,  1.1998e-01,  1.4690e-01,\n",
      "           5.6724e-01, -9.5334e-01,  1.0883e-01, -4.6437e-01, -2.8476e-01,\n",
      "          -2.8313e-01,  5.9793e-01, -1.3925e+00,  5.2537e-02,  1.7755e-01,\n",
      "           4.5361e-02,  1.0916e-01, -1.9150e-01, -1.3015e-01, -5.1746e-01,\n",
      "          -5.5892e-01, -1.6779e-01,  9.6007e-01,  1.4014e+00, -3.8179e-01,\n",
      "          -2.3898e-01,  9.5665e-02,  5.4185e-01,  7.8480e-02, -7.4198e-01,\n",
      "           3.7485e-02, -1.1244e-01,  5.6840e-01, -1.5983e-01,  3.1847e-01,\n",
      "          -2.8043e-01,  1.3540e-01, -9.7404e-02, -7.2468e-01,  9.9290e-01,\n",
      "           6.1460e-01,  3.0556e-01, -9.4487e-01,  1.0193e+00, -1.0106e-01,\n",
      "          -1.5386e+00,  3.4158e-01,  4.2114e-01, -3.2881e-01, -1.3621e-02,\n",
      "          -2.3702e-01, -5.9156e-01, -6.2746e-02, -9.9363e-01, -3.5500e-03,\n",
      "          -1.1910e-02, -1.5673e-01, -1.3858e-01, -1.2728e-01,  3.2764e-01,\n",
      "           1.5330e-01,  3.4395e-01, -1.7346e+00,  4.2143e-01,  2.9009e-01,\n",
      "          -2.0314e-01, -1.6999e-01, -5.6043e-01,  1.5592e+00,  9.0695e-01,\n",
      "          -2.3074e-01,  2.6335e-01,  1.0063e-02,  3.3536e-01, -1.0068e+00,\n",
      "           3.3994e-01,  3.1071e-01,  5.5808e-04, -1.8070e-01,  3.1451e-01,\n",
      "           3.3578e-01, -2.1316e-02,  1.2061e-01, -2.9430e-01,  1.0108e-01,\n",
      "           3.9898e-02,  3.1339e-01,  4.6233e-01, -6.2455e-02, -4.8597e-01,\n",
      "          -1.1414e-01, -2.3682e-01,  3.2588e-01,  2.1854e-01,  2.1128e-01,\n",
      "          -6.2360e-01, -1.0117e-01,  4.4842e-01, -7.2232e-01,  8.1424e-02,\n",
      "          -1.1417e-01, -1.5510e-01,  1.9553e+00,  1.4658e-01,  8.1736e-01,\n",
      "          -1.5598e-01, -1.1353e-01,  7.0220e-01,  3.5282e-03, -2.4982e-01,\n",
      "          -2.7995e+00, -1.3884e+00,  9.2986e-01, -3.0575e-01,  4.1183e-01,\n",
      "          -5.4223e-01, -2.7192e-01,  3.2496e-01, -2.3899e-01, -3.1130e-02,\n",
      "          -1.0525e+00,  2.2014e+00, -7.1531e-01,  3.3892e-02, -3.3486e-01,\n",
      "           6.7763e-01,  2.0083e-01, -1.8894e-01, -1.0283e+00, -9.1044e-02,\n",
      "           4.8329e-03, -1.0640e-01,  4.0725e-01, -2.3403e-01,  6.0655e-01,\n",
      "           3.4804e-01, -3.5779e-01, -1.3233e-02, -1.0694e-01,  6.3256e-01,\n",
      "           1.0990e-01,  2.3830e-02,  3.6173e-01,  5.7738e-01, -1.9464e-01,\n",
      "           4.8241e-01, -2.5946e-02, -1.9019e-01, -7.8480e-01,  6.8758e-02,\n",
      "          -4.7497e-02, -1.3609e+00,  6.1587e-01,  5.8165e-02, -1.9913e-01,\n",
      "           9.7329e-01,  1.0289e-02,  1.6345e-01, -1.8136e-01, -2.1239e-01,\n",
      "          -7.4947e-02,  3.7483e-01, -1.4315e+00,  9.2524e-01,  5.4806e-02,\n",
      "           4.1944e-01,  2.0483e-02,  7.2994e-01,  2.1012e+00, -1.2746e+00,\n",
      "          -2.7914e-01, -4.1034e-01,  1.5823e-01, -1.2046e-01,  2.5009e-01,\n",
      "          -2.6848e-01,  9.3349e-03, -6.9723e-01, -1.1454e+00,  2.8049e-01,\n",
      "           1.7298e-01,  1.3442e-02, -3.6490e-01,  2.7565e-01, -5.0091e-01,\n",
      "           5.6422e-01, -4.3578e-01,  1.3744e+00,  2.6284e-01, -3.6305e-01,\n",
      "           1.8917e-01,  6.6354e-01, -6.3040e-01, -7.2850e-01, -8.3665e-02,\n",
      "          -2.6176e-01,  7.0304e-02,  1.4631e-01, -5.3198e-01,  6.2124e-01,\n",
      "           4.9013e-01,  7.6268e-02,  3.4316e-02, -1.7787e-01, -1.4833e-01,\n",
      "           1.1812e+00,  1.1317e+00, -4.8711e-01, -1.6038e-01,  2.3041e-01,\n",
      "           1.3259e+00,  9.8977e-02,  8.9631e-02,  1.8019e-01,  3.3693e-01,\n",
      "          -3.6393e-02,  1.1927e-01, -2.7777e-01, -9.0305e-02, -5.1156e-02,\n",
      "          -2.2291e-01, -8.1878e-01,  7.2951e-01,  2.9266e-01,  2.8071e+00,\n",
      "           2.3238e-01,  1.9978e-01,  4.6962e-01, -6.9338e-01,  2.1595e-02,\n",
      "           5.8179e-01, -8.0825e-03,  4.0437e-02,  4.6131e-01, -8.8928e-02,\n",
      "           1.0060e+00, -3.3248e-01, -4.9280e-01,  7.4792e-01,  1.4398e+00,\n",
      "          -1.4240e-01,  5.4036e-01,  3.3272e-01, -1.4869e-01, -3.5158e-01,\n",
      "          -2.0619e+00, -1.1094e-01, -3.5929e-01, -9.2581e-03, -6.2078e-01,\n",
      "          -3.0006e-01,  1.2676e-01, -3.4668e-01,  4.0886e-01, -1.8963e-01,\n",
      "          -3.1097e-01,  3.9580e-01, -8.1414e-02,  1.1727e-01, -1.0543e-01,\n",
      "          -1.1591e-01,  9.5239e-02,  1.2715e+00,  9.5719e-01, -1.0286e+00,\n",
      "          -1.2770e+00,  8.1440e-02, -1.8329e+00,  1.0241e-01, -3.5173e-01,\n",
      "          -5.2059e-01, -2.3979e-03, -1.6086e-01,  5.2218e-01,  1.0047e+00,\n",
      "           8.4269e-01,  7.7826e-02,  1.0640e-01, -3.7783e-02, -1.3345e+00,\n",
      "           5.3439e-01,  9.4980e-02,  1.7555e+00, -1.7011e-01,  6.6691e-02,\n",
      "           6.1246e-02,  5.6022e-01,  1.3658e-01, -1.5076e+00,  1.5500e-01,\n",
      "          -2.7122e-01, -2.7139e-01,  1.8960e-01, -1.3290e-01, -8.1194e-02,\n",
      "           2.3106e-02, -6.0200e-01,  2.4592e-01,  9.4521e-02, -3.6338e-01,\n",
      "           4.7547e-01, -1.4175e+00, -3.1754e-01,  2.4655e-02,  1.7531e+00,\n",
      "           2.2224e-01, -6.8889e-02,  1.7817e-01, -2.8154e-01,  1.2842e-01,\n",
      "          -1.1765e-01, -2.4398e-01,  6.9239e-01,  4.9469e-03, -1.0554e-01,\n",
      "          -2.1135e-01, -8.2615e-01, -1.2064e+00, -9.0425e-02, -3.6638e-01,\n",
      "          -1.1402e-01,  3.5683e-01, -4.8989e-01, -3.2952e-01, -1.4446e-01,\n",
      "           1.1521e-01,  5.4473e-01,  4.6421e-01, -4.7061e-01,  4.1033e-02,\n",
      "           3.0311e-02,  3.8718e-01,  3.9273e-02, -4.2830e-02, -2.2708e-02,\n",
      "           1.9289e+00,  2.8577e-02,  3.5952e-01,  4.2292e-02, -1.2712e+00,\n",
      "           4.9575e-01, -1.7472e-01,  6.2497e-01,  7.0061e-01,  1.0168e+00,\n",
      "           2.0898e-01,  2.9583e-01,  2.6145e+00,  7.3840e-01, -4.0931e-02,\n",
      "           1.6071e-01, -1.3981e+00, -6.6715e-02, -1.3173e-01, -1.1371e-01,\n",
      "           3.8258e-01,  1.4547e-01, -1.7297e-01,  3.8544e-02, -3.1107e-01,\n",
      "          -1.8706e+00, -2.0439e-01, -1.0771e-01,  3.1944e-01,  4.9499e-02,\n",
      "          -1.0994e-01,  1.5210e-01, -1.4176e+00,  5.2413e-02, -8.5459e-01,\n",
      "          -9.9805e-01,  1.9167e+00, -6.7263e-03,  2.3618e+00, -2.4710e-01,\n",
      "          -1.2896e-01,  3.7116e-01,  8.9034e-01, -6.4879e-02,  4.0245e-01,\n",
      "           3.8369e-01, -3.5353e-01,  5.1265e-01, -3.5775e-01,  6.3312e-02,\n",
      "          -1.3479e+00, -1.6700e-01, -2.2919e-01, -1.7324e-01, -3.7457e-01,\n",
      "          -1.0357e-01, -1.8559e-01, -5.9229e-01, -1.9978e-01,  4.4437e-01,\n",
      "          -8.8195e-01,  6.1009e-01,  5.7204e-01, -1.4240e+00, -3.9134e-01,\n",
      "           4.3413e-01,  5.6744e-01, -5.3973e-01,  1.3536e-01, -1.7571e-02,\n",
      "           4.3265e-01, -2.3575e+00, -2.0904e-01, -2.3189e+00, -6.9198e-01,\n",
      "           4.8116e-02,  4.4486e-01, -8.9616e-02, -3.0280e-01, -2.8890e-02,\n",
      "           1.9719e-01, -1.6125e+00, -1.0723e-02, -1.2308e+00,  2.7813e-02,\n",
      "           7.9382e-01, -3.8642e-01,  1.1324e-02,  3.2542e-02,  3.3886e-02,\n",
      "           8.7939e-02,  3.2446e-02, -4.3876e-01, -5.7848e-01,  2.2803e-01,\n",
      "          -5.0407e-02,  6.0831e-01, -1.8474e-01,  2.5290e+00,  4.7034e-01,\n",
      "          -7.4563e-01,  1.8814e-01,  5.8178e-02,  1.7588e-01, -2.3231e-01,\n",
      "          -2.6213e-01, -3.2092e-01,  3.5052e-01,  2.3856e-02, -9.3220e-02,\n",
      "          -1.4070e+00,  8.7897e-01, -1.7089e-01,  1.5757e-01,  6.0234e-01,\n",
      "           1.0688e-01, -5.8827e-02,  4.0119e-01, -8.5685e-02, -2.9215e-01,\n",
      "           3.3505e-02,  5.2877e-01,  8.5433e-02, -1.3682e-01,  5.6899e-02,\n",
      "           3.0420e-02, -1.6028e+00,  1.9255e-01,  1.2622e-01, -9.5260e-01,\n",
      "           2.0320e-01,  2.3399e-01,  2.6022e-01, -4.4882e-02, -3.5379e-01,\n",
      "          -4.8428e-01,  7.3951e-01,  3.5998e-01, -3.1704e-02,  6.6309e-01,\n",
      "           1.2429e-01,  1.0664e-01, -4.8499e-01, -1.4012e+00,  6.6858e-01,\n",
      "          -5.0829e-01,  3.4053e-02, -7.1859e-02,  2.4280e-01,  1.2617e-01,\n",
      "           3.1691e-01,  5.0482e-01, -1.4471e-01,  5.6196e-01, -1.0742e+00,\n",
      "          -3.1774e+00, -5.2434e-01, -7.6493e-01, -3.8002e-01, -7.4135e-02,\n",
      "          -1.2321e-01, -4.9928e-01,  3.1236e-01,  4.7799e-01,  9.0799e-01,\n",
      "          -6.3907e-02, -3.8825e-01,  1.3708e-01, -1.9597e-01, -6.9311e-01,\n",
      "          -2.2167e-01,  8.6342e-02,  5.5120e-03,  1.1685e+00, -1.1648e-01,\n",
      "           2.3934e-01,  1.8242e+00, -2.1611e-01, -2.9277e-01,  2.9649e-01,\n",
      "          -2.1038e-01, -2.2648e-01, -7.3345e-02,  1.4272e+00, -1.9541e-01,\n",
      "          -7.2778e-02,  5.3655e-01,  8.1853e-02]]], device='cuda:0'), 'image_feats': tensor([[[ 0.2431,  0.8703,  0.4091,  ..., -0.1364,  0.5865, -0.0774],\n",
      "         [ 0.1377,  1.0587,  0.3401,  ..., -0.0132,  0.5184,  1.2675],\n",
      "         [ 1.2541,  0.5216,  0.6157,  ...,  0.0277,  0.6304,  0.1008],\n",
      "         ...,\n",
      "         [-0.1858,  1.0811,  0.0942,  ..., -0.1176,  0.2101,  1.4752],\n",
      "         [ 0.2074,  0.9274,  0.3214,  ..., -0.2068,  0.5712, -0.3430],\n",
      "         [ 0.9357,  0.9592,  0.3450,  ..., -0.1386,  0.4405,  0.8156]]],\n",
      "       device='cuda:0'), 'cls_feats': tensor([[ 0.6861,  0.9635,  0.9189, -0.6999, -0.9506, -0.9428,  0.8898, -0.9481,\n",
      "         -0.4192, -0.7655, -0.9380, -0.7018, -0.8167,  0.9557, -0.9731,  0.9530,\n",
      "         -0.0454,  0.6914,  0.7266, -0.0052, -0.9271,  0.6346,  0.9023,  0.9638,\n",
      "         -0.3695,  0.9387, -0.8322,  0.9430, -0.2531,  0.8075, -0.6678, -0.6310,\n",
      "          0.7473,  0.9280, -0.0177,  0.3133, -0.8889,  0.1552, -0.9467, -0.9320,\n",
      "         -0.6951, -0.8687,  0.1766,  0.3877, -0.9530, -0.9646,  0.7337, -0.5759,\n",
      "          0.9306,  0.4362, -0.6669, -0.9406,  0.8098, -0.8067, -0.6465,  0.8948,\n",
      "          0.6083, -0.0344, -0.3722, -0.6427, -0.9051,  0.0540, -0.9654, -0.5094,\n",
      "          0.9314, -0.4041,  0.9361,  0.7168,  0.9392, -0.9849, -0.6538,  0.9099,\n",
      "         -0.8167, -0.6269, -0.8203, -0.8790, -0.9354,  0.9654,  0.9002,  0.8086,\n",
      "          0.6134,  0.8996,  0.4390, -0.9166,  0.7954,  0.4243,  0.5765, -0.4910,\n",
      "         -0.0837, -0.7827, -0.9418, -0.9364,  0.8557,  0.8651,  0.8614,  0.9193,\n",
      "          0.8506,  0.6370, -0.7113, -0.9676, -0.6871, -0.2314,  0.7330,  0.9065,\n",
      "         -0.9324,  0.3956,  0.7447, -0.8064,  0.9067,  0.8631,  0.4799,  0.6384,\n",
      "          0.8402, -0.8473, -0.8665,  0.1329,  0.9430,  0.9106, -0.9522, -0.8534,\n",
      "          0.8711,  0.2717, -0.5412,  0.7744, -0.9263,  0.0793,  0.4515, -0.9735,\n",
      "         -0.0066,  0.7723, -0.9771, -0.5410, -0.8353, -0.3052, -0.9695,  0.8457,\n",
      "          0.4923, -0.8924,  0.6764, -0.9508,  0.0490,  0.8915,  0.9543,  0.9395,\n",
      "          0.8224,  0.2361, -0.9094, -0.7523,  0.9566, -0.4121, -0.7178, -0.8682,\n",
      "         -0.9594, -0.5169,  0.9100, -0.0268, -0.2220,  0.8911,  0.8748, -0.5452,\n",
      "          0.9679, -0.0137, -0.6876,  0.9694,  0.2526, -0.8979,  0.1786, -0.8641,\n",
      "         -0.5407,  0.9638,  0.5739, -0.3002, -0.9697, -0.8552,  0.4265, -0.8314,\n",
      "          0.1260, -0.7668,  0.9569,  0.8464,  0.8809, -0.8522, -0.4863, -0.9610,\n",
      "          0.9031, -0.2059,  0.9832,  0.6457, -0.8745, -0.8451,  0.7987, -0.9393,\n",
      "         -0.9211,  0.3932, -0.8454, -0.7477,  0.9450,  0.9613,  0.8656,  0.0195,\n",
      "          0.6211, -0.4546,  0.9077,  0.5471,  0.5030,  0.9209,  0.6497, -0.8848,\n",
      "          0.4744,  0.2030, -0.9027, -0.8507, -0.2835, -0.0010,  0.9581, -0.9146,\n",
      "          0.9396, -0.2140, -0.4562,  0.8399, -0.3735,  0.5367, -0.6889,  0.8266,\n",
      "          0.8667,  0.6894, -0.0769,  0.1583, -0.0120,  0.7468, -0.4944, -0.9677,\n",
      "          0.8974,  0.9041, -0.7135,  0.7476,  0.8049, -0.7467,  0.8361, -0.1140,\n",
      "         -0.9609, -0.9281, -0.8294, -0.8841,  0.7275, -0.8979, -0.7762, -0.7321,\n",
      "         -0.7858, -0.7055,  0.9645, -0.9546,  0.8950,  0.9380, -0.4398, -0.9443,\n",
      "         -0.7640, -0.8377, -0.9044, -0.7822,  0.5797,  0.6652,  0.8443, -0.7218,\n",
      "         -0.9397, -0.7241, -0.9334, -0.7932, -0.9124, -0.9315, -0.9212,  0.9657,\n",
      "         -0.9403, -0.9138, -0.9086, -0.2287, -0.9148, -0.7972, -0.4978, -0.9206,\n",
      "         -0.9397, -0.3000, -0.8109, -0.9089,  0.8219, -0.9187, -0.9375,  0.1631,\n",
      "          0.9176, -0.4643,  0.0486,  0.8334,  0.9211, -0.9416, -0.4710, -0.8741,\n",
      "          0.4695, -0.8994,  0.0282,  0.8080, -0.6750, -0.8064,  0.9439, -0.3361,\n",
      "         -0.8883,  0.9143, -0.7095, -0.0080, -0.9304, -0.0989,  0.8746, -0.9472,\n",
      "         -0.9569, -0.5521,  0.1029,  0.9448,  0.9725, -0.9444, -0.8032,  0.6849,\n",
      "         -0.8741, -0.8476, -0.8543, -0.8867,  0.3841, -0.9577,  0.9002,  0.8944,\n",
      "          0.8741,  0.9605,  0.9298,  0.7942,  0.0601,  0.0177,  0.8477, -0.7911,\n",
      "         -0.7208,  0.6451, -0.7525,  0.9019,  0.9625, -0.6047, -0.4711, -0.7241,\n",
      "         -0.8680, -0.0926,  0.9080,  0.9230, -0.8913, -0.7550, -0.9705,  0.9343,\n",
      "          0.9556, -0.3745,  0.0613,  0.0245,  0.8374, -0.8194,  0.4525,  0.1838,\n",
      "         -0.1391, -0.8964, -0.9057, -0.9511, -0.8785, -0.9473, -0.9584, -0.9404,\n",
      "         -0.9258, -0.9336, -0.4731, -0.6960, -0.0861, -0.4606,  0.8067, -0.9468,\n",
      "          0.8689,  0.9710,  0.9321, -0.9172, -0.5130, -0.9465, -0.3851,  0.0096,\n",
      "         -0.8701,  0.7197,  0.1344, -0.2644,  0.8965,  0.0093, -0.8958, -0.1762,\n",
      "         -0.7720,  0.9036,  0.7997,  0.5176,  0.7928, -0.4390,  0.0357, -0.4593,\n",
      "         -0.1821,  0.7816, -0.4445, -0.6764,  0.9206, -0.5247, -0.8472,  0.6751,\n",
      "         -0.4740,  0.5442,  0.5204, -0.9465, -0.5485, -0.5013,  0.4493, -0.7130,\n",
      "         -0.9599, -0.0396, -0.8417, -0.8242, -0.8399, -0.9091, -0.9375,  0.3721,\n",
      "         -0.9502, -0.9258,  0.9106,  0.7854, -0.9354, -0.5029,  0.7846, -0.8933,\n",
      "          0.8479, -0.7099, -0.9312, -0.4060,  0.9086,  0.4037, -0.9608, -0.9267,\n",
      "          0.0818,  0.8091, -0.9481, -0.9064, -0.6212,  0.6837, -0.6029, -0.0268,\n",
      "         -0.1795,  0.8621, -0.4785,  0.1611, -0.9613,  0.6329, -0.8598, -0.8511,\n",
      "         -0.9122, -0.7216, -0.7042,  0.9457,  0.3143,  0.7789,  0.2101,  0.8547,\n",
      "          0.7129,  0.5477, -0.4509,  0.8447, -0.8087,  0.0530, -0.8974, -0.6889,\n",
      "          0.9161,  0.8877, -0.8584,  0.8737,  0.8873, -0.9335, -0.6944,  0.9046,\n",
      "          0.2264,  0.2252,  0.4507,  0.9608, -0.4124,  0.7434, -0.9581, -0.8339,\n",
      "          0.0081,  0.7294,  0.9500,  0.8169, -0.7480,  0.8812,  0.0795, -0.7554,\n",
      "         -0.9528, -0.5903, -0.8181, -0.6516, -0.9364, -0.7622,  0.7517,  0.8241,\n",
      "          0.6484, -0.7409, -0.8043,  0.8486, -0.3270,  0.7394, -0.9655, -0.8375,\n",
      "         -0.4116, -0.0213, -0.4419, -0.9021, -0.8633,  0.6484,  0.8442, -0.0075,\n",
      "          0.9237, -0.8946, -0.9126, -0.7234,  0.9336, -0.0032, -0.8876,  0.5668,\n",
      "          0.7643, -0.9399,  0.9520,  0.8163, -0.9074,  0.8824, -0.0571, -0.8952,\n",
      "         -0.9411,  0.9370, -0.9421,  0.5225,  0.3039,  0.9505,  0.8541,  0.9092,\n",
      "         -0.8648,  0.8545, -0.7344,  0.8958,  0.9592,  0.6203,  0.9080,  0.0415,\n",
      "         -0.9120,  0.2949,  0.9180, -0.9235, -0.8646, -0.1513,  0.3003, -0.7236,\n",
      "          0.1011,  0.9349, -0.7686, -0.8321,  0.8599, -0.8982, -0.9394,  0.9132,\n",
      "          0.4026,  0.5501,  0.9313, -0.9104,  0.8664, -0.0157,  0.9230, -0.9348,\n",
      "         -0.6024,  0.3617,  0.7102,  0.3783,  0.9083,  0.9204,  0.9442, -0.7189,\n",
      "          0.9407,  0.4892,  0.9174, -0.5663, -0.6324, -0.7260,  0.6909,  0.9679,\n",
      "          0.9625, -0.5346, -0.8391,  0.9468,  0.7944,  0.5043, -0.1009, -0.9703,\n",
      "          0.9267, -0.0780,  0.3834,  0.6234, -0.9261,  0.8249, -0.9312, -0.6229,\n",
      "         -0.8443,  0.8005, -0.3518,  0.9231,  0.9207,  0.9443,  0.8111, -0.9530,\n",
      "          0.9275,  0.0298, -0.8262, -0.6245,  0.9380,  0.6245, -0.5522,  0.6369,\n",
      "          0.9122,  0.9521, -0.6275,  0.5342,  0.0438,  0.6407,  0.5023,  0.9227,\n",
      "          0.4988,  0.3001,  0.9290,  0.7555, -0.8777, -0.9615,  0.7393,  0.7521,\n",
      "          0.4154,  0.9627, -0.7893,  0.8038,  0.9428, -0.4511, -0.0362, -0.2598,\n",
      "          0.0159,  0.1406,  0.4937,  0.4351,  0.5316, -0.9096, -0.9051,  0.0515,\n",
      "         -0.8954, -0.9084, -0.3198,  0.8460,  0.8972,  0.8789,  0.0014,  0.9582,\n",
      "         -0.9012, -0.8863,  0.9037,  0.1938,  0.8355, -0.6972,  0.8905,  0.9534,\n",
      "          0.2107,  0.5049, -0.9387, -0.7600, -0.9061, -0.9502, -0.0081, -0.9196,\n",
      "         -0.8195,  0.0489,  0.3990,  0.7317, -0.8240, -0.5181, -0.0454,  0.0215,\n",
      "          0.8402, -0.6998,  0.8516,  0.2863, -0.8246, -0.9624,  0.0259,  0.4900,\n",
      "         -0.6030, -0.8088, -0.9358, -0.6502, -0.7431, -0.5907, -0.5223, -0.1334,\n",
      "          0.8094, -0.6562,  0.8715, -0.4621, -0.8301,  0.3937, -0.8643,  0.5434,\n",
      "          0.3503, -0.7083,  0.5814,  0.7330, -0.4296, -0.9077, -0.9078, -0.9718,\n",
      "          0.9640,  0.3906,  0.8785,  0.6919, -0.9295,  0.0940,  0.4989, -0.8747,\n",
      "          0.7955,  0.7242,  0.8476, -0.9083,  0.6682,  0.9036,  0.0162, -0.5133,\n",
      "         -0.9446, -0.8102,  0.9813,  0.5234,  0.6895,  0.8091, -0.8560, -0.9017,\n",
      "          0.1673,  0.8996,  0.0289, -0.4581, -0.9003,  0.4672,  0.9173, -0.8879,\n",
      "         -0.7248, -0.9403,  0.3426,  0.2516, -0.9224, -0.9453,  0.9738,  0.5616,\n",
      "          0.9058, -0.8701,  0.9186,  0.7613,  0.3678,  0.2124, -0.5984,  0.3086]],\n",
      "       device='cuda:0'), 'raw_cls_feats': tensor([[ 2.7024e-01,  8.4886e-01,  3.5035e-01,  5.3281e-02,  5.2474e-02,\n",
      "         -1.7046e-01,  7.3329e-02,  3.0590e-02,  6.7037e-02, -3.7755e-01,\n",
      "         -8.7652e-01,  1.3844e-01,  2.5090e-01, -3.3451e-01, -1.6991e-01,\n",
      "         -2.3502e-02, -6.9722e-02, -1.1445e-01, -1.7391e-01,  3.5070e-01,\n",
      "         -1.2979e+00,  2.7135e-01, -6.4320e-02, -9.8884e-01,  3.2600e-02,\n",
      "         -4.4981e-01,  1.7270e-01,  3.7485e-01, -8.4396e-01, -6.4098e-02,\n",
      "          1.6703e-01,  3.6598e-01, -4.2784e-02, -1.1087e-01,  1.1336e-02,\n",
      "         -2.0030e+00, -7.8494e-01, -9.4766e-02, -1.2019e-01,  1.6362e-01,\n",
      "         -1.2572e-01,  2.2219e-01, -3.8874e-02,  6.9456e-01, -6.6659e-01,\n",
      "         -7.5572e-02, -6.5935e-02, -2.7468e-02,  1.0221e+00, -2.5591e-01,\n",
      "          1.8912e-01, -5.2756e-01,  4.2142e-02,  1.3391e+00,  6.7435e-02,\n",
      "          9.3807e-01,  1.4467e+00,  4.8933e-01,  2.6360e-01, -6.8080e-02,\n",
      "          1.7264e-01,  7.1070e-02,  3.0559e-01,  1.0487e+00, -1.0531e-01,\n",
      "          1.4899e-01, -1.4601e-01,  7.0311e-02, -6.1047e-01,  3.2517e-01,\n",
      "          9.6615e-02, -4.9635e-01,  3.9653e-01, -8.1497e-01,  4.3536e-01,\n",
      "         -1.7965e-01, -1.8054e-02, -7.7346e-02,  3.7056e-01, -1.1527e-01,\n",
      "         -5.1328e-02,  2.2571e-01, -1.4052e-01,  3.9916e-01, -1.5368e+00,\n",
      "         -2.2687e-01,  6.8785e-01,  4.7555e-03,  4.0235e-01, -3.9818e-01,\n",
      "          4.5255e-01,  1.8249e-01,  2.4254e-02,  5.4363e-01,  3.1668e-01,\n",
      "          1.4741e-01, -1.2045e+00,  5.6026e-01,  1.8129e-02, -5.2342e-01,\n",
      "         -2.5647e-01, -5.9585e-01,  1.6685e-01, -2.0819e-01, -2.7393e-01,\n",
      "         -5.4547e-02,  8.3671e-01,  1.0122e+00,  3.0082e-01, -4.0947e-01,\n",
      "         -3.5765e-01, -8.6501e-04,  1.6294e-01, -4.0080e-01, -8.3902e-01,\n",
      "          2.2061e-01, -4.1820e-02, -4.1544e-01, -2.5201e+00, -9.8932e-02,\n",
      "         -5.8175e-01, -7.2491e-02, -8.2113e-01, -1.3048e-01, -4.9790e-01,\n",
      "         -2.5302e-01,  9.9828e-02,  3.8401e-01, -1.0704e-01, -1.3460e-01,\n",
      "         -5.2490e-01,  1.6422e-01, -7.2538e-02,  3.1729e-01, -1.8784e-01,\n",
      "          8.4847e-01,  2.7782e-01,  3.9456e-01,  7.3581e-01, -4.6038e-01,\n",
      "         -1.2405e-01,  3.6507e-01,  1.0595e+00, -3.3720e-01, -1.7847e-01,\n",
      "          6.9445e-02,  5.5660e-02,  6.6612e-01, -1.5342e-01, -1.0245e-01,\n",
      "         -4.1698e-01, -4.7990e-01, -4.3741e-02,  7.5446e-01, -8.5839e-01,\n",
      "         -2.9759e-01,  7.4105e-02,  3.6936e-01,  2.2517e-01,  2.0445e-01,\n",
      "         -2.2520e-01, -7.0262e-01,  1.7491e+00,  1.5410e-01,  2.4333e-01,\n",
      "          1.1808e-01,  2.0031e-01, -4.1765e-01, -4.4570e-02, -7.5414e-02,\n",
      "         -1.7943e-01,  2.9114e-01, -5.1989e-01,  5.7214e-02,  3.4968e-03,\n",
      "         -5.4809e-02,  9.5891e-02, -1.0574e-01,  1.3325e-01,  6.3144e-01,\n",
      "          5.8261e-02, -5.3787e-01,  4.9443e-01,  8.5900e-01,  3.4082e-02,\n",
      "          8.8916e-04, -2.6900e-02,  2.4115e-01,  3.4658e-01, -6.3444e-02,\n",
      "          1.6090e-01,  6.9500e-01, -3.7949e-01,  1.2788e-01,  1.5003e-01,\n",
      "         -4.2237e-02, -2.5673e-01, -3.3161e-01, -2.3348e-01,  5.5662e-01,\n",
      "         -4.5105e-01,  1.1752e-01,  5.5362e-01,  1.0310e+00,  5.0748e-03,\n",
      "         -1.2152e+00, -4.7172e-01,  1.2711e-01,  6.1709e-02,  4.8978e-01,\n",
      "          2.5862e-01, -1.6091e-01, -2.9285e-01, -2.4275e-01,  3.7013e-01,\n",
      "         -6.4637e-01,  4.7067e-01, -1.3941e-01,  8.2075e-02, -4.9278e-02,\n",
      "         -2.3442e-01,  2.8614e-01, -2.1160e-01, -1.1124e+00,  9.2892e-01,\n",
      "          3.1191e-01,  8.5168e-02,  1.1483e-01,  8.2778e-01,  3.2094e-01,\n",
      "         -4.2826e-01, -4.3217e-01,  9.0470e-02,  1.4781e-01,  6.4168e-01,\n",
      "         -4.0168e-01, -3.3907e-01,  1.7142e-01, -1.4673e-01,  8.6523e-02,\n",
      "         -4.7792e-03, -1.9192e-01, -3.2239e-01, -2.2403e-01, -2.6295e-02,\n",
      "         -1.5122e-01,  6.5477e-02,  1.5560e-01,  1.1998e-01,  1.4690e-01,\n",
      "          5.6724e-01, -9.5334e-01,  1.0883e-01, -4.6437e-01, -2.8476e-01,\n",
      "         -2.8313e-01,  5.9793e-01, -1.3925e+00,  5.2537e-02,  1.7755e-01,\n",
      "          4.5361e-02,  1.0916e-01, -1.9150e-01, -1.3015e-01, -5.1746e-01,\n",
      "         -5.5892e-01, -1.6779e-01,  9.6007e-01,  1.4014e+00, -3.8179e-01,\n",
      "         -2.3898e-01,  9.5665e-02,  5.4185e-01,  7.8480e-02, -7.4198e-01,\n",
      "          3.7485e-02, -1.1244e-01,  5.6840e-01, -1.5983e-01,  3.1847e-01,\n",
      "         -2.8043e-01,  1.3540e-01, -9.7404e-02, -7.2468e-01,  9.9290e-01,\n",
      "          6.1460e-01,  3.0556e-01, -9.4487e-01,  1.0193e+00, -1.0106e-01,\n",
      "         -1.5386e+00,  3.4158e-01,  4.2114e-01, -3.2881e-01, -1.3621e-02,\n",
      "         -2.3702e-01, -5.9156e-01, -6.2746e-02, -9.9363e-01, -3.5500e-03,\n",
      "         -1.1910e-02, -1.5673e-01, -1.3858e-01, -1.2728e-01,  3.2764e-01,\n",
      "          1.5330e-01,  3.4395e-01, -1.7346e+00,  4.2143e-01,  2.9009e-01,\n",
      "         -2.0314e-01, -1.6999e-01, -5.6043e-01,  1.5592e+00,  9.0695e-01,\n",
      "         -2.3074e-01,  2.6335e-01,  1.0063e-02,  3.3536e-01, -1.0068e+00,\n",
      "          3.3994e-01,  3.1071e-01,  5.5808e-04, -1.8070e-01,  3.1451e-01,\n",
      "          3.3578e-01, -2.1316e-02,  1.2061e-01, -2.9430e-01,  1.0108e-01,\n",
      "          3.9898e-02,  3.1339e-01,  4.6233e-01, -6.2455e-02, -4.8597e-01,\n",
      "         -1.1414e-01, -2.3682e-01,  3.2588e-01,  2.1854e-01,  2.1128e-01,\n",
      "         -6.2360e-01, -1.0117e-01,  4.4842e-01, -7.2232e-01,  8.1424e-02,\n",
      "         -1.1417e-01, -1.5510e-01,  1.9553e+00,  1.4658e-01,  8.1736e-01,\n",
      "         -1.5598e-01, -1.1353e-01,  7.0220e-01,  3.5282e-03, -2.4982e-01,\n",
      "         -2.7995e+00, -1.3884e+00,  9.2986e-01, -3.0575e-01,  4.1183e-01,\n",
      "         -5.4223e-01, -2.7192e-01,  3.2496e-01, -2.3899e-01, -3.1130e-02,\n",
      "         -1.0525e+00,  2.2014e+00, -7.1531e-01,  3.3892e-02, -3.3486e-01,\n",
      "          6.7763e-01,  2.0083e-01, -1.8894e-01, -1.0283e+00, -9.1044e-02,\n",
      "          4.8329e-03, -1.0640e-01,  4.0725e-01, -2.3403e-01,  6.0655e-01,\n",
      "          3.4804e-01, -3.5779e-01, -1.3233e-02, -1.0694e-01,  6.3256e-01,\n",
      "          1.0990e-01,  2.3830e-02,  3.6173e-01,  5.7738e-01, -1.9464e-01,\n",
      "          4.8241e-01, -2.5946e-02, -1.9019e-01, -7.8480e-01,  6.8758e-02,\n",
      "         -4.7497e-02, -1.3609e+00,  6.1587e-01,  5.8165e-02, -1.9913e-01,\n",
      "          9.7329e-01,  1.0289e-02,  1.6345e-01, -1.8136e-01, -2.1239e-01,\n",
      "         -7.4947e-02,  3.7483e-01, -1.4315e+00,  9.2524e-01,  5.4806e-02,\n",
      "          4.1944e-01,  2.0483e-02,  7.2994e-01,  2.1012e+00, -1.2746e+00,\n",
      "         -2.7914e-01, -4.1034e-01,  1.5823e-01, -1.2046e-01,  2.5009e-01,\n",
      "         -2.6848e-01,  9.3349e-03, -6.9723e-01, -1.1454e+00,  2.8049e-01,\n",
      "          1.7298e-01,  1.3442e-02, -3.6490e-01,  2.7565e-01, -5.0091e-01,\n",
      "          5.6422e-01, -4.3578e-01,  1.3744e+00,  2.6284e-01, -3.6305e-01,\n",
      "          1.8917e-01,  6.6354e-01, -6.3040e-01, -7.2850e-01, -8.3665e-02,\n",
      "         -2.6176e-01,  7.0304e-02,  1.4631e-01, -5.3198e-01,  6.2124e-01,\n",
      "          4.9013e-01,  7.6268e-02,  3.4316e-02, -1.7787e-01, -1.4833e-01,\n",
      "          1.1812e+00,  1.1317e+00, -4.8711e-01, -1.6038e-01,  2.3041e-01,\n",
      "          1.3259e+00,  9.8977e-02,  8.9631e-02,  1.8019e-01,  3.3693e-01,\n",
      "         -3.6393e-02,  1.1927e-01, -2.7777e-01, -9.0305e-02, -5.1156e-02,\n",
      "         -2.2291e-01, -8.1878e-01,  7.2951e-01,  2.9266e-01,  2.8071e+00,\n",
      "          2.3238e-01,  1.9978e-01,  4.6962e-01, -6.9338e-01,  2.1595e-02,\n",
      "          5.8179e-01, -8.0825e-03,  4.0437e-02,  4.6131e-01, -8.8928e-02,\n",
      "          1.0060e+00, -3.3248e-01, -4.9280e-01,  7.4792e-01,  1.4398e+00,\n",
      "         -1.4240e-01,  5.4036e-01,  3.3272e-01, -1.4869e-01, -3.5158e-01,\n",
      "         -2.0619e+00, -1.1094e-01, -3.5929e-01, -9.2581e-03, -6.2078e-01,\n",
      "         -3.0006e-01,  1.2676e-01, -3.4668e-01,  4.0886e-01, -1.8963e-01,\n",
      "         -3.1097e-01,  3.9580e-01, -8.1414e-02,  1.1727e-01, -1.0543e-01,\n",
      "         -1.1591e-01,  9.5239e-02,  1.2715e+00,  9.5719e-01, -1.0286e+00,\n",
      "         -1.2770e+00,  8.1440e-02, -1.8329e+00,  1.0241e-01, -3.5173e-01,\n",
      "         -5.2059e-01, -2.3979e-03, -1.6086e-01,  5.2218e-01,  1.0047e+00,\n",
      "          8.4269e-01,  7.7826e-02,  1.0640e-01, -3.7783e-02, -1.3345e+00,\n",
      "          5.3439e-01,  9.4980e-02,  1.7555e+00, -1.7011e-01,  6.6691e-02,\n",
      "          6.1246e-02,  5.6022e-01,  1.3658e-01, -1.5076e+00,  1.5500e-01,\n",
      "         -2.7122e-01, -2.7139e-01,  1.8960e-01, -1.3290e-01, -8.1194e-02,\n",
      "          2.3106e-02, -6.0200e-01,  2.4592e-01,  9.4521e-02, -3.6338e-01,\n",
      "          4.7547e-01, -1.4175e+00, -3.1754e-01,  2.4655e-02,  1.7531e+00,\n",
      "          2.2224e-01, -6.8889e-02,  1.7817e-01, -2.8154e-01,  1.2842e-01,\n",
      "         -1.1765e-01, -2.4398e-01,  6.9239e-01,  4.9469e-03, -1.0554e-01,\n",
      "         -2.1135e-01, -8.2615e-01, -1.2064e+00, -9.0425e-02, -3.6638e-01,\n",
      "         -1.1402e-01,  3.5683e-01, -4.8989e-01, -3.2952e-01, -1.4446e-01,\n",
      "          1.1521e-01,  5.4473e-01,  4.6421e-01, -4.7061e-01,  4.1033e-02,\n",
      "          3.0311e-02,  3.8718e-01,  3.9273e-02, -4.2830e-02, -2.2708e-02,\n",
      "          1.9289e+00,  2.8577e-02,  3.5952e-01,  4.2292e-02, -1.2712e+00,\n",
      "          4.9575e-01, -1.7472e-01,  6.2497e-01,  7.0061e-01,  1.0168e+00,\n",
      "          2.0898e-01,  2.9583e-01,  2.6145e+00,  7.3840e-01, -4.0931e-02,\n",
      "          1.6071e-01, -1.3981e+00, -6.6715e-02, -1.3173e-01, -1.1371e-01,\n",
      "          3.8258e-01,  1.4547e-01, -1.7297e-01,  3.8544e-02, -3.1107e-01,\n",
      "         -1.8706e+00, -2.0439e-01, -1.0771e-01,  3.1944e-01,  4.9499e-02,\n",
      "         -1.0994e-01,  1.5210e-01, -1.4176e+00,  5.2413e-02, -8.5459e-01,\n",
      "         -9.9805e-01,  1.9167e+00, -6.7263e-03,  2.3618e+00, -2.4710e-01,\n",
      "         -1.2896e-01,  3.7116e-01,  8.9034e-01, -6.4879e-02,  4.0245e-01,\n",
      "          3.8369e-01, -3.5353e-01,  5.1265e-01, -3.5775e-01,  6.3312e-02,\n",
      "         -1.3479e+00, -1.6700e-01, -2.2919e-01, -1.7324e-01, -3.7457e-01,\n",
      "         -1.0357e-01, -1.8559e-01, -5.9229e-01, -1.9978e-01,  4.4437e-01,\n",
      "         -8.8195e-01,  6.1009e-01,  5.7204e-01, -1.4240e+00, -3.9134e-01,\n",
      "          4.3413e-01,  5.6744e-01, -5.3973e-01,  1.3536e-01, -1.7571e-02,\n",
      "          4.3265e-01, -2.3575e+00, -2.0904e-01, -2.3189e+00, -6.9198e-01,\n",
      "          4.8116e-02,  4.4486e-01, -8.9616e-02, -3.0280e-01, -2.8890e-02,\n",
      "          1.9719e-01, -1.6125e+00, -1.0723e-02, -1.2308e+00,  2.7813e-02,\n",
      "          7.9382e-01, -3.8642e-01,  1.1324e-02,  3.2542e-02,  3.3886e-02,\n",
      "          8.7939e-02,  3.2446e-02, -4.3876e-01, -5.7848e-01,  2.2803e-01,\n",
      "         -5.0407e-02,  6.0831e-01, -1.8474e-01,  2.5290e+00,  4.7034e-01,\n",
      "         -7.4563e-01,  1.8814e-01,  5.8178e-02,  1.7588e-01, -2.3231e-01,\n",
      "         -2.6213e-01, -3.2092e-01,  3.5052e-01,  2.3856e-02, -9.3220e-02,\n",
      "         -1.4070e+00,  8.7897e-01, -1.7089e-01,  1.5757e-01,  6.0234e-01,\n",
      "          1.0688e-01, -5.8827e-02,  4.0119e-01, -8.5685e-02, -2.9215e-01,\n",
      "          3.3505e-02,  5.2877e-01,  8.5433e-02, -1.3682e-01,  5.6899e-02,\n",
      "          3.0420e-02, -1.6028e+00,  1.9255e-01,  1.2622e-01, -9.5260e-01,\n",
      "          2.0320e-01,  2.3399e-01,  2.6022e-01, -4.4882e-02, -3.5379e-01,\n",
      "         -4.8428e-01,  7.3951e-01,  3.5998e-01, -3.1704e-02,  6.6309e-01,\n",
      "          1.2429e-01,  1.0664e-01, -4.8499e-01, -1.4012e+00,  6.6858e-01,\n",
      "         -5.0829e-01,  3.4053e-02, -7.1859e-02,  2.4280e-01,  1.2617e-01,\n",
      "          3.1691e-01,  5.0482e-01, -1.4471e-01,  5.6196e-01, -1.0742e+00,\n",
      "         -3.1774e+00, -5.2434e-01, -7.6493e-01, -3.8002e-01, -7.4135e-02,\n",
      "         -1.2321e-01, -4.9928e-01,  3.1236e-01,  4.7799e-01,  9.0799e-01,\n",
      "         -6.3907e-02, -3.8825e-01,  1.3708e-01, -1.9597e-01, -6.9311e-01,\n",
      "         -2.2167e-01,  8.6342e-02,  5.5120e-03,  1.1685e+00, -1.1648e-01,\n",
      "          2.3934e-01,  1.8242e+00, -2.1611e-01, -2.9277e-01,  2.9649e-01,\n",
      "         -2.1038e-01, -2.2648e-01, -7.3345e-02,  1.4272e+00, -1.9541e-01,\n",
      "         -7.2778e-02,  5.3655e-01,  8.1853e-02]], device='cuda:0'), 'image_labels': None, 'image_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0'), 'patch_index': (tensor([[[ 1,  8],\n",
      "         [ 2, 14],\n",
      "         [ 9,  8],\n",
      "         [ 3,  9],\n",
      "         [ 9,  3],\n",
      "         [ 7,  9],\n",
      "         [ 8,  1],\n",
      "         [ 4, 14],\n",
      "         [ 0,  5],\n",
      "         [ 6,  5],\n",
      "         [ 1, 14],\n",
      "         [ 2, 17],\n",
      "         [ 9, 10],\n",
      "         [10,  8],\n",
      "         [ 9, 13],\n",
      "         [ 9, 14],\n",
      "         [ 7, 15],\n",
      "         [ 7, 14],\n",
      "         [ 9,  0],\n",
      "         [ 9,  5],\n",
      "         [ 3,  8],\n",
      "         [ 5, 14],\n",
      "         [ 1,  5],\n",
      "         [10,  7],\n",
      "         [ 5, 15],\n",
      "         [10,  6],\n",
      "         [ 4,  8],\n",
      "         [ 4,  2],\n",
      "         [ 9, 12],\n",
      "         [ 8,  2],\n",
      "         [ 0,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  0],\n",
      "         [ 0,  3],\n",
      "         [ 5, 11],\n",
      "         [ 9,  6],\n",
      "         [ 6,  0],\n",
      "         [10, 14],\n",
      "         [ 2, 11],\n",
      "         [ 8, 18],\n",
      "         [ 6,  1],\n",
      "         [ 2, 16],\n",
      "         [ 0, 15],\n",
      "         [ 5, 17],\n",
      "         [ 6,  9],\n",
      "         [10,  9],\n",
      "         [ 9, 11],\n",
      "         [ 1, 13],\n",
      "         [ 3, 11],\n",
      "         [ 6,  7],\n",
      "         [ 3, 16],\n",
      "         [ 4, 17],\n",
      "         [ 4, 13],\n",
      "         [ 1, 17],\n",
      "         [ 7,  0],\n",
      "         [ 9, 18],\n",
      "         [ 3,  7],\n",
      "         [ 0, 17],\n",
      "         [ 3, 12],\n",
      "         [ 2, 10],\n",
      "         [ 0,  8],\n",
      "         [ 8, 10],\n",
      "         [ 8, 12],\n",
      "         [ 4,  3],\n",
      "         [ 6,  6],\n",
      "         [ 7, 10],\n",
      "         [ 5,  3],\n",
      "         [ 5,  0],\n",
      "         [10,  1],\n",
      "         [ 9,  4],\n",
      "         [ 2,  6],\n",
      "         [ 3,  0],\n",
      "         [ 0, 14],\n",
      "         [ 8, 14],\n",
      "         [ 6, 17],\n",
      "         [ 6, 14],\n",
      "         [ 5,  6],\n",
      "         [10, 17],\n",
      "         [ 9,  2],\n",
      "         [ 4,  9],\n",
      "         [ 2,  1],\n",
      "         [ 5,  9],\n",
      "         [ 7, 11],\n",
      "         [ 1,  4],\n",
      "         [ 3, 10],\n",
      "         [ 3, 15],\n",
      "         [ 4, 18],\n",
      "         [ 1,  7],\n",
      "         [ 4,  6],\n",
      "         [ 5, 12],\n",
      "         [ 6,  3],\n",
      "         [ 7,  2],\n",
      "         [ 0,  4],\n",
      "         [ 8, 13],\n",
      "         [ 2,  7],\n",
      "         [ 4,  7],\n",
      "         [ 6, 11],\n",
      "         [ 7, 13],\n",
      "         [ 4, 16],\n",
      "         [ 7,  1],\n",
      "         [ 8, 15],\n",
      "         [ 4,  4],\n",
      "         [ 3, 17],\n",
      "         [ 1,  0],\n",
      "         [ 8,  0],\n",
      "         [ 5, 18],\n",
      "         [ 8,  8],\n",
      "         [ 1,  1],\n",
      "         [ 0, 10],\n",
      "         [ 8,  5],\n",
      "         [ 0, 18],\n",
      "         [ 3,  4],\n",
      "         [ 9,  7],\n",
      "         [ 2,  0],\n",
      "         [10, 16],\n",
      "         [ 8, 17],\n",
      "         [10,  4],\n",
      "         [ 1, 10],\n",
      "         [ 3,  2],\n",
      "         [ 5, 16],\n",
      "         [ 3,  6],\n",
      "         [ 6, 10],\n",
      "         [ 2,  2],\n",
      "         [ 3, 18],\n",
      "         [10,  0],\n",
      "         [10, 10],\n",
      "         [ 7,  8],\n",
      "         [ 1,  2],\n",
      "         [ 8,  4],\n",
      "         [ 9,  1],\n",
      "         [ 5,  4],\n",
      "         [ 7, 12],\n",
      "         [ 0,  1],\n",
      "         [ 5,  8],\n",
      "         [ 3, 13],\n",
      "         [ 0,  7],\n",
      "         [ 7, 18],\n",
      "         [ 2,  3],\n",
      "         [ 2,  5],\n",
      "         [ 5,  5],\n",
      "         [ 7,  3],\n",
      "         [ 6, 18],\n",
      "         [ 8, 16],\n",
      "         [ 0, 16],\n",
      "         [ 6,  8],\n",
      "         [ 4, 11],\n",
      "         [ 2,  4],\n",
      "         [ 2, 15],\n",
      "         [ 8,  9],\n",
      "         [ 5, 13],\n",
      "         [ 3, 14],\n",
      "         [ 2, 12],\n",
      "         [ 4, 10],\n",
      "         [ 2, 18],\n",
      "         [ 9, 15],\n",
      "         [ 1, 16],\n",
      "         [ 7,  7],\n",
      "         [ 4,  5],\n",
      "         [ 7,  4],\n",
      "         [ 7,  6],\n",
      "         [ 7, 17],\n",
      "         [ 6, 15],\n",
      "         [ 6, 16],\n",
      "         [ 1,  3],\n",
      "         [ 4,  1],\n",
      "         [ 8,  6],\n",
      "         [ 1,  6],\n",
      "         [ 9, 16],\n",
      "         [ 8,  3],\n",
      "         [ 0, 12],\n",
      "         [ 0,  0],\n",
      "         [ 4, 15],\n",
      "         [ 5,  7],\n",
      "         [ 3,  5],\n",
      "         [ 1,  9],\n",
      "         [ 9, 17],\n",
      "         [ 5, 10],\n",
      "         [ 6, 13],\n",
      "         [ 8, 11],\n",
      "         [ 5,  2],\n",
      "         [ 1, 11],\n",
      "         [ 0,  9],\n",
      "         [10,  2],\n",
      "         [ 3,  1],\n",
      "         [ 2,  8],\n",
      "         [ 6,  2],\n",
      "         [10, 12],\n",
      "         [ 4, 12],\n",
      "         [ 1, 12],\n",
      "         [10,  3],\n",
      "         [10, 18],\n",
      "         [10,  5],\n",
      "         [10, 15],\n",
      "         [ 2, 13],\n",
      "         [ 0, 13],\n",
      "         [ 9,  9],\n",
      "         [ 2,  9],\n",
      "         [ 0, 11],\n",
      "         [ 7, 16],\n",
      "         [ 7,  5],\n",
      "         [ 8,  7],\n",
      "         [ 1, 15],\n",
      "         [ 6,  4],\n",
      "         [ 0,  6],\n",
      "         [ 1, 18],\n",
      "         [10, 13],\n",
      "         [10, 11],\n",
      "         [ 6, 12],\n",
      "         [ 5,  1]]]), (11, 19)), 'cls_output': tensor([[0.3804]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2814811/3734256495.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img)\n"
     ]
    }
   ],
   "source": [
    "idx = 64\n",
    "sensor =  torch.tensor(sensor_test_list[idx]).unsqueeze(0).unsqueeze(0)\n",
    "out = infer(image_test_list[idx],sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb Cell 60\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m876\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m sensor \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mtensor(sensor_test_list[idx])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal-gpu-server-3/home/junsheng/ViLT/my_vilt_tianhang_corn.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m out \u001b[39m=\u001b[39m infer(image_test_list[idx],sensor)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "idx = 876\n",
    "sensor =  torch.tensor(sensor_test_list[idx]).unsqueeze(0).unsqueeze(0)\n",
    "out = infer(image_test_list[idx],sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1817\n",
    "sensor =  torch.tensor(sensor_test_list[idx]).unsqueeze(0).unsqueeze(0)\n",
    "out = infer(image_test_list[idx],sensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch_junsheng_39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29fd19f11c6b89e267402bb3227bc1208f7e2c9719aa03eba13baf7684fe5867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
