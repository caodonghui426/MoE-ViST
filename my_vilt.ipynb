{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junsheng/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from vilt.modules import heads, objectives\n",
    "import vilt.modules.vision_transformer as vit\n",
    "import torch.nn.functional as F\n",
    "from typing import OrderedDict\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vilt.transforms import pixelbert_transform\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__module__': '__main__',\n",
       " 'exp_name': 'vilt',\n",
       " 'seed': 101,\n",
       " 'batch_size': 4096,\n",
       " 'train_batch_size': 2,\n",
       " 'valid_batch_size': 4,\n",
       " 'device': device(type='cuda', index=0),\n",
       " 'train_transform_keys': ['pixelbert'],\n",
       " 'val_transform_keys': ['pixelbert'],\n",
       " 'img_size': 384,\n",
       " 'max_image_len': -1,\n",
       " 'patch_size': 32,\n",
       " 'draw_false_image': 1,\n",
       " 'image_only': False,\n",
       " 'vqav2_label_size': 3129,\n",
       " 'max_text_len': 40,\n",
       " 'tokenizer': 'bert-base-uncased',\n",
       " 'vocab_size': 30522,\n",
       " 'whole_word_masking': False,\n",
       " 'mlm_prob': 0.15,\n",
       " 'draw_false_text': 0,\n",
       " 'vit': 'vit_base_patch32_384',\n",
       " 'hidden_size': 768,\n",
       " 'num_heads': 12,\n",
       " 'num_layers': 12,\n",
       " 'mlp_ratio': 4,\n",
       " 'drop_rate': 0.1,\n",
       " 'optim_type': 'adamw',\n",
       " 'learning_rate': 0.0001,\n",
       " 'weight_decay': 0.01,\n",
       " 'decay_power': 1,\n",
       " 'max_epoch': 3,\n",
       " 'max_steps': 25000,\n",
       " 'warmup_steps': 2500,\n",
       " 'end_lr': 0,\n",
       " 'lr_mult': 1,\n",
       " 'get_recall_metric': False,\n",
       " 'resume_from': None,\n",
       " 'fast_dev_run': False,\n",
       " 'val_check_interval': 1.0,\n",
       " 'test_only': False,\n",
       " 'data_root': '',\n",
       " 'log_dir': 'result',\n",
       " 'per_gpu_batchsize': 0,\n",
       " 'num_gpus': 1,\n",
       " 'num_nodes': 1,\n",
       " 'load_path': 'weights/vilt_200k_mlm_itm.ckpt',\n",
       " 'num_workers': 1,\n",
       " 'precision': 16,\n",
       " '__dict__': <attribute '__dict__' of 'config' objects>,\n",
       " '__weakref__': <attribute '__weakref__' of 'config' objects>,\n",
       " '__doc__': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class config:\n",
    "    exp_name = \"vilt\"\n",
    "    seed = 101\n",
    "    batch_size = 4096  # this is a desired batch size; pl trainer will accumulate gradients when per step batch is smaller.\n",
    "    train_batch_size = 2\n",
    "    valid_batch_size = 4\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "\n",
    "    # Image setting\n",
    "    train_transform_keys = [\"pixelbert\"]\n",
    "    val_transform_keys = [\"pixelbert\"]\n",
    "    img_size = 384\n",
    "    max_image_len = -1\n",
    "    patch_size = 32\n",
    "    draw_false_image = 1\n",
    "    image_only = False\n",
    "\n",
    "    # Text Setting\n",
    "    vqav2_label_size = 3129\n",
    "    max_text_len = 40\n",
    "    tokenizer = \"bert-base-uncased\"\n",
    "    vocab_size = 30522 # vocabulary词汇数量\n",
    "    whole_word_masking = False\n",
    "    mlm_prob = 0.15\n",
    "    draw_false_text = 0\n",
    "\n",
    "    # Transformer Setting\n",
    "    vit = \"vit_base_patch32_384\"\n",
    "    hidden_size = 768  # 嵌入向量大小\n",
    "    num_heads = 12\n",
    "    num_layers = 12\n",
    "    mlp_ratio = 4\n",
    "    drop_rate = 0.1\n",
    "\n",
    "    # Optimizer Setting\n",
    "    optim_type = \"adamw\"\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 0.01\n",
    "    decay_power = 1\n",
    "    max_epoch = 3\n",
    "    max_steps = 25000\n",
    "    warmup_steps = 2500\n",
    "    end_lr = 0\n",
    "    lr_mult = 1  # multiply lr for downstream heads\n",
    "\n",
    "    # Downstream Setting\n",
    "    get_recall_metric = False\n",
    "\n",
    "    # PL Trainer Setting\n",
    "    resume_from = None\n",
    "    fast_dev_run = False\n",
    "    val_check_interval = 1.0\n",
    "    test_only = False\n",
    "\n",
    "    # below params varies with the environment\n",
    "    data_root = \"\"\n",
    "    log_dir = \"result\"\n",
    "    per_gpu_batchsize = 0  # you should define this manually with per_gpu_batch_size=#\n",
    "    num_gpus = 1\n",
    "    num_nodes = 1\n",
    "    load_path = \"weights/vilt_200k_mlm_itm.ckpt\"\n",
    "    # load_path = \"save_model_dict.pt\"\n",
    "    num_workers = 1\n",
    "    precision = 16\n",
    "\n",
    "config = vars(config)\n",
    "config = dict(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed=0):\n",
    "    import torch\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import random\n",
    "    torch.manual_seed(seed)  # 为CPU设置随机种子\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    if torch.cuda.is_available():\n",
    "        # torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.cuda.manual_seed(seed)  # 为当前GPU设置随机种子\n",
    "        torch.cuda.manual_seed_all(seed)  # 为所有GPU设置随机种子\n",
    "        #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "setup_seed(seed=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    \"a\":np.random.randn(500),\n",
    "    \"b\":np.random.randn(500),\n",
    "    \"c\":np.random.randn(500),\n",
    "    \"d\":np.random.randn(500),\n",
    "    \"image_path\":\"assets/vilt.png\",\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = test_df.a + 2*test_df.b + 3*test_df.c + 4*test_df.d\n",
    "test_df['sensor'] = test_df[['a','b','c','d','a','b','c','d','a','b']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()\n",
    "test_df.to_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"sensor\":[np.random.randn(10)]*10,\"image_path\":\"assets/vilt.png\",\"label\":np.random.randint(1,10+1)})\n",
    "df=test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((config[\"img_size\"],config[\"img_size\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    mean=[0.7136, 0.7118, 0.6788],\n",
    "    std=[0.3338, 0.3453, 0.3020],\n",
    "    \n",
    ")\n",
    "])\n",
    "\n",
    "def load_img(path):\n",
    "    img =  Image.open(path).convert('RGB')\n",
    "    img = myTransforms(img)\n",
    "    return img\n",
    "\n",
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, label=True, transforms=None):\n",
    "        self.df         = df\n",
    "        self.label      = label\n",
    "        self.sensors = df['sensor'].tolist()\n",
    "        self.img_paths  = df['image_path'].tolist()   \n",
    "        if self.label:\n",
    "            self.labels = df['label'].tolist()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        img = load_img(img_path)\n",
    "        sensor = self.sensors[index]\n",
    "        sensor = torch.tensor(sensor).unsqueeze(0) #[1,n]\n",
    "        if self.label:\n",
    "            label = self.labels[index]\n",
    "            return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n",
    "        else:\n",
    "            return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BuildDataset(df=df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['train_batch_size'],shuffle=True)\n",
    "valid_loader = DataLoader(train_dataset, batch_size=config['valid_batch_size'],shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 384, 384])\n",
      "torch.Size([2, 1, 10])\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_226713/3759876696.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n"
     ]
    }
   ],
   "source": [
    "img,sensor,label = next(iter(train_loader))\n",
    "print(img.shape)\n",
    "print(sensor.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sensorViLTransformerSS(nn.Module):\n",
    "\n",
    "    def __init__(self, config,sensor_class_n,output_class_n):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.sensor_linear = nn.Linear(sensor_class_n,config[\"hidden_size\"]) \n",
    "\n",
    "        self.token_type_embeddings = nn.Embedding(2, config[\"hidden_size\"])\n",
    "        self.token_type_embeddings.apply(objectives.init_weights)\n",
    "\n",
    "        # if self.config[\"load_path\"] == \"\":\n",
    "        self.transformer = getattr(vit, self.config[\"vit\"])(\n",
    "                pretrained=False, config=self.config\n",
    "            )\n",
    "       \n",
    "        self.dense = nn.Linear(config[\"hidden_size\"], config[\"hidden_size\"])\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "        self.pooler = heads.Pooler(config[\"hidden_size\"])\n",
    "\n",
    "        # self.pooler.apply(objectives.init_weights)\n",
    "        self.classifier = nn.Linear(config[\"hidden_size\"],output_class_n)\n",
    "        # ===================== Downstream ===================== #\n",
    "        # if (\n",
    "        #     self.config[\"load_path\"] != \"\"\n",
    "        #     and not self.config[\"test_only\"]\n",
    "        # ):\n",
    "        #     ckpt = torch.load(self.config[\"load_path\"], map_location=\"cpu\")\n",
    "        #     if isinstance(ckpt,OrderedDict):\n",
    "\n",
    "        #         state_dict = ckpt\n",
    "        #     else:\n",
    "        #         state_dict = ckpt[\"state_dict\"]\n",
    "        #     self.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        hs = self.config[\"hidden_size\"]\n",
    "\n",
    "        # vilt_utils.set_metrics(self) # 设定模型评价\n",
    "\n",
    "        # ===================== load downstream (test_only) ======================\n",
    "\n",
    "        if self.config[\"load_path\"] != \"\" and self.config[\"test_only\"]:\n",
    "            ckpt = torch.load(self.config[\"load_path\"], map_location=\"cpu\")\n",
    "            state_dict = ckpt[\"state_dict\"]\n",
    "            self.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        batch,\n",
    "        mask_image=False,\n",
    "        image_token_type_idx=1,\n",
    "        image_embeds=None,\n",
    "        image_masks=None,\n",
    "    ):\n",
    "        sensor = batch['sensor'].to(config['device'])\n",
    "        sensor_embeds = self.sensor_linear(sensor) # input[1,1,12]  output[1,1,768]\n",
    "        \n",
    "\n",
    "        if image_embeds is None and image_masks is None:\n",
    "            img = batch[\"image\"].to(config['device'])\n",
    "       \n",
    "            (\n",
    "                image_embeds, # torch.Size([1, 217, 768])\n",
    "                image_masks, # torch.Size([1, 217])\n",
    "                patch_index,\n",
    "                image_labels,\n",
    "            ) = self.transformer.visual_embed(\n",
    "                img,\n",
    "                max_image_len=self.config[\"max_image_len\"],\n",
    "                mask_it=mask_image,\n",
    "            )\n",
    "        else:\n",
    "            patch_index, image_labels = (\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "        # 用embedding对数据输入预处理，降低维度\n",
    "        image_embeds = image_embeds + self.token_type_embeddings(\n",
    "                torch.full_like(image_masks, image_token_type_idx)\n",
    "            )\n",
    "        # sensor_masks = batch['sensor_masks'] # 序列数量\n",
    "        batch_size = img.shape[0]\n",
    "        sensor_masks = torch.ones(batch_size,1).to(config['device']) # 序列数量\n",
    "        image_masks = image_masks.to(config['device'])\n",
    "        co_embeds = torch.cat([sensor_embeds, image_embeds], dim=1) # torch.Size([1, 240, 768]) ->240=217+23\n",
    "        co_masks = torch.cat([sensor_masks, image_masks], dim=1) # torch.Size([1, 240])\n",
    "\n",
    "        x = co_embeds.to(config['device'])\n",
    "\n",
    "        for i, blk in enumerate(self.transformer.blocks):\n",
    "            blk = blk.to(config['device'])\n",
    "            x, _attn = blk(x, mask=co_masks)\n",
    "\n",
    "        x = self.transformer.norm(x) # torch.Size([1, 240, 768])\n",
    "        sensor_feats, image_feats = ( # torch.Size([1, 23, 768]),torch.Size([1, 217, 768])\n",
    "            x[:, : sensor_embeds.shape[1]], # 后面字数输出23维\n",
    "            x[:, sensor_embeds.shape[1] :], # 前面图片输出217维\n",
    "        )\n",
    "        cls_feats = self.pooler(x) # torch.Size([1, 768])\n",
    "        # cls_feats = self.dense(x)\n",
    "        # cls_feats = self.activation(cls_feats)\n",
    "        cls_output = self.classifier(cls_feats)\n",
    "        # m = nn.Softmax(dim=1)\n",
    "        # cls_output = m(cls_output)\n",
    "\n",
    "        \n",
    "        ret = {\n",
    "           \"sensor_feats\":sensor_feats,\n",
    "            \"image_feats\": image_feats,\n",
    "            \"cls_feats\": cls_feats, # class features\n",
    "            \"raw_cls_feats\": x[:, 0],\n",
    "            \"image_labels\": image_labels,\n",
    "            \"image_masks\": image_masks,\n",
    "           \n",
    "            \"patch_index\": patch_index,\n",
    "\n",
    "            \"cls_output\":cls_output,\n",
    "        }\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = dict()\n",
    "        \n",
    "        ret.update(self.infer(batch))\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = sensorViLTransformerSS(config,sensor_class_n= 10,output_class_n = 1)\n",
    "model.to(config['device'])\n",
    "print(config['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.mse_loss #均方误差损失函数\n",
    "# criterion = F.mae_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (img, sensor,label) in pbar:         \n",
    "        # img = img.to(device, dtype=torch.float)\n",
    "        # sensor  = sensor.to(device, dtype=torch.float)\n",
    "        # label  = label.to(device, dtype=torch.float)\n",
    "        batch_size = img.size(0)\n",
    "        \n",
    "        batch = {\"image\":img,\"sensor\":sensor}\n",
    "\n",
    "        y_pred = model(batch)\n",
    "        label = label.to(config['device']).unsqueeze(1)\n",
    "        loss = criterion(y_pred['cls_output'], label)\n",
    "        \n",
    "        #一坨优化\n",
    "        optimizer.zero_grad()#每一次反向传播之前都要归零梯度\n",
    "        loss.backward()      #反向传播\n",
    "        optimizer.step()     #固定写法\n",
    "        scheduler.step()\n",
    "     \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    history = defaultdict(list)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=device, epoch=epoch)\n",
    "        \n",
    "        # val_loss, val_scores = valid_one_epoch(model, valid_loader, \n",
    "                                                #  device=CFG.device, \n",
    "                                                #  epoch=epoch)\n",
    "        # val_dice, val_jaccard = val_scores\n",
    "    \n",
    "        history['Train Loss'].append(train_loss)\n",
    "        # history['Valid Loss'].append(val_loss)\n",
    "        \n",
    "\n",
    "        \n",
    "        # deep copy the model\n",
    "        # if val_dice >= best_dice:\n",
    "            # print(f\"{c_}Valid Score Improved ({best_dice:0.4f} ---> {val_dice:0.4f})\")\n",
    "            # best_dice    = val_dice\n",
    "            # best_jaccard = val_jaccard\n",
    "            # best_epoch   = epoch\n",
    "            # run.summary[\"Best Dice\"]    = best_dice\n",
    "            # run.summary[\"Best Jaccard\"] = best_jaccard\n",
    "            # run.summary[\"Best Epoch\"]   = best_epoch\n",
    "            # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            # PATH = os.path.join(CFG.model_output_path, f\"best_epoch-{fold:02d}.bin\")\n",
    "            # torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            # wandb.save(PATH)\n",
    "            # print(f\"Model Saved{sr_} to path:\",PATH)\n",
    "            \n",
    "        # last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # PATH = os.path.join(CFG.model_output_path,f\"last_epoch-{fold:02d}.bin\")\n",
    "        # torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "    \n",
    "    # load best model weights\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.2, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=1000, \n",
    "                                                   eta_min=0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: NVIDIA GeForce RTX 3090\n",
      "\n",
      "Epoch 1/3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/250 [00:00<?, ?it/s]/tmp/ipykernel_226713/3759876696.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n",
      "/home/junsheng/.conda/envs/pytorch_junsheng_39/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Train : 100%|██████████| 250/250 [00:12<00:00, 19.41it/s, gpu_mem=1.82 GB, lr=0.01709, train_loss=48.0798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 250/250 [00:11<00:00, 21.53it/s, gpu_mem=1.82 GB, lr=0.01005, train_loss=44.5714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 250/250 [00:11<00:00, 21.16it/s, gpu_mem=1.82 GB, lr=0.00301, train_loss=35.8674]\n"
     ]
    }
   ],
   "source": [
    "model, history = run_training(model, optimizer, scheduler,\n",
    "                                device=config['device'],\n",
    "                                num_epochs=config['max_epoch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensorViLTransformerSS(\n",
      "  (sensor_linear): Linear(in_features=10, out_features=768, bias=True)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (transformer): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      "  (pooler): Pooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n",
      "img.shape: torch.Size([1, 3, 384, 576])\n",
      "{'sensor_feats': tensor([[[-0.1228, -0.6675,  0.1351,  1.9585,  0.0037,  1.2392, -1.3237,\n",
      "          -0.3683,  1.9655, -1.3632,  0.4314, -1.0886, -0.9001,  1.2250,\n",
      "          -0.1528,  1.1962, -1.7803,  0.2932,  2.3316, -0.8266, -1.3214,\n",
      "           0.7669,  0.2835,  1.3352,  1.0776, -1.6744,  2.0369, -1.7355,\n",
      "          -0.2595, -0.5231, -1.8723,  0.8809,  0.5579, -0.5101, -1.3433,\n",
      "           0.3743,  1.3827, -0.3924,  0.6350, -0.4755, -1.1632, -1.7362,\n",
      "           0.1793,  0.1377,  1.2603,  2.0368,  0.4385, -0.1116, -0.0694,\n",
      "          -1.0312,  0.8100,  0.2971, -2.0312,  1.5286,  1.4956, -0.1626,\n",
      "           1.6873,  1.3844,  1.8500, -1.0853,  0.0592,  0.0932,  0.2362,\n",
      "           2.0147,  1.1846,  0.4906,  1.9062, -1.5979,  0.2196,  1.6724,\n",
      "           1.6697,  0.5706, -1.8853,  0.4832,  0.7780,  0.9129,  0.3497,\n",
      "          -1.4302,  1.1214, -0.9682,  0.5880, -1.5456, -1.8616, -1.9246,\n",
      "           1.7688,  0.9065, -1.7205,  1.2922, -2.0724, -0.5328,  0.6058,\n",
      "           1.5478, -1.5995,  0.5173, -1.8627,  0.4522,  1.0337,  1.9992,\n",
      "          -2.3859, -2.1631,  0.0028,  0.1881,  0.6526, -1.2066,  0.7118,\n",
      "           1.2959,  1.9361, -0.0921,  0.4978,  2.2614, -0.5206, -1.1170,\n",
      "          -0.0735, -0.2948, -0.6566, -1.0107, -0.5488,  1.9527,  1.5635,\n",
      "           1.7720, -1.6672,  0.9959, -0.0795, -1.1968,  1.0035, -1.1061,\n",
      "           1.6841, -0.0517, -0.4770,  0.8287,  0.4152, -1.6424, -0.2029,\n",
      "           1.7581,  1.8396,  1.4608,  1.6686, -0.1480, -1.1537, -0.2228,\n",
      "          -1.4608,  0.9850,  1.6554,  1.3912,  2.2451,  0.9552, -2.0016,\n",
      "          -0.6713, -0.1478,  0.0149, -1.1730, -2.1285, -1.2162, -0.7377,\n",
      "           1.5200, -0.2601,  0.3994, -1.9899, -0.9962, -0.6149, -1.7476,\n",
      "          -0.6008, -0.5845, -1.3373,  0.5191,  0.2628,  1.4905, -0.0096,\n",
      "          -0.8507,  0.0471,  1.3695, -0.4503, -0.8410,  1.5050, -1.7656,\n",
      "           2.1541,  0.9919,  0.0895,  0.8820,  1.5942,  0.9045, -0.8601,\n",
      "           0.7812, -1.6532, -1.1031, -1.5019,  0.1640, -0.0994, -1.8053,\n",
      "           1.8719,  0.3541, -0.4037, -0.6761,  1.5039, -1.6067, -0.6262,\n",
      "           1.4887, -0.6699,  0.0503, -0.5671,  2.2124,  1.4164, -1.3276,\n",
      "          -0.7831,  1.7594, -1.8194,  1.6361,  0.1068, -0.3395,  0.2778,\n",
      "           1.3394, -0.3810,  0.6722, -0.5113,  1.4524, -1.8441,  0.1030,\n",
      "          -1.8825, -1.0356,  1.2918,  0.5097, -0.0550,  0.0734,  2.3523,\n",
      "          -0.7546,  0.5644, -0.2786,  0.8582,  0.8740,  0.1939,  1.5166,\n",
      "           0.4930, -1.6510,  2.2246,  0.4439,  1.4150, -1.0540, -0.8805,\n",
      "          -1.6711,  1.3832,  0.8438, -0.1754, -0.5310,  0.4010, -0.3653,\n",
      "           0.4635, -1.5710, -2.3385,  0.2864, -1.7332, -0.0202,  1.8523,\n",
      "           0.6241,  0.8141,  0.8578, -0.3717, -0.1044,  1.6206,  2.1328,\n",
      "           0.7691, -0.4350, -0.6251,  1.1665,  1.4250, -0.7946, -0.0798,\n",
      "          -1.8736, -0.1317,  1.8582,  2.0001, -0.0848,  1.7106, -1.1119,\n",
      "          -2.0727,  0.9944,  0.1838, -1.0332,  0.0131,  0.8952,  0.4262,\n",
      "          -0.9035, -1.7458,  1.5507, -0.3631,  0.3416, -0.0592, -0.9064,\n",
      "          -1.7254, -0.4498, -0.1410, -2.1527,  0.3800, -0.1519, -0.4388,\n",
      "          -1.8785,  1.0533,  0.8320,  0.1526,  0.5648,  0.2784, -2.2535,\n",
      "          -0.9527, -1.7764, -1.5124,  1.1450, -0.2320,  0.0476,  1.5717,\n",
      "           0.4412,  0.9080, -0.7800, -1.9894, -0.8898, -1.2609, -1.5413,\n",
      "          -1.3040,  0.7402, -0.1949, -2.2103, -1.8333, -0.5227, -0.9647,\n",
      "          -0.0228, -0.1397,  1.2937,  1.0306,  0.8357, -0.6782,  0.5454,\n",
      "           2.0691,  1.5980,  0.6555,  1.9099, -0.0452,  0.9497, -1.1098,\n",
      "          -0.3536,  0.2864, -0.5352,  0.5949, -1.7328,  1.7335, -1.7049,\n",
      "           0.8712, -1.9069, -1.4605,  0.0574, -0.4653, -1.5057, -0.3173,\n",
      "           0.0803,  1.2964, -1.6922, -1.4328, -0.6525,  1.6047, -2.2062,\n",
      "           0.1320,  1.6313, -1.3882,  1.7695,  1.3700, -1.2222, -0.6805,\n",
      "          -2.0109,  0.8655, -0.1062, -0.0609, -1.3878,  1.8083,  1.3934,\n",
      "          -0.3835,  0.9937,  1.3028,  0.1042,  1.8422, -1.1645, -1.6472,\n",
      "           0.7557, -0.6095,  0.2816,  0.5780, -0.7235, -1.0689, -0.8892,\n",
      "          -1.9982, -1.6099, -0.7378,  1.5201, -2.1644, -1.3805, -0.8392,\n",
      "          -1.5527, -0.4867, -0.0915,  0.7426, -1.1654, -0.1968,  0.6096,\n",
      "           0.8462,  0.3516,  0.6579,  0.0430, -0.7266,  1.0864, -0.3852,\n",
      "           0.2324, -1.7835,  1.4526,  0.0153, -0.1315,  1.4092,  0.7925,\n",
      "           0.7384,  1.4348, -0.6629,  0.1771, -1.1932, -1.6401, -0.6156,\n",
      "           0.4620, -0.4232,  0.5095,  0.4731, -1.0629,  0.4539,  1.8076,\n",
      "          -0.5604, -1.5931,  0.4044,  0.0880,  0.1989,  0.0570, -1.9139,\n",
      "           1.3785, -1.0501, -0.1112, -0.1003,  0.6364,  0.3570,  0.4824,\n",
      "          -0.4149,  1.6147,  0.5115,  1.3715,  0.4375,  0.0620, -0.1878,\n",
      "           1.8674, -0.2318, -0.1940, -1.4556,  0.6990,  1.7062, -1.9500,\n",
      "           0.8649,  0.7593, -0.0514,  0.2274,  0.1547,  0.5333,  1.8467,\n",
      "           1.2428,  1.4378, -1.4641,  0.9588,  0.6540, -1.9474, -0.7782,\n",
      "           0.2035, -0.2519,  0.2528,  1.0068,  1.9047, -0.3302,  2.6750,\n",
      "           1.1437, -1.1700,  1.0187, -2.3386, -0.0707,  1.6352,  1.1137,\n",
      "          -0.7794, -1.5773, -0.4378, -1.1387, -1.4003, -0.5946,  1.3430,\n",
      "          -0.2618, -1.5970, -0.3942, -0.2996, -1.1660,  1.3395, -0.0273,\n",
      "          -0.6560,  0.5123,  0.3919,  1.0377,  0.6096,  0.5825, -1.1731,\n",
      "           0.5900, -0.4325, -2.2552,  1.0448,  0.0807,  1.7570,  0.5691,\n",
      "          -0.2483,  1.4477, -2.3770,  0.1206, -0.4002,  0.2413, -0.5477,\n",
      "          -1.1307, -1.6441, -0.1417,  1.7309,  1.8293,  1.2044,  1.5416,\n",
      "           1.1974, -1.2975,  1.0689, -0.4725, -0.4886, -1.1022, -0.0346,\n",
      "          -0.0412,  0.3756,  1.8429, -0.4977,  1.9370, -0.4333, -0.3206,\n",
      "          -1.2302,  0.4571,  0.7942,  1.6689, -0.4464, -1.7792,  1.8034,\n",
      "          -0.2102, -1.6077,  1.2368, -0.2807,  1.6597, -0.4931, -1.5046,\n",
      "           1.3644, -0.2154, -2.1480, -0.9939,  1.0006,  1.1182,  2.1914,\n",
      "           0.8736, -2.0442, -0.3789, -0.3982,  1.2589,  0.5488, -1.6079,\n",
      "          -1.0724, -0.9995,  0.3629, -0.2506, -0.1797, -0.8638, -0.1584,\n",
      "           1.1740, -1.4752,  0.2409,  0.0910, -0.6194,  1.4621, -0.0897,\n",
      "           0.3138,  1.8898,  2.0355, -0.2109,  0.8626, -0.1003, -0.0187,\n",
      "           1.3711, -0.0554, -1.7951,  1.1526,  1.2538,  0.1211, -1.6712,\n",
      "           1.8356, -0.1906,  0.4491,  0.2265, -1.8222, -0.3303, -0.8718,\n",
      "          -1.1150,  0.9001,  0.4334, -1.0734,  1.6582, -1.2389,  0.7815,\n",
      "          -1.4342, -0.6971,  1.8609,  0.2537, -0.8285,  0.5457, -0.4235,\n",
      "          -0.1248,  1.0877,  1.3765, -1.3491, -1.9664, -0.5735,  1.2977,\n",
      "           0.9376, -0.0719, -2.1883,  1.4776, -1.4917,  1.6970, -1.8621,\n",
      "          -1.8719, -0.1049, -1.6904,  0.9914,  0.0487, -0.3456, -0.0515,\n",
      "           1.7346,  0.1042, -0.9726, -1.4717, -0.6434, -0.1079, -1.7802,\n",
      "          -0.2087,  1.4000, -0.3448, -1.1305, -1.8315,  0.8359, -0.5659,\n",
      "           0.8988, -0.6563, -0.2744, -1.0174, -0.4629,  1.4898, -0.9910,\n",
      "           0.7933,  0.3148,  0.4707, -1.8616,  0.3944, -1.8351,  0.7884,\n",
      "           0.0937,  0.8576,  0.3497,  1.4007, -1.6024, -0.5122,  1.3446,\n",
      "           0.0991, -1.0571, -1.0012,  0.6348,  0.6294, -0.5255,  1.5010,\n",
      "           1.0419,  0.5824, -0.3353,  1.4138, -1.7175, -1.0939, -2.0761,\n",
      "           0.8572,  1.4573,  1.7397, -0.6032, -0.5935,  0.5203, -0.6764,\n",
      "           2.0745, -1.6958, -0.1088,  0.6198,  1.7910, -1.3417, -1.3539,\n",
      "           1.3046, -0.1985,  1.6220, -0.7937,  2.2877, -1.1309,  1.9717,\n",
      "          -0.9397, -0.9871, -2.1530,  0.5046, -1.5136, -1.3633,  1.8872,\n",
      "          -1.3174, -1.4577, -1.8986,  1.8204,  0.8597, -2.1523, -0.7779,\n",
      "           0.2569, -2.1843,  1.0802,  1.8525,  0.1419,  1.0070,  0.4168,\n",
      "          -0.3939,  1.7232,  0.3631, -0.0689,  1.7335, -0.3620,  0.5863,\n",
      "          -1.4145, -1.7918,  0.4266, -0.2112,  1.3947, -0.2390,  0.7498,\n",
      "           1.8435,  1.2187, -1.5271,  0.4698,  1.8832, -0.9711, -1.1442,\n",
      "          -1.8386, -1.4862,  0.4332,  0.3616, -2.1034,  0.1512,  2.2160,\n",
      "          -0.1287, -0.9227, -0.1996, -0.7316, -0.3548, -1.7037, -1.9966,\n",
      "          -0.6375, -0.5647, -0.0157,  0.9840, -1.8439]]], device='cuda:0'), 'image_feats': tensor([[[-0.1229, -0.6668,  0.1326,  ..., -0.0305,  0.9960, -1.8578],\n",
      "         [-0.1578, -0.4545,  0.0784,  ...,  0.2079,  0.9542, -1.7897],\n",
      "         [-0.1151, -0.6774,  0.1158,  ..., -0.0401,  0.9927, -1.8301],\n",
      "         ...,\n",
      "         [-0.1116, -0.6815,  0.1100,  ..., -0.0444,  0.9918, -1.8199],\n",
      "         [-0.1611, -0.4530,  0.0787,  ...,  0.2088,  0.9547, -1.7925],\n",
      "         [-0.1586, -0.4533,  0.0789,  ...,  0.2088,  0.9544, -1.7904]]],\n",
      "       device='cuda:0'), 'cls_feats': tensor([[ 1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "          1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,\n",
      "         -1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "         -1.0000,  1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000,\n",
      "         -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         -1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,\n",
      "         -1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         -1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,\n",
      "          1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000,\n",
      "         -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         -1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000,\n",
      "         -1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "         -1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,\n",
      "         -1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000,\n",
      "          1.0000,  1.0000, -1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -1.0000,\n",
      "          1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000,\n",
      "          1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "          1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000,\n",
      "         -1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000,\n",
      "         -1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,\n",
      "         -1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000,\n",
      "         -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000,\n",
      "          1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,\n",
      "         -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "          1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000,\n",
      "         -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         -1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,\n",
      "         -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000,\n",
      "         -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
      "          1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000,\n",
      "         -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "          1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -1.0000,\n",
      "         -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
      "          1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000,\n",
      "          1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000,\n",
      "          1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         -1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000,\n",
      "         -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "          1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,\n",
      "          1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
      "         -1.0000, -1.0000,  1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
      "         -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000,\n",
      "         -1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         -1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "          1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000, -1.0000]],\n",
      "       device='cuda:0'), 'raw_cls_feats': tensor([[-0.1228, -0.6675,  0.1351,  1.9585,  0.0037,  1.2392, -1.3237, -0.3683,\n",
      "          1.9655, -1.3632,  0.4314, -1.0886, -0.9001,  1.2250, -0.1528,  1.1962,\n",
      "         -1.7803,  0.2932,  2.3316, -0.8266, -1.3214,  0.7669,  0.2835,  1.3352,\n",
      "          1.0776, -1.6744,  2.0369, -1.7355, -0.2595, -0.5231, -1.8723,  0.8809,\n",
      "          0.5579, -0.5101, -1.3433,  0.3743,  1.3827, -0.3924,  0.6350, -0.4755,\n",
      "         -1.1632, -1.7362,  0.1793,  0.1377,  1.2603,  2.0368,  0.4385, -0.1116,\n",
      "         -0.0694, -1.0312,  0.8100,  0.2971, -2.0312,  1.5286,  1.4956, -0.1626,\n",
      "          1.6873,  1.3844,  1.8500, -1.0853,  0.0592,  0.0932,  0.2362,  2.0147,\n",
      "          1.1846,  0.4906,  1.9062, -1.5979,  0.2196,  1.6724,  1.6697,  0.5706,\n",
      "         -1.8853,  0.4832,  0.7780,  0.9129,  0.3497, -1.4302,  1.1214, -0.9682,\n",
      "          0.5880, -1.5456, -1.8616, -1.9246,  1.7688,  0.9065, -1.7205,  1.2922,\n",
      "         -2.0724, -0.5328,  0.6058,  1.5478, -1.5995,  0.5173, -1.8627,  0.4522,\n",
      "          1.0337,  1.9992, -2.3859, -2.1631,  0.0028,  0.1881,  0.6526, -1.2066,\n",
      "          0.7118,  1.2959,  1.9361, -0.0921,  0.4978,  2.2614, -0.5206, -1.1170,\n",
      "         -0.0735, -0.2948, -0.6566, -1.0107, -0.5488,  1.9527,  1.5635,  1.7720,\n",
      "         -1.6672,  0.9959, -0.0795, -1.1968,  1.0035, -1.1061,  1.6841, -0.0517,\n",
      "         -0.4770,  0.8287,  0.4152, -1.6424, -0.2029,  1.7581,  1.8396,  1.4608,\n",
      "          1.6686, -0.1480, -1.1537, -0.2228, -1.4608,  0.9850,  1.6554,  1.3912,\n",
      "          2.2451,  0.9552, -2.0016, -0.6713, -0.1478,  0.0149, -1.1730, -2.1285,\n",
      "         -1.2162, -0.7377,  1.5200, -0.2601,  0.3994, -1.9899, -0.9962, -0.6149,\n",
      "         -1.7476, -0.6008, -0.5845, -1.3373,  0.5191,  0.2628,  1.4905, -0.0096,\n",
      "         -0.8507,  0.0471,  1.3695, -0.4503, -0.8410,  1.5050, -1.7656,  2.1541,\n",
      "          0.9919,  0.0895,  0.8820,  1.5942,  0.9045, -0.8601,  0.7812, -1.6532,\n",
      "         -1.1031, -1.5019,  0.1640, -0.0994, -1.8053,  1.8719,  0.3541, -0.4037,\n",
      "         -0.6761,  1.5039, -1.6067, -0.6262,  1.4887, -0.6699,  0.0503, -0.5671,\n",
      "          2.2124,  1.4164, -1.3276, -0.7831,  1.7594, -1.8194,  1.6361,  0.1068,\n",
      "         -0.3395,  0.2778,  1.3394, -0.3810,  0.6722, -0.5113,  1.4524, -1.8441,\n",
      "          0.1030, -1.8825, -1.0356,  1.2918,  0.5097, -0.0550,  0.0734,  2.3523,\n",
      "         -0.7546,  0.5644, -0.2786,  0.8582,  0.8740,  0.1939,  1.5166,  0.4930,\n",
      "         -1.6510,  2.2246,  0.4439,  1.4150, -1.0540, -0.8805, -1.6711,  1.3832,\n",
      "          0.8438, -0.1754, -0.5310,  0.4010, -0.3653,  0.4635, -1.5710, -2.3385,\n",
      "          0.2864, -1.7332, -0.0202,  1.8523,  0.6241,  0.8141,  0.8578, -0.3717,\n",
      "         -0.1044,  1.6206,  2.1328,  0.7691, -0.4350, -0.6251,  1.1665,  1.4250,\n",
      "         -0.7946, -0.0798, -1.8736, -0.1317,  1.8582,  2.0001, -0.0848,  1.7106,\n",
      "         -1.1119, -2.0727,  0.9944,  0.1838, -1.0332,  0.0131,  0.8952,  0.4262,\n",
      "         -0.9035, -1.7458,  1.5507, -0.3631,  0.3416, -0.0592, -0.9064, -1.7254,\n",
      "         -0.4498, -0.1410, -2.1527,  0.3800, -0.1519, -0.4388, -1.8785,  1.0533,\n",
      "          0.8320,  0.1526,  0.5648,  0.2784, -2.2535, -0.9527, -1.7764, -1.5124,\n",
      "          1.1450, -0.2320,  0.0476,  1.5717,  0.4412,  0.9080, -0.7800, -1.9894,\n",
      "         -0.8898, -1.2609, -1.5413, -1.3040,  0.7402, -0.1949, -2.2103, -1.8333,\n",
      "         -0.5227, -0.9647, -0.0228, -0.1397,  1.2937,  1.0306,  0.8357, -0.6782,\n",
      "          0.5454,  2.0691,  1.5980,  0.6555,  1.9099, -0.0452,  0.9497, -1.1098,\n",
      "         -0.3536,  0.2864, -0.5352,  0.5949, -1.7328,  1.7335, -1.7049,  0.8712,\n",
      "         -1.9069, -1.4605,  0.0574, -0.4653, -1.5057, -0.3173,  0.0803,  1.2964,\n",
      "         -1.6922, -1.4328, -0.6525,  1.6047, -2.2062,  0.1320,  1.6313, -1.3882,\n",
      "          1.7695,  1.3700, -1.2222, -0.6805, -2.0109,  0.8655, -0.1062, -0.0609,\n",
      "         -1.3878,  1.8083,  1.3934, -0.3835,  0.9937,  1.3028,  0.1042,  1.8422,\n",
      "         -1.1645, -1.6472,  0.7557, -0.6095,  0.2816,  0.5780, -0.7235, -1.0689,\n",
      "         -0.8892, -1.9982, -1.6099, -0.7378,  1.5201, -2.1644, -1.3805, -0.8392,\n",
      "         -1.5527, -0.4867, -0.0915,  0.7426, -1.1654, -0.1968,  0.6096,  0.8462,\n",
      "          0.3516,  0.6579,  0.0430, -0.7266,  1.0864, -0.3852,  0.2324, -1.7835,\n",
      "          1.4526,  0.0153, -0.1315,  1.4092,  0.7925,  0.7384,  1.4348, -0.6629,\n",
      "          0.1771, -1.1932, -1.6401, -0.6156,  0.4620, -0.4232,  0.5095,  0.4731,\n",
      "         -1.0629,  0.4539,  1.8076, -0.5604, -1.5931,  0.4044,  0.0880,  0.1989,\n",
      "          0.0570, -1.9139,  1.3785, -1.0501, -0.1112, -0.1003,  0.6364,  0.3570,\n",
      "          0.4824, -0.4149,  1.6147,  0.5115,  1.3715,  0.4375,  0.0620, -0.1878,\n",
      "          1.8674, -0.2318, -0.1940, -1.4556,  0.6990,  1.7062, -1.9500,  0.8649,\n",
      "          0.7593, -0.0514,  0.2274,  0.1547,  0.5333,  1.8467,  1.2428,  1.4378,\n",
      "         -1.4641,  0.9588,  0.6540, -1.9474, -0.7782,  0.2035, -0.2519,  0.2528,\n",
      "          1.0068,  1.9047, -0.3302,  2.6750,  1.1437, -1.1700,  1.0187, -2.3386,\n",
      "         -0.0707,  1.6352,  1.1137, -0.7794, -1.5773, -0.4378, -1.1387, -1.4003,\n",
      "         -0.5946,  1.3430, -0.2618, -1.5970, -0.3942, -0.2996, -1.1660,  1.3395,\n",
      "         -0.0273, -0.6560,  0.5123,  0.3919,  1.0377,  0.6096,  0.5825, -1.1731,\n",
      "          0.5900, -0.4325, -2.2552,  1.0448,  0.0807,  1.7570,  0.5691, -0.2483,\n",
      "          1.4477, -2.3770,  0.1206, -0.4002,  0.2413, -0.5477, -1.1307, -1.6441,\n",
      "         -0.1417,  1.7309,  1.8293,  1.2044,  1.5416,  1.1974, -1.2975,  1.0689,\n",
      "         -0.4725, -0.4886, -1.1022, -0.0346, -0.0412,  0.3756,  1.8429, -0.4977,\n",
      "          1.9370, -0.4333, -0.3206, -1.2302,  0.4571,  0.7942,  1.6689, -0.4464,\n",
      "         -1.7792,  1.8034, -0.2102, -1.6077,  1.2368, -0.2807,  1.6597, -0.4931,\n",
      "         -1.5046,  1.3644, -0.2154, -2.1480, -0.9939,  1.0006,  1.1182,  2.1914,\n",
      "          0.8736, -2.0442, -0.3789, -0.3982,  1.2589,  0.5488, -1.6079, -1.0724,\n",
      "         -0.9995,  0.3629, -0.2506, -0.1797, -0.8638, -0.1584,  1.1740, -1.4752,\n",
      "          0.2409,  0.0910, -0.6194,  1.4621, -0.0897,  0.3138,  1.8898,  2.0355,\n",
      "         -0.2109,  0.8626, -0.1003, -0.0187,  1.3711, -0.0554, -1.7951,  1.1526,\n",
      "          1.2538,  0.1211, -1.6712,  1.8356, -0.1906,  0.4491,  0.2265, -1.8222,\n",
      "         -0.3303, -0.8718, -1.1150,  0.9001,  0.4334, -1.0734,  1.6582, -1.2389,\n",
      "          0.7815, -1.4342, -0.6971,  1.8609,  0.2537, -0.8285,  0.5457, -0.4235,\n",
      "         -0.1248,  1.0877,  1.3765, -1.3491, -1.9664, -0.5735,  1.2977,  0.9376,\n",
      "         -0.0719, -2.1883,  1.4776, -1.4917,  1.6970, -1.8621, -1.8719, -0.1049,\n",
      "         -1.6904,  0.9914,  0.0487, -0.3456, -0.0515,  1.7346,  0.1042, -0.9726,\n",
      "         -1.4717, -0.6434, -0.1079, -1.7802, -0.2087,  1.4000, -0.3448, -1.1305,\n",
      "         -1.8315,  0.8359, -0.5659,  0.8988, -0.6563, -0.2744, -1.0174, -0.4629,\n",
      "          1.4898, -0.9910,  0.7933,  0.3148,  0.4707, -1.8616,  0.3944, -1.8351,\n",
      "          0.7884,  0.0937,  0.8576,  0.3497,  1.4007, -1.6024, -0.5122,  1.3446,\n",
      "          0.0991, -1.0571, -1.0012,  0.6348,  0.6294, -0.5255,  1.5010,  1.0419,\n",
      "          0.5824, -0.3353,  1.4138, -1.7175, -1.0939, -2.0761,  0.8572,  1.4573,\n",
      "          1.7397, -0.6032, -0.5935,  0.5203, -0.6764,  2.0745, -1.6958, -0.1088,\n",
      "          0.6198,  1.7910, -1.3417, -1.3539,  1.3046, -0.1985,  1.6220, -0.7937,\n",
      "          2.2877, -1.1309,  1.9717, -0.9397, -0.9871, -2.1530,  0.5046, -1.5136,\n",
      "         -1.3633,  1.8872, -1.3174, -1.4577, -1.8986,  1.8204,  0.8597, -2.1523,\n",
      "         -0.7779,  0.2569, -2.1843,  1.0802,  1.8525,  0.1419,  1.0070,  0.4168,\n",
      "         -0.3939,  1.7232,  0.3631, -0.0689,  1.7335, -0.3620,  0.5863, -1.4145,\n",
      "         -1.7918,  0.4266, -0.2112,  1.3947, -0.2390,  0.7498,  1.8435,  1.2187,\n",
      "         -1.5271,  0.4698,  1.8832, -0.9711, -1.1442, -1.8386, -1.4862,  0.4332,\n",
      "          0.3616, -2.1034,  0.1512,  2.2160, -0.1287, -0.9227, -0.1996, -0.7316,\n",
      "         -0.3548, -1.7037, -1.9966, -0.6375, -0.5647, -0.0157,  0.9840, -1.8439]],\n",
      "       device='cuda:0'), 'image_labels': None, 'image_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0'), 'patch_index': (tensor([[[10,  4],\n",
      "         [ 1, 17],\n",
      "         [ 7, 15],\n",
      "         [ 5,  1],\n",
      "         [ 6,  9],\n",
      "         [ 8, 10],\n",
      "         [ 1,  0],\n",
      "         [11, 10],\n",
      "         [ 3,  5],\n",
      "         [ 8,  3],\n",
      "         [ 2,  5],\n",
      "         [ 8, 16],\n",
      "         [ 6,  6],\n",
      "         [ 5,  0],\n",
      "         [ 9, 15],\n",
      "         [ 9,  2],\n",
      "         [ 7,  1],\n",
      "         [ 3,  1],\n",
      "         [ 6,  0],\n",
      "         [ 1,  5],\n",
      "         [ 5, 17],\n",
      "         [ 8, 12],\n",
      "         [ 0, 15],\n",
      "         [ 2,  7],\n",
      "         [ 1,  7],\n",
      "         [ 9, 16],\n",
      "         [ 2, 17],\n",
      "         [ 2, 15],\n",
      "         [ 9, 11],\n",
      "         [ 8, 13],\n",
      "         [ 0,  1],\n",
      "         [ 0, 11],\n",
      "         [ 6,  2],\n",
      "         [10,  2],\n",
      "         [10, 12],\n",
      "         [ 2,  6],\n",
      "         [11, 16],\n",
      "         [ 5,  7],\n",
      "         [ 1,  1],\n",
      "         [ 3, 10],\n",
      "         [11,  1],\n",
      "         [ 7, 11],\n",
      "         [10, 16],\n",
      "         [11,  6],\n",
      "         [ 4, 16],\n",
      "         [ 1, 16],\n",
      "         [ 2, 11],\n",
      "         [ 5, 15],\n",
      "         [ 4,  4],\n",
      "         [11, 12],\n",
      "         [ 1, 15],\n",
      "         [11, 14],\n",
      "         [ 4,  8],\n",
      "         [ 7,  3],\n",
      "         [ 3,  3],\n",
      "         [10,  7],\n",
      "         [ 9,  5],\n",
      "         [ 2, 13],\n",
      "         [ 8,  4],\n",
      "         [11,  0],\n",
      "         [ 5, 13],\n",
      "         [ 6, 16],\n",
      "         [ 0, 14],\n",
      "         [ 7, 10],\n",
      "         [ 8,  2],\n",
      "         [ 0,  0],\n",
      "         [ 8,  9],\n",
      "         [ 6,  7],\n",
      "         [ 9,  1],\n",
      "         [ 3,  4],\n",
      "         [ 6,  5],\n",
      "         [ 1,  9],\n",
      "         [ 2, 16],\n",
      "         [ 9, 10],\n",
      "         [10, 14],\n",
      "         [10,  6],\n",
      "         [ 4,  6],\n",
      "         [ 9,  8],\n",
      "         [ 7,  2],\n",
      "         [ 9,  7],\n",
      "         [ 3,  9],\n",
      "         [11, 17],\n",
      "         [11,  5],\n",
      "         [ 6,  1],\n",
      "         [10,  3],\n",
      "         [ 0, 16],\n",
      "         [ 2, 10],\n",
      "         [11, 11],\n",
      "         [ 0,  2],\n",
      "         [ 5,  3],\n",
      "         [ 4, 15],\n",
      "         [ 3,  8],\n",
      "         [11,  3],\n",
      "         [11,  4],\n",
      "         [ 6, 12],\n",
      "         [ 5,  2],\n",
      "         [ 5, 12],\n",
      "         [ 3, 13],\n",
      "         [ 6, 10],\n",
      "         [ 9,  9],\n",
      "         [ 7, 14],\n",
      "         [ 3, 12],\n",
      "         [ 2,  9],\n",
      "         [ 4, 14],\n",
      "         [ 7,  0],\n",
      "         [ 7, 13],\n",
      "         [ 0,  9],\n",
      "         [11,  7],\n",
      "         [ 0,  8],\n",
      "         [10, 13],\n",
      "         [ 1,  6],\n",
      "         [ 5,  9],\n",
      "         [ 2, 12],\n",
      "         [ 4,  3],\n",
      "         [ 3,  2],\n",
      "         [ 1, 11],\n",
      "         [ 4,  2],\n",
      "         [ 0,  5],\n",
      "         [ 4,  1],\n",
      "         [ 8, 15],\n",
      "         [11,  2],\n",
      "         [ 3, 17],\n",
      "         [ 8,  1],\n",
      "         [ 8, 17],\n",
      "         [ 5,  5],\n",
      "         [ 5,  6],\n",
      "         [10,  0],\n",
      "         [ 2, 14],\n",
      "         [ 9,  0],\n",
      "         [ 1,  4],\n",
      "         [ 7, 16],\n",
      "         [ 3, 16],\n",
      "         [ 9,  4],\n",
      "         [ 9,  6],\n",
      "         [ 1,  2],\n",
      "         [ 6, 13],\n",
      "         [11,  9],\n",
      "         [ 0,  4],\n",
      "         [ 7,  9],\n",
      "         [ 1,  3],\n",
      "         [ 3, 15],\n",
      "         [10,  5],\n",
      "         [ 9, 12],\n",
      "         [ 8, 11],\n",
      "         [ 5, 14],\n",
      "         [ 4, 13],\n",
      "         [10, 17],\n",
      "         [ 3, 14],\n",
      "         [ 3,  0],\n",
      "         [ 9, 17],\n",
      "         [ 6, 17],\n",
      "         [11, 13],\n",
      "         [ 8,  7],\n",
      "         [ 6, 11],\n",
      "         [ 3, 11],\n",
      "         [ 6, 14],\n",
      "         [ 8,  6],\n",
      "         [ 4, 11],\n",
      "         [ 7, 12],\n",
      "         [ 5,  4],\n",
      "         [ 9,  3],\n",
      "         [ 0,  3],\n",
      "         [ 6,  3],\n",
      "         [ 1, 12],\n",
      "         [ 8,  8],\n",
      "         [ 6, 15],\n",
      "         [ 3,  7],\n",
      "         [ 8,  0],\n",
      "         [ 7,  5],\n",
      "         [ 0, 13],\n",
      "         [ 8, 14],\n",
      "         [ 5, 10],\n",
      "         [ 3,  6],\n",
      "         [ 6,  4],\n",
      "         [ 4, 17],\n",
      "         [ 5, 16],\n",
      "         [ 1,  8],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5],\n",
      "         [ 1, 10],\n",
      "         [ 2,  4],\n",
      "         [ 7,  4],\n",
      "         [10,  8],\n",
      "         [ 2,  1],\n",
      "         [ 7, 17],\n",
      "         [ 4,  7],\n",
      "         [ 0, 10],\n",
      "         [ 7,  8],\n",
      "         [10, 11],\n",
      "         [ 4, 10],\n",
      "         [ 5,  8],\n",
      "         [ 0,  7],\n",
      "         [ 1, 14],\n",
      "         [ 2,  2],\n",
      "         [ 0, 12],\n",
      "         [ 4,  9],\n",
      "         [ 2,  8],\n",
      "         [ 1, 13],\n",
      "         [ 2,  0],\n",
      "         [10, 15],\n",
      "         [11, 15],\n",
      "         [ 4,  0],\n",
      "         [10,  1],\n",
      "         [10, 10],\n",
      "         [ 8,  5],\n",
      "         [ 4, 12],\n",
      "         [ 0,  6],\n",
      "         [11,  8],\n",
      "         [ 6,  8],\n",
      "         [ 9, 14],\n",
      "         [ 9, 13],\n",
      "         [ 5, 11],\n",
      "         [ 7,  7],\n",
      "         [ 0, 17],\n",
      "         [10,  9],\n",
      "         [ 7,  6]]]), (12, 18)), 'cls_output': tensor([[-0.3554]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_226713/582452387.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img)\n"
     ]
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), 'embedding_test_dict.pt')\n",
    "print(model)\n",
    "model.eval()\n",
    "device = config[\"device\"]\n",
    "model.to(device)\n",
    "def infer(img_filename, sensor):\n",
    "    try:\n",
    "        img_path = os.path.join('pictures',img_filename)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        img = pixelbert_transform(size=384)(image) # 将图像数据归一化torch.Size([3, 384, 576])\n",
    "        img = torch.tensor(img)\n",
    "        img = torch.unsqueeze(img, 0) # torch.Size([1, 3, 384, 576])\n",
    "        img = img.to(device)\n",
    "        print(\"img.shape:\",img.shape)\n",
    "    except :\n",
    "        print(\"图片加载失败！\")\n",
    "        raise\n",
    "\n",
    "    batch = dict()\n",
    "    batch[\"image\"] = img\n",
    "\n",
    "    batch['sensor_masks'] = torch.ones(1,1).to(device)\n",
    "    with torch.no_grad():\n",
    "        batch['sensor'] = sensor.to(device)       \n",
    "        infer = model(batch)\n",
    "\n",
    "        print(infer)\n",
    "        sensor_emb, img_emb = infer[\"sensor_feats\"], infer[\"image_feats\"]# torch.Size([1, 23, 768]) torch.Size([1, 217, 768])\n",
    "        cls_output = infer['cls_output']\n",
    "        \n",
    "\n",
    "    return [cls_output]\n",
    "\n",
    "examples=[\n",
    "        [\n",
    "            \"6212487_1cca7f3f_1024x1024.jpg\",\n",
    "        ],\n",
    "        [\n",
    "            \"6212487_1cca7f3f_1024x1024.jpg\",\n",
    "        ],\n",
    "        [\n",
    "            \"6212487_1cca7f3f_1024x1024.jpg\",\n",
    "        ],\n",
    "    ],\n",
    "\n",
    "n = 1\n",
    "sensor = torch.randn(1,1,10)\n",
    "out = infer(examples[0][n][0],sensor)\n",
    "# print(\"out:\",out,\"000\\n\")\n",
    "# print(\"out0.shape:\",out[0].shape)\n",
    "# cv2.imwrite('output.png',out[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3554]], device='cuda:0')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3554198"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].cpu().numpy()[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch_junsheng_39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29fd19f11c6b89e267402bb3227bc1208f7e2c9719aa03eba13baf7684fe5867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
