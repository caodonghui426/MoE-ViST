{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch_junsheng_39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from vilt.modules import heads, objectives\n",
    "import vilt.modules.vision_transformer as vit\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from typing import OrderedDict\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vilt.transforms import pixelbert_transform\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
    "import warnings\n",
    "\n",
    "# 禁用所有警告\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前device= cuda:1\n"
     ]
    }
   ],
   "source": [
    "class config:\n",
    "    debug = True\n",
    "    sensor_only = False\n",
    "    label_col = \"tsm1_k2\"\n",
    "    class_num = 4\n",
    "\n",
    "    exp_name = \"ViST-OffRoad\"\n",
    "    seed = 520\n",
    "    batch_size = 4096  # this is a desired batch size; pl trainer will accumulate gradients when per step batch is smaller.\n",
    "    train_batch_size = 64\n",
    "    valid_batch_size = 64\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_fold = 5\n",
    "    \n",
    "    # weights = torch.tensor([11491, 864], dtype=torch.float32,device=device)\n",
    "    weights = torch.tensor([1, 1], dtype=torch.float32,device=device)\n",
    "    model_name = \"sensorViLOnlyTransformerSS\" #仅图片\n",
    "    \n",
    "    wandb_name = \"\"\n",
    "\n",
    "    # Image setting\n",
    "    train_transform_keys = [\"pixelbert\"]\n",
    "    val_transform_keys = [\"pixelbert\"]\n",
    "    img_size = 384\n",
    "    max_image_len = -1\n",
    "    patch_size = 32\n",
    "    draw_false_image = 1\n",
    "    image_only = False\n",
    "\n",
    "    # Sensor\n",
    "    # senser_input_num = 11 # 翔冠的传感器参数\n",
    "    senser_input_num = 19 # 天航的传感器参数\n",
    "    \n",
    "    # Text Setting\n",
    "    vqav2_label_size = 3129\n",
    "    max_text_len = 40\n",
    "    tokenizer = \"bert-base-uncased\"\n",
    "    vocab_size = 30522 # vocabulary词汇数量\n",
    "    whole_word_masking = False\n",
    "    mlm_prob = 0.15\n",
    "    draw_false_text = 0\n",
    "\n",
    "    # Transformer Setting\n",
    "    # vit = \"vit_base_patch32_384\"\n",
    "    vit = \"vit_base_patch32_384_SemanticEstimation\"\n",
    "    hidden_size = 768  # 嵌入向量大小\n",
    "    num_heads = 12\n",
    "    num_layers = 12\n",
    "    mlp_ratio = 4\n",
    "    drop_rate = 0.2\n",
    "\n",
    "    # Optimizer Setting\n",
    "    optim_type = \"adamw\"\n",
    "    learning_rate = 1e-2 #0.0015#2e-3 #\n",
    "    weight_decay = 1e-2 # 0.01 ->1e-4\n",
    "    decay_power = 1\n",
    "    max_epoch = 10\n",
    "    max_steps = 25000\n",
    "    # warmup_steps = 2500\n",
    "    end_lr = 0\n",
    "    lr_mult = 1  # multiply lr for downstream heads\n",
    "    # T_max = 8000/train_batch_size*max_epoch \n",
    "    # T_max = 4632/train_batch_size*max_epoch # total 7237.5\n",
    "    # T_max = 2126/train_batch_size*max_epoch # soybean 3321.875\n",
    "    T_max = 9884/train_batch_size*max_epoch # soybean 3321.875\n",
    "\n",
    "    # Downstream Setting\n",
    "    get_recall_metric = False\n",
    "\n",
    "\n",
    "    # below params varies with the environment\n",
    "    data_root = \"\"\n",
    "    log_dir = \"result\"\n",
    "    per_gpu_batchsize = 0  # you should define this manually with per_gpu_batch_size=#\n",
    "    num_gpus = 1\n",
    "    num_nodes = 1\n",
    "    load_path = \"weights/vilt_200k_mlm_itm.ckpt\"\n",
    "    # load_path = \"save_model_dict.pt\"\n",
    "    num_workers = 1\n",
    "    precision = 16\n",
    "\n",
    "    # CBP 算法1,random maclaurin Projection参数\n",
    "    RMP_d = 10000\n",
    "\n",
    "\n",
    "\n",
    "if config.debug:\n",
    "    config.max_epoch = 2\n",
    "print(\"当前device=\",config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "\n",
    "    torch.manual_seed(seed)  # 为CPU设置随机种子\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.manual_seed(seed)  # 为当前GPU设置随机种子\n",
    "    torch.cuda.manual_seed_all(seed)  # 为所有GPU设置随机种子\n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "setup_seed(config.seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    }
   ],
   "source": [
    "if config.debug == True:\n",
    "    os.environ[\"WANDB_MODE\"] = 'dryrun' # 离线模式\n",
    "try:\n",
    "    # wandb.log(key=\"*******\") # if debug\n",
    "    wandb.login() # storage in ~/.netrc file\n",
    "    anonymous = None\n",
    "except:\n",
    "    anonymous = \"must\"\n",
    "    print('\\nGet your W&B access token from here: https://wandb.ai/authorize\\n')\n",
    "\n",
    "# os.environ[\"WANDB_MODE\"] = 'dryrun' # 离线模式\n",
    "# anonymous = None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "def fetch_df(label_col):\n",
    "    \"\"\"获取DataFrame\n",
    "\n",
    "    Args:\n",
    "        label_col (Enum): 标签那一列,枚举\n",
    "        'tsm1_original', 'tsm1_k2', 'tsm1_k3', 'tsm1_k4'\n",
    "\n",
    "    Returns:\n",
    "        _type_: DataFrame\n",
    "    \"\"\"\n",
    "    df_off_road = pd.read_csv(\"/home/junsheng/ViLT/data/off_road_tsm1_label_0.csv\")\n",
    "    df_off_road['image_path'] = df_off_road['file_path'].map(lambda x:os.path.join('/home/junsheng/data/off_road/Images/Images',x))\n",
    "    # df_off_road['image_path'] = df_off_road['file_path'].map(lambda x:os.path.join('/mnt/data/junsheng/data/off_road/Images/Images',x))\n",
    "\n",
    "    df_off_road['label'] = df_off_road[label_col]\n",
    "    # 重采样\n",
    "    # if config.label_col == 'tsm2_k2' :\n",
    "\n",
    "    #     # 统计label为0和1的数量\n",
    "    #     count_0 = df_off_road[df_off_road['label'] == 0].shape[0]\n",
    "    #     count_1 = df_off_road[df_off_road['label'] == 1].shape[0]\n",
    "\n",
    "    #     # 复制label为1的记录\n",
    "    #     df_label_1 = df_off_road[df_off_road['label'] == 1].copy()\n",
    "\n",
    "    #     # 复制8次label为1的记录\n",
    "    #     df_label_1_repeated = pd.concat([df_label_1] * (count_0 // count_1), ignore_index=True)\n",
    "\n",
    "    #     # 将复制后的记录添加到原始DataFrame中\n",
    "    #     df_off_road = pd.concat([df_off_road, df_label_1_repeated], ignore_index=True)\n",
    "    # else:\n",
    "    class_counts = df_off_road['label'].value_counts()\n",
    "\n",
    "    # 找到样本数量最少的类别\n",
    "    minority_class = class_counts.idxmin()\n",
    "\n",
    "    # 获取所有类别的索引\n",
    "    all_classes = class_counts.index.tolist()\n",
    "\n",
    "    # 创建过采样对象\n",
    "    oversampler = RandomOverSampler(sampling_strategy='not majority')\n",
    "\n",
    "    # 对少数类别进行过采样\n",
    "    df_resampled, labels_resampled = oversampler.fit_resample(df_off_road.drop('label', axis=1), df_off_road['label'])\n",
    "\n",
    "    # 将过采样后的数据集重新组合成DataFrame\n",
    "    df_balanced = pd.DataFrame(df_resampled, columns=df_off_road.columns.drop('label'))\n",
    "    df_balanced['label'] = labels_resampled\n",
    "    df_off_road = df_balanced\n",
    "    \n",
    "    df_off_road = df_off_road.dropna()\n",
    "    df_off_road = df_off_road.reset_index()\n",
    "\n",
    "    # number_title = []\n",
    "    # 归一化数值列\n",
    "    # recorder = {}\n",
    "    # for title in df_off_road:\n",
    "    #     if title == label_col or title == 'label':\n",
    "    #         continue\n",
    "    #     if df_off_road[title].dtype != \"object\":\n",
    "            \n",
    "    #         number_title.append(title)\n",
    "    #         x_min = df_off_road[title].min()\n",
    "    #         x_max = df_off_road[title].max()\n",
    "    #         recorder[title] = (x_min,x_max)\n",
    "    #         df_off_road[title] = df_off_road[title].map(lambda x:(x-x_min + 0.01)/(x_max - x_min))\n",
    "\n",
    "    # 选择传感器列\n",
    "    # off_road_sensor = [\n",
    "    # 'accel_x (counts)', 'accel_y (counts)', 'accel_z (counts)', 'calibrated_accel_x (g)', 'calibrated_accel_y (g)', 'calibrated_accel_z (g)', 'calibrated_accel_x (m/s^2)', 'calibrated_accel_y (m/s^2)', 'calibrated_accel_z (m/s^2)', 'position_lat (semicircles)', 'position_long (semicircles)', 'enhanced_altitude (m)', 'enhanced_speed (m/s)', 'heading (degrees)', 'gyro_x (counts)', 'gyro_y (counts)', 'gyro_z (counts)', 'calibrated_gyro_x (deg/s)', 'calibrated_gyro_y (deg/s)', 'calibrated_gyro_z (deg/s)', 'mag_x (counts)', 'mag_y (counts)', 'mag_z (counts)', 'velocity (m/s)1', 'velocity (m/s)2', 'velocity (m/s)3'\n",
    "    # ]\n",
    "    off_road_sensor = [\n",
    "    'accel_x (counts)', 'accel_y (counts)', 'accel_z (counts)', 'calibrated_accel_x (g)', 'calibrated_accel_y (g)', 'calibrated_accel_z (g)', 'gyro_x (counts)', 'gyro_y (counts)', 'gyro_z (counts)', 'calibrated_gyro_x (deg/s)', 'calibrated_gyro_y (deg/s)', 'calibrated_gyro_z (deg/s)', 'mag_x (counts)', 'mag_y (counts)', 'mag_z (counts)'\n",
    "    ]\n",
    "\n",
    "    # 标准化传感器列\n",
    "    df_off_road[off_road_sensor] = StandardScaler().fit_transform(df_off_road[off_road_sensor])\n",
    "\n",
    "    config.senser_input_num = len(off_road_sensor)\n",
    "\n",
    "    df_off_road['sensor'] = df_off_road[off_road_sensor].values.tolist()\n",
    "    print(\"input dim:\",len(off_road_sensor))\n",
    "    \n",
    "    # 筛选仅传感器信息\n",
    "    # if config.sensor_only:\n",
    "    #     df_tianhang.drop_duplicates(subset=['pic_key'],inplace=True,ignore_index=True)\n",
    "    \n",
    "    # debug 特判\n",
    "    df=df_off_road\n",
    "    if config.debug:\n",
    "        df = df[:200]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_folds(df):\n",
    "    skf = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)  \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df,df.filename)):\n",
    "        df.loc[val_idx, 'fold'] = fold\n",
    "    print(df.groupby(['fold'])['label'].count())   \n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: 15\n",
      "fold\n",
      "0.0    40\n",
      "1.0    40\n",
      "2.0    40\n",
      "3.0    40\n",
      "4.0    40\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = fetch_df(config.label_col)\n",
    "df = creat_folds(df)\n",
    "\n",
    "df.to_csv(\"test.csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0    92\n",
      "1.0    88\n",
      "2.0    20\n",
      "Name: tsm1_original, dtype: int64\n",
      "1.0    112\n",
      "0.0     88\n",
      "Name: tsm1_k2, dtype: int64\n",
      "2.0    92\n",
      "0.0    88\n",
      "1.0    20\n",
      "Name: tsm1_k3, dtype: int64\n",
      "3.0    92\n",
      "0.0    68\n",
      "1.0    20\n",
      "2.0    20\n",
      "Name: tsm1_k4, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['tsm1_original'].value_counts())\n",
    "print(df['tsm1_k2'].value_counts())\n",
    "print(df['tsm1_k3'].value_counts())\n",
    "print(df['tsm1_k4'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((config.img_size,config.img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    mean=[0.3552, 0.3744, 0.3293],\n",
    "    std=[0.2038, 0.2201, 0.2194],\n",
    ")\n",
    "])\n",
    "\n",
    "def load_img(path):\n",
    "    img =  Image.open(path).convert('RGB')\n",
    "    img = myTransforms(img)\n",
    "    return img\n",
    "\n",
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, label=True, transforms=None):\n",
    "        self.df         = df\n",
    "        self.label      = label\n",
    "        self.sensors = df['sensor'].tolist()\n",
    "        self.img_paths  = df['image_path'].tolist()   \n",
    "        if self.label:\n",
    "            self.labels = df['label'].tolist()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        img = load_img(img_path)\n",
    "        sensor = self.sensors[index]\n",
    "        sensor = torch.tensor(sensor).unsqueeze(0) #[1,n]\n",
    "        if self.label:\n",
    "            label = self.labels[index]\n",
    "            return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float),torch.tensor(label).to(torch.float)\n",
    "         \n",
    "\n",
    "        else:\n",
    "            return torch.tensor(img).to(torch.float), torch.tensor(sensor).to(torch.float)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_dataloader(fold:int,df):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "\n",
    "    df = fetch_df(config.label_col)\n",
    "\n",
    "\n",
    "    print(\"train_df.shape:\",train_df.shape)\n",
    "    print(\"valid_df.shape:\",valid_df.shape)\n",
    "\n",
    "    train_data  = BuildDataset(df=train_df,label=True)\n",
    "    valid_data = BuildDataset(df=valid_df,label=True)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.train_batch_size,shuffle=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=config.valid_batch_size,shuffle=True)\n",
    "    # test_loader = DataLoader(test_data, batch_size=config.test_batch_size,shuffle=False)\n",
    "    return train_loader,valid_loader,train_df\n",
    "\n",
    "def fetch_dataloader_ubiquatous():\n",
    "    train_df = pd.concat((fetch_df('soybean'),fetch_df('rice')),axis=0,join='inner').reset_index(drop=True)\n",
    "\n",
    "    valid_df = fetch_df('corn').reset_index(drop=True)\n",
    "    print(\"train_df.shape:\",train_df.shape)\n",
    "    print(\"valid_df.shape:\",valid_df.shape)\n",
    "\n",
    "    train_data  = BuildDataset(df=train_df,label=True)\n",
    "    valid_data = BuildDataset(df=valid_df,label=True)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.train_batch_size,shuffle=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=config.valid_batch_size,shuffle=False)\n",
    "    # test_loader = DataLoader(test_data, batch_size=config.test_batch_size,shuffle=False)\n",
    "    return train_loader,valid_loader\n",
    "def fetch_dataloader_ubiquatous_single_crop_test(fold:int,df,crop_name):#以一种作物为测试\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    if crop_name == \"soybean\":\n",
    "        valid_df = pd.read_csv(\"/home/junsheng/ViLT/data/ubiquitous_soybean.csv\")\n",
    "    elif crop_name == \"corn\":\n",
    "        valid_df = pd.read_csv(\"/home/junsheng/ViLT/data/ubiquitous_corn.csv\")\n",
    "    elif crop_name == \"rice\":\n",
    "        valid_df = pd.read_csv(\"/home/junsheng/ViLT/data/ubiquitous_rice.csv\")\n",
    "    print(\"train_df.shape:\",train_df.shape)\n",
    "    print(\"valid_df.shape:\",valid_df.shape)\n",
    "\n",
    "    train_data  = BuildDataset(df=train_df,label=True)\n",
    "    valid_data = BuildDataset(df=valid_df,label=True)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=config.train_batch_size,shuffle=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=config.valid_batch_size,shuffle=False)\n",
    "    # test_loader = DataLoader(test_data, batch_size=config.test_batch_size,shuffle=False)\n",
    "    return train_loader,valid_loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算图像均值标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_value(loader):\n",
    "    '''\n",
    "    求数据集的均值和标准差\n",
    "    :param loader:\n",
    "    :return:\n",
    "    '''\n",
    "    data_sum,data_squared_sum,num_batches = 0,0,0\n",
    "       \n",
    "    pbar = tqdm(enumerate(loader), total=len(loader), desc='caculating ')    \n",
    "    # for data,sensor,label  in loader:\n",
    "    for step,(data,sensor,label)  in pbar:\n",
    "        # data: [batch_size,channels,height,width]\n",
    "        # 计算dim=0,2,3维度的均值和，dim=1为通道数量，不用参与计算\n",
    "        # data_sum += torch.mean(data,dim=[0,2,3])    # [batch_size,channels,height,width]\n",
    "        data_sum += torch.mean(data,dim=[0,2,3])    # [batch_size,height,width,channels]\n",
    "        # 计算dim=0,2,3维度的平方均值和，dim=1为通道数量，不用参与计算\n",
    "        # data_squared_sum += torch.mean(data**2,dim=[0,2,3])  # [batch_size,channels,height,width]\n",
    "        data_squared_sum += torch.mean(data**2,dim=[0,2,3])  # [batch_size,height,width,channels]\n",
    "        # 统计batch的数量\n",
    "        num_batches += 1\n",
    "\n",
    "       \n",
    "    # 计算均值\n",
    "    mean = data_sum/num_batches\n",
    "    # 计算标准差\n",
    "    std = (data_squared_sum/num_batches - mean**2)**0.5\n",
    "    return mean,std\n",
    "# df = fetch_df(config.label_col)\n",
    "# df = creat_folds(df)\n",
    "# train_loader,_ = fetch_dataloader(fold=0,df=df)\n",
    "# mean,std = get_mean_std_value(train_loader)\n",
    "# print('mean = {},std = {}'.format(mean,std))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import models\n",
    "\n",
    "from models.CNNTransformer import CNNTransformer\n",
    "from models.RiceFusion import RiceFusion\n",
    "from models.RiceTransformer import RiceTransformer\n",
    "from models.ViST import *\n",
    "from models.resnet import *\n",
    "from models.vilt_ import *\n",
    "from models.DNNF1 import *\n",
    "from models.DNNF2 import *\n",
    "from models.RiceFusionMLP import *\n",
    "from models.RiceFusionCNN import *\n",
    "from models.BilinearPooling import *\n",
    "from models.CompactBilinearPoolingRMP import *\n",
    "from models.CompactBilinearPoolingTSP import *\n",
    "from models.SemanticEstimation import SemanticEstimation\n",
    "\n",
    "def build_model(model_name: str,pre_train):\n",
    "    if model_name[:6] == \"resnet50\":\n",
    "        model = pretrainedmodels.__dict__[config.model_name](\n",
    "            num_classes=1000, pretrained='imagenet')\n",
    "        dim_feats = model.last_linear.in_features  # =2048\n",
    "        nb_classes = 1\n",
    "        model.last_linear = nn.Linear(dim_feats, nb_classes)\n",
    "        return model\n",
    "    if model_name == \"se_resnet50\":\n",
    "        model = pretrainedmodels.__dict__[config.model_name](\n",
    "            num_classes=1000, pretrained='imagenet')\n",
    "        model.last_linear = nn.Linear(204800, 1,bias=True)\n",
    "        return model\n",
    "    if model_name == \"efficientnet-b4\": # efficient net\n",
    "        # refer:https://github.com/lukemelas/EfficientNet-PyTorch#example-classification\n",
    "        nb_classes = 1\n",
    "        if pre_train:\n",
    "            model = EfficientNet.from_pretrained(config.model_name)# 'efficientnet-b4'\n",
    "        else:\n",
    "            model = EfficientNet.from_name(config.model_name)# 'efficientnet-b4'\n",
    "        model._fc = nn.Linear(1792, nb_classes)\n",
    "        return model\n",
    "        \n",
    "    if model_name == \"ViST\":\n",
    "        model = ViST(sensor_class_n= config.senser_input_num,output_class_n = config.class_num,config=config)\n",
    "        return model\n",
    "    if model_name == \"ViST2\":\n",
    "        model = ViST2(sensor_class_n= config.senser_input_num,output_class_n = 1,config=config)\n",
    "        return model\n",
    "    if model_name == \"sensorViST\":\n",
    "        model = sensorViST(sensor_class_n= config.senser_input_num,output_class_n = config.class_num,config=config)\n",
    "        return model\n",
    "    if model_name == \"imageViST\":\n",
    "        model = imageViST(sensor_class_n= config.senser_input_num,output_class_n = 1,config=config)\n",
    "        return model\n",
    "        \n",
    "    if model_name == \"sensorOnlyViLTransformerSS\": #仅传感器\n",
    "        model = sensorOnlyViLTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1,config=config)\n",
    "        return model\n",
    "    if model_name == \"sensorViLOnlyTransformerSS\": # 仅vit图像\n",
    "        model = sensorViLOnlyTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1,config=config)\n",
    "        return model\n",
    "        \n",
    "    if model_name == \"sensorResnet50TransformerSS\":\n",
    "        model = sensorResnet50TransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1,config=config)\n",
    "        return model\n",
    "    if model_name == \"sensorResnet101TransformerSS\":\n",
    "        model = sensorResnet101TransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1,config=config)\n",
    "        return model\n",
    "\n",
    "    if model_name == \"sensorViLTransformerSS\":\n",
    "        model = sensorViLTransformerSS(sensor_class_n= config.senser_input_num,output_class_n = 1,config=config)\n",
    "        return model\n",
    "\n",
    "    if model_name == \"DNNF1\":\n",
    "        model = DNNF1(sensor_nums=config.senser_input_num,config=config)\n",
    "        return model\n",
    "    if model_name == \"DNNF1PictureOnly\":\n",
    "        model = DNNF1PictureOnly(sensor_nums=config.senser_input_num,config=config)\n",
    "        return model\n",
    "    if model_name == \"DNNF1SensorOnly\":\n",
    "        model = DNNF1SensorOnly(sensor_nums=config.senser_input_num,config=config)\n",
    "        return model\n",
    "        \n",
    "    if model_name == \"DNNF2\":\n",
    "        model = DNNF2(sensor_nums=config.senser_input_num,config=config)\n",
    "        return model\n",
    "    if model_name == \"DNNF2PictureOnly\":\n",
    "        model = DNNF2PictureOnly(sensor_nums=config.senser_input_num,config=config)\n",
    "        return model\n",
    "    if model_name == \"DNNF2SensorOnly\":\n",
    "        model = DNNF2SensorOnly(sensor_nums=config.senser_input_num,config=config)\n",
    "        return model\n",
    "    # RiceFusion对比模型\n",
    "    if model_name == \"RiceFusionMLP\":\n",
    "        model = RiceFusionMLP(sensor_nums=config.senser_input_num,config=config)\n",
    "        return model\n",
    "\n",
    "    if model_name == \"RiceFusionCNN\":\n",
    "        model = RiceFusionCNN(config=config)\n",
    "        return model\n",
    "    \n",
    "    if model_name == \"RiceFusion\":\n",
    "        return RiceFusion(sensor_nums=config.senser_input_num,config=config)\n",
    "    if model_name == \"RiceTransformer\":\n",
    "        return RiceTransformer(sensor_nums=config.senser_input_num,config=config)\n",
    "    if model_name == \"CNNTransformer\":\n",
    "        return CNNTransformer(sensor_nums=config.senser_input_num,config=config)\n",
    "    \n",
    "    if model_name == \"BilinearPooling\":\n",
    "        return BilinearPooling(sensor_nums=config.senser_input_num,config=config)\n",
    "    \n",
    "    if model_name == \"CompactBilinearPoolingRMP\":\n",
    "        return CompactBilinearPoolingRMP(sensor_nums=config.senser_input_num,config=config)\n",
    "    if model_name == \"CompactBilinearPoolingTSP\":\n",
    "        return CompactBilinearPoolingTSP(sensor_nums=config.senser_input_num,config=config)\n",
    "    if model_name == \"SemanticEstimation\":\n",
    "        return SemanticEstimation(sensor_class_n=config.senser_input_num,output_class_n = config.class_num,config=config)\n",
    "    raise Exception(\"模型未定义\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = config.weights / config.weights.sum()\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(weight=weights) #交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss(weight=weights) #交叉熵损失函数\n",
    "\n",
    "criterion_mae = nn.L1Loss()\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "def MAPE(y_true,y_pred):\n",
    "    \"\"\"计算MAPE误差，除数如果为0或者太小，则返回数值会很大\n",
    "\n",
    "    Args:\n",
    "        y_true (_type_): ground truth\n",
    "        y_pred (_type_): 预测值\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return mean_absolute_percentage_error(y_true,y_pred)\n",
    "\n",
    "def SMAPE(y_true, y_pred):\n",
    "    \"\"\"计算smape\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.tensor): 真实值\n",
    "        y_pred (torch.tensor): 预测值\n",
    "\n",
    "    Returns:\n",
    "        tensor: 一个数，如返回50，则表示50%\n",
    "    \"\"\"\n",
    "    return 2.0 * torch.mean(torch.abs(y_pred - y_true) / (torch.abs(y_pred) + torch.abs(y_true))) * 100.0\n",
    "\n",
    "def average_accuracy(predictions, targets, num_classes):\n",
    "    \"\"\"\n",
    "    计算平均类别准确率。\n",
    "\n",
    "    :param predictions: 模型给出的预测结果 (logits)，应该是浮点数类型。\n",
    "    :param targets: 实际结果的标签。\n",
    "    :param num_classes: 类别的数量。\n",
    "    :return: 平均类别准确率。\n",
    "    \"\"\"\n",
    "    predictions = predictions.float()  # 确保为浮点数类型\n",
    "    # probs = F.softmax(predictions, dim=1)\n",
    "    _, predicted_classes = torch.max(predictions, 1)\n",
    "    \n",
    "    class_accuracies = []\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        class_targets = (targets == i)\n",
    "        class_predictions = (predicted_classes == i)\n",
    "        class_correct_samples = (class_predictions & class_targets).sum().item()\n",
    "        class_total_samples = class_targets.sum().item()\n",
    "        \n",
    "        if class_total_samples > 0:\n",
    "            class_accuracy = class_correct_samples / class_total_samples\n",
    "            class_accuracies.append(class_accuracy)\n",
    "        else:\n",
    "            # 考虑到某些类别可能不出现在targets里面（即class_total_samples为0）\n",
    "            # 为了不影响平均准确率的计算, 可以选择跳过这个类别或给予默认准确率值（例如0）\n",
    "            # 这里选择跳过该类别\n",
    "            continue\n",
    "    \n",
    "    # aa = sum(class_accuracies) / len(class_accuracies)\n",
    "    aa = sum(class_accuracies) / num_classes\n",
    "    return aa\n",
    "\n",
    "def overall_accuracy(predictions, targets):\n",
    "    \"\"\"\n",
    "    计算预测结果的总体准确率，基于最大概率。\n",
    "\n",
    "    :param predictions: 模型给出的预测结果 (logits)。\n",
    "    :param targets: 实际结果的标签。\n",
    "    :return: 总体准确率。\n",
    "    \"\"\"\n",
    "    predictions = predictions.float()\n",
    "    # 使用 softmax 将 logits 转换为概率\n",
    "    probs = F.softmax(predictions, dim=1)\n",
    "    # 取概率最大值的索引，即预测的类别\n",
    "    _, predicted_classes = torch.max(probs, 1)\n",
    "    # 计算准确的样本数量\n",
    "    correct_samples = (predicted_classes == targets).sum().item()\n",
    "    # 计算样本总数\n",
    "    total_samples = targets.size(0)\n",
    "    # 计算整体准确率\n",
    "    accuracy = correct_samples / total_samples\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算精确率，召回率，F1分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def precision_recall_fscore(y_true ,y_pred ):\n",
    "    \"\"\"average参数在precision_recall_fscore_support函数中用于决定如何计算多类别问题的精确率、召回率和F1分数。不同的average参数值会影响计算的结果。下面是一些可用的参数选项和它们的含义：\n",
    "None：不做平均处理。返回每个类别的精确率、召回率和F1分数。\n",
    "'binary'：只报告针对指定的正类的结果。在二分类任务中使用，或者在多分类任务中指定一个类别视为正类。\n",
    "'micro'：通过先计算总的真正例、假正例和假负例的数量，然后计算精确率、召回率和F1分数。这种方法给每个样本和每个类别赋予相同的权重，即总体性能。\n",
    "'macro'：分别为每个类别计算指标，然后计算它们的未加权平均值。这种方法对所有类别都赋予相等的权重，无论它们的支持（样本数量）如何。不考虑标签不平衡。\n",
    "'weighted'：为每个类别计算指标，然后计算它们的平均值，使用每个类别的支持（出现的样本数量）作为权重。这意味着对于每个标签的分数乘以它在数据中的实际出现频率。这种方法适用于标签不平衡的情况。\n",
    "'samples'：仅用于多标签分类问题。计算每个实例的指标，然后找到它们的平均值（每行只统计一次）。\n",
    "选择哪个average参数取决于您的数据集特性和分析目标。例如，如果您关心所有类别的整体平均性能，那么'macro'可能是合适的；如果您的数据集类别非常不平衡，'weighted'会更合适，因为它考虑了每个类别的支持度；而'micro'通过累计整个数据集的性能，提供了总体的性能指标。在实际应用时，您可以根据任务的具体需求和数据集的特征来选择最合适的average参数。\n",
    "\n",
    "    Args:\n",
    "        targets (_type_): y_true\n",
    "        predictions (_type_): y_prediction\n",
    "    \"\"\"\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1)\n",
    "    # 使用softmax将输出转换为概率分布，并取得概率最大的索引作为预测的类别\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    # 将PyTorch Tensors转换为NumPy数组\n",
    "    y_pred_np = y_pred_labels.cpu().numpy()\n",
    "    y_true_np = y_true.squeeze().cpu().numpy()  # 使用squeeze去除单维度条目\n",
    "    # 计算精确率、召回率和F1分数\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true_np, y_pred_np, average='macro')\n",
    "    return precision, recall, f1_score\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Mixture Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMixtureLoss(nn.Module):\n",
    "    def __init__(self, num_mixtures):\n",
    "        super(KernelMixtureLoss, self).__init__()\n",
    "        self.num_mixtures = num_mixtures\n",
    "        self.alpha = nn.Parameter(torch.ones(num_mixtures))\n",
    "        self.tau = nn.Parameter(torch.ones(num_mixtures))\n",
    "\n",
    "    def forward(self, q, k_plus, k_negatives):\n",
    "        # Compute the exponential terms\n",
    "        exp_terms = torch.exp(q * k_plus / self.tau.unsqueeze(1))\n",
    "        \n",
    "        # Compute the numerator and denominator\n",
    "        numerator = torch.sum(self.alpha.unsqueeze(1) * exp_terms, dim=1)\n",
    "        denominator = torch.sum(self.alpha.unsqueeze(1) * torch.exp(q * k_negatives / self.tau.unsqueeze(1)), dim=2)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = -torch.log(numerator / denominator).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_mixture_loss = KernelMixtureLoss(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 示例数据\n",
    "# predictions_example = torch.tensor([[1.0, 2.0, 0.0, 3.0], [4.0, 1.0, 2.0, 0.0]])\n",
    "# targets_example = torch.tensor([3, 0])  # True labels\n",
    "# num_classes_example = 4\n",
    "\n",
    "# # 计算平均类别准确率\n",
    "# average_acc = average_accuracy(predictions_example, targets_example, num_classes_example)\n",
    "# print(f\"Average Class Accuracy: {average_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (img, sensor,label) in pbar:         \n",
    "        # img = img.to(device, dtype=torch.float)\n",
    "        # sensor  = sensor.to(device, dtype=torch.float)\n",
    "        # label  = label.to(device, dtype=torch.float)\n",
    "        batch_size = img.size(0)\n",
    "        \n",
    "        batch = {\"image\":img,\"sensor\":sensor}\n",
    "\n",
    "        y_pred = model(batch)\n",
    "        label = label.to(config.device)\n",
    "        label = label.long()\n",
    "        loss = criterion(y_pred['cls_output'], label)\n",
    "\n",
    "        # print(\"output\",y_pred['cls_output'])\n",
    "        # print(f\"Loss: {loss.item()}\")\n",
    "        #一坨优化\n",
    "        optimizer.zero_grad()# 每一次反向传播之前都要归零梯度\n",
    "        loss.backward()      # 反向传播\n",
    "        \n",
    "        # print(\"train eopch{}-step{}\",epoch,step)\n",
    "        # 监视特定层的梯度\n",
    "        # specific_layers_gradients = {\n",
    "        #     \"transformer.blocks.0.norm1.bias\": None,\n",
    "        #     \"transformer.blocks.0.attn.qkv.bias\": None,\n",
    "        #     \"transformer.blocks.0.attn.proj.bias\": None,\n",
    "        #     \"transformer.blocks.0.norm2.bias\": None,\n",
    "        #     \"transformer.blocks.0.mlp.fc1.bias\": None,\n",
    "        #     \"transformer.blocks.0.mlp.fc2.bias\": None,\n",
    "        # }\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if name in specific_layers_gradients:\n",
    "        #         print(f\"{name} requires_grad: {param.requires_grad}\")\n",
    "        # 通过model.named_parameters()方法获取模型参数及其名称\n",
    "        # for name, parameter in model.named_parameters():\n",
    "        #     if name in specific_layers_gradients:\n",
    "        #         specific_layers_gradients[name] = parameter.grad\n",
    "\n",
    "        # 打印获取到的梯度信息\n",
    "        # for layer_name, gradient in specific_layers_gradients.items():\n",
    "        #     print(f\"Gradient for {layer_name}: {gradient}\")\n",
    "        optimizer.step()     #固定写法\n",
    "        scheduler.step()\n",
    "     \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "        \n",
    "        wandb.log({\"Training Loss\": loss,\n",
    "                \"Training lr\": scheduler.get_last_lr()[0]\n",
    "                })\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import collections\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, optimizer):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # 计算overall_accuracy\n",
    "    predictions= torch.empty(0, config.class_num).to(config.device)\n",
    "    targets = torch.empty(0).to(config.device)\n",
    "    running_loss_mae = 0.0\n",
    "    running_loss_smape = 0.0\n",
    "    running_loss_mape = 0.0\n",
    "    running_overall_accuracy = 0.0\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (img, sensor,label) in pbar:               \n",
    "        \n",
    "        \n",
    "        batch_size = img.size(0)\n",
    "        batch = {\"image\":img,\"sensor\":sensor}\n",
    "\n",
    "        y_pred  = model(batch)\n",
    "        label = label.to(config.device)\n",
    "        label = label.long()\n",
    "        loss = criterion(y_pred['cls_output'], label)\n",
    "        \n",
    "        targets = torch.cat((targets, label), dim=0)\n",
    "        predictions = torch.cat((predictions, y_pred['cls_output']), dim=0)\n",
    "\n",
    "        running_overall_accuracy = overall_accuracy(y_pred['cls_output'], label)\n",
    "        running_average_accuracy = average_accuracy(y_pred['cls_output'], label,config.class_num)\n",
    "        # loss_mae = criterion_mae(y_pred['cls_output'], label)\n",
    "        # loss_smape = SMAPE(label,y_pred['cls_output'])\n",
    "        # loss_mape = MAPE(label.cpu(),y_pred['cls_output'].cpu())\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        # running_loss_mae += (loss_mae.item() * batch_size)\n",
    "        # running_loss_smape += (loss_smape.item() * batch_size)\n",
    "        # running_loss_mape += (loss_mape.item() * batch_size)\n",
    "\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        # epoch_loss_mae = running_loss_mae / dataset_size\n",
    "        # epoch_loss_smape = running_loss_smape / dataset_size\n",
    "        # epoch_loss_mape = running_loss_mape / dataset_size\n",
    "        # print(\"验证过程中日志记录\")\n",
    "        # print(\"当前loss:\",epoch_loss)\n",
    "        # print(\"当前overall_accuracy:\",running_overall_accuracy)\n",
    "        # print(\"当前average_accuracy:\",running_average_accuracy)\n",
    "        # print(\"当前targets\",targets.cpu().tolist())\n",
    "        # print(\"当前predictions\",predictions.cpu().tolist())\n",
    "\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB',\n",
    "                        overall_accuracy=f'{running_overall_accuracy:0.4f}',\n",
    "                        average_accuracy=f'{running_average_accuracy:0.4f}',\n",
    "        )\n",
    "        # wandb.log({\"Validing Loss\": loss,\n",
    "        #             \"Validing OAcc\": running_overall_accuracy,\n",
    "        #             \"Validing AAcc\": running_average_accuracy,\n",
    "        #         })\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    precision, recall, f1_score = precision_recall_fscore(targets,predictions)\n",
    "\n",
    "\n",
    "    overall_acc = overall_accuracy(predictions,targets)\n",
    "    average_acc = average_accuracy(predictions,targets,config.class_num)\n",
    "\n",
    "    Metrics = collections.namedtuple('Metrics', ['val_loss', 'overall_acc', 'average_acc','precision', 'recall', 'f1_score'])\n",
    "    metrics = Metrics(epoch_loss, overall_acc, average_acc, precision, recall, f1_score)\n",
    "    return metrics\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_training(model, optimizer, scheduler, device, num_epochs,train_loader,valid_loader):\n",
    "     # init wandb\n",
    "    run = wandb.init(project=config.exp_name,\n",
    "                    config={k: v for k, v in dict(vars(config)).items() if '__' not in k},\n",
    "                    # config={k: v for k, v in dict(config).items() if '__' not in k},\n",
    "                    anonymous=anonymous,\n",
    "                    # name=f\"vilt|fold-{config.valid_fold}\",\n",
    "                    name=config.wandb_name,\n",
    "                    # group=config.wandb_group,\n",
    "                    )\n",
    "    wandb.watch(model, log_freq=100)\n",
    "\n",
    "    best_loss = 9999\n",
    "    best_valid_loss = 9999\n",
    "    history = defaultdict(list)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=device, epoch=epoch)\n",
    "        # val_loss,overall_acc,average_acc = valid_one_epoch(model,valid_loader,device=device,optimizer=optimizer) # epoch_loss\n",
    "        valid_metrics = valid_one_epoch(model,valid_loader,device=device,optimizer=optimizer) \n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(valid_metrics.val_loss)\n",
    "        history['Valid OAcc'].append(valid_metrics.overall_acc)\n",
    "        history['Valid AAcc'].append(valid_metrics.average_acc)\n",
    "        history['Valid Precision'].append(valid_metrics.precision)\n",
    "        history['Valid recall'].append(valid_metrics.recall)\n",
    "        history['Valid f1_score'].append(valid_metrics.f1_score)\n",
    "\n",
    "        wandb.log({\"Train Loss\": train_loss,\n",
    "                    \"Valid Loss\": valid_metrics.val_loss,\n",
    "                    \"Valid OAcc\": valid_metrics.overall_acc,\n",
    "                    \"Valid AAcc\": valid_metrics.average_acc,\n",
    "                    \"Valid Precision\": valid_metrics.precision,\n",
    "                    \"Valid recall\": valid_metrics.recall,\n",
    "                    \"Valid f1_score\": valid_metrics.f1_score,\n",
    "                    \"lr\": scheduler.get_last_lr()[0]\n",
    "                })\n",
    "        if best_valid_loss > valid_metrics.val_loss:\n",
    "            best_valid_loss = valid_metrics.val_loss\n",
    "            # model_file_path = os.path.join(wandb.run.dir,\"epoch-{}-{}.bin\".format(epoch,wandb.run.id))\n",
    "            # model_file_path = os.path.join(wandb.run.dir,\"epoch-best.bin\")\n",
    "            run.summary[\"Best Epoch\"] = epoch\n",
    "            # torch.save(model.state_dict(), model_file_path)\n",
    "            # print(\"model save to\", model_file_path)\n",
    "               \n",
    "    os.system(\"cp /home/junsheng/ViLT/my_vilt_total_off_road.ipynb {}\".format(wandb.run.dir))\n",
    "    run.finish()\n",
    "    return model, history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(label_col:str,model_name:str,wandb_name:str,sensor_only:bool):\n",
    "    config.model_name = model_name\n",
    "    config.wandb_name = wandb_name\n",
    "    config.sensor_only = sensor_only\n",
    "\n",
    "    df = fetch_df(label_col)\n",
    "    df = creat_folds(df)\n",
    "    kernel_mixture_loss = KernelMixtureLoss(10)\n",
    "    \n",
    "    train_loader,valid_loader = fetch_dataloader(fold=0,df=df)\n",
    "    # train_loader,valid_loader = fetch_dataloader_ubiquatous()\n",
    "\n",
    "\n",
    "    model = build_model(config.model_name,True)\n",
    "    model.to(config.device)\n",
    "    print(config.device)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    optimizer =  optim.SGD(model.parameters(), lr=config.learning_rate,weight_decay=config.weight_decay,momentum=0.9)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=config.T_max, \n",
    "                                                    eta_min=5e-6)\n",
    "    model, history = run_training(model, optimizer, scheduler,device=config.device,num_epochs=config.max_epoch,train_loader=train_loader,valid_loader=valid_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vist_task_dict = {\n",
    "    \"tsm1_original\":{\n",
    "        \"label_col\":\"tsm1_original\",\n",
    "        \"model_name\":\"ViST\",\n",
    "        \"wandb_name\":\"vist|tsm1_original|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"tsm1_k2\":{\n",
    "        \"label_col\":\"tsm1_k2\",\n",
    "        \"model_name\":\"ViST\",\n",
    "        \"wandb_name\":\"vist|tsm1_k2|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "        },\n",
    "    \"tsm1_k3\":{\n",
    "        \"label_col\":\"tsm1_k3\",\n",
    "        \"model_name\":\"ViST\",\n",
    "        \"wandb_name\":\"vist|tsm1_k3|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"tsm1_k4\":{\n",
    "        \"label_col\":\"tsm1_k4\",\n",
    "        \"model_name\":\"ViST\",\n",
    "        \"wandb_name\":\"vist|tsm1_k4|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"tsm2_original\":{\n",
    "        \"label_col\":\"tsm2_original\",\n",
    "        \"model_name\":\"ViST\",\n",
    "        \"wandb_name\":\"vist|tsm2_original|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"tsm2_k2\":{\n",
    "        \"label_col\":\"tsm2_k2\",\n",
    "        \"model_name\":\"ViST\",\n",
    "        \"wandb_name\":\"vist|tsm2_k2|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "        },\n",
    "    \"tsm2_k3\":{\n",
    "        \"label_col\":\"tsm2_k3\",\n",
    "        \"model_name\":\"ViST\",\n",
    "        \"wandb_name\":\"vist|tsm2_k3|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"tsm2_k4\":{\n",
    "        \"label_col\":\"tsm2_k4\",\n",
    "        \"model_name\":\"ViST\",\n",
    "        \"wandb_name\":\"vist|tsm2_k4|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_task_dict = {  \n",
    "    \"tsm1_original\":{\n",
    "        \"label_col\":\"tsm1_original\",\n",
    "        \"model_name\":\"SemanticEstimation\",\n",
    "        \"wandb_name\":\"Semantic|tsm1_original|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"tsm1_k2\":{\n",
    "        \"label_col\":\"tsm1_k2\",\n",
    "        \"model_name\":\"SemanticEstimation\",\n",
    "        \"wandb_name\":\"Semantic|tsm1_k2|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "        },\n",
    "    \"tsm1_k3\":{\n",
    "        \"label_col\":\"tsm1_k3\",\n",
    "        \"model_name\":\"SemanticEstimation\",\n",
    "        \"wandb_name\":\"Semantic|tsm1_k3|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"tsm1_k4\":{\n",
    "        \"label_col\":\"tsm1_k4\",\n",
    "        \"model_name\":\"SemanticEstimation\",\n",
    "        \"wandb_name\":\"Semantic|tsm1_k4|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"tsm2_original\":{\n",
    "        \"label_col\":\"tsm2_original\",\n",
    "        \"model_name\":\"SemanticEstimation\",\n",
    "        \"wandb_name\":\"Semantic|tsm2_original|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"tsm2_k2\":{\n",
    "        \"label_col\":\"tsm2_k2\",\n",
    "        \"model_name\":\"SemanticEstimation\",\n",
    "        \"wandb_name\":\"Semantic|tsm2_k2|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "        },\n",
    "    \"tsm2_k3\":{\n",
    "        \"label_col\":\"tsm2_k3\",\n",
    "        \"model_name\":\"SemanticEstimation\",\n",
    "        \"wandb_name\":\"Semantic|tsm2_k3|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"tsm2_k4\":{\n",
    "        \"label_col\":\"tsm2_k4\",\n",
    "        \"model_name\":\"SemanticEstimation\",\n",
    "        \"wandb_name\":\"Semantic|tsm2_k4|OffRoad\",\n",
    "        \"sensor_only\":False,\n",
    "    \n",
    "    },\n",
    "    \"sensorViST\":{\n",
    "        \"label_col\":\"tsm1_k2\",\n",
    "        \"model_name\":\"sensorViST\",\n",
    "        \"wandb_name\":\"sensorViST|tsm2_k2|OffRoad\",\n",
    "        \"sensor_only\":True,\n",
    "    \n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试仅传感器\n",
    "# task = semantic_task_dict[\"sensorViST\"]\n",
    "# config.class_num = 2\n",
    "# config.max_epoch = 10\n",
    "# config.learning_rate = 0.001\n",
    "# run(task[\"label_col\"],task[\"model_name\"],task[\"wandb_name\"],task[\"sensor_only\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: 15\n",
      "fold\n",
      "0.0    40\n",
      "1.0    40\n",
      "2.0    40\n",
      "3.0    40\n",
      "4.0    40\n",
      "Name: label, dtype: int64\n",
      "input dim: 15\n",
      "train_df.shape: (160, 40)\n",
      "valid_df.shape: (40, 40)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m config\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m\n\u001b[1;32m      3\u001b[0m task \u001b[38;5;241m=\u001b[39m vist_task_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtsm1_k3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_col\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msensor_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m task \u001b[38;5;241m=\u001b[39m vist_task_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtsm2_k3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m run(task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_col\u001b[39m\u001b[38;5;124m\"\u001b[39m],task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m],task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb_name\u001b[39m\u001b[38;5;124m\"\u001b[39m],task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor_only\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(label_col, model_name, wandb_name, sensor_only)\u001b[0m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m creat_folds(df)\n\u001b[1;32m      8\u001b[0m kernel_mixture_loss \u001b[38;5;241m=\u001b[39m KernelMixtureLoss(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m train_loader,valid_loader \u001b[38;5;241m=\u001b[39m fetch_dataloader(fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,df\u001b[38;5;241m=\u001b[39mdf)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# train_loader,valid_loader = fetch_dataloader_ubiquatous()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(config\u001b[38;5;241m.\u001b[39mmodel_name,\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "config.class_num = 3\n",
    "config.learning_rate = 0.0001\n",
    "task = vist_task_dict[\"tsm1_k3\"]\n",
    "run(task[\"label_col\"],task[\"model_name\"],task[\"wandb_name\"],task[\"sensor_only\"])\n",
    "\n",
    "task = vist_task_dict[\"tsm2_k3\"]\n",
    "run(task[\"label_col\"],task[\"model_name\"],task[\"wandb_name\"],task[\"sensor_only\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model = build_model(\"ViST\",True)\n",
    "    state_dict = torch.load('/home/junsheng/ViLT/wandb/run-20230111_141431-tb52bngc/files/epoch-best.bin')\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(config.device)\n",
    "    test_df = pd.read_csv(\"/home/junsheng/ViLT/data/ubiquitous_soybean.csv\")\n",
    "    tianhang_sensor = ['co2', 'stemp', 'stemp2', 'stemp3', 'stemp5', 'shumi', 'shumi2', 'shumi3', 'shumi5', 'humi', 'pm10', 'pm25', 'press', 'solar', 'temp', 'wind_d', 'wind_sp']\n",
    "    test_df['sensor'] = test_df[tianhang_sensor].values.tolist()\n",
    "    test_data = BuildDataset(df=test_df,label=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=config.valid_batch_size,shuffle=False)\n",
    "    val_loss,val_loss_mae,val_loss_smape,val_loss_mape = valid_one_epoch(model,test_loader,device=config.device) # # epoch_loss,epoch_loss_mae,epoch_loss_smape,epoch_loss_mape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_junsheng_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29fd19f11c6b89e267402bb3227bc1208f7e2c9719aa03eba13baf7684fe5867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
